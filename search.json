[{"title":"HSF-base-info","url":"/2023/08/16/%E5%90%8E%E7%AB%AF/HSF-base-info/","content":"1. 简述：什么是HSFHSF (High-speed Service Framework)，高速服务框架，是集团内部广泛使用的分布式 RPC 服务框架，和外部使用的Dubbo类似。HSF 作为集团的基础中间件，联通不同的业务系统，解耦系统间的实现依赖。HSF 从分布式应用的层面，统一了服务的发布/调用方式，从而帮助用户可以方便、快速的开发分布式应用，以及提供或使用公共功能模块。（HSF是集团内部的分布式RPC服务框架，类似在外面用的Dubbo + Zookeeper）\n2. HSF结构设计HSF搭配Config Server、Diamon和Redis已经实现了微服务架构的各种基本功能。\nHSF 本身是没有服务端集群，是一个纯客户端架构的 RPC 框架，所有的 HSF 服务调用都是服务消费方（Consumer）与服务提供方（Provider）点对点建立连接的。\n为了实现整套分布式服务体系，HSF 还需要依赖集团的各种其他中间件：主要的中间件有以下几个:\n\nDiamond：持久化配置中心：HSF 客户端在启动的过程中会向持久化配置中心订阅各种服务治理规则，如路由规则、归组规则、权重规则等，从而根据规则对调用过程的选址逻辑进行干预。\nConfigServer：地址注册中心：提供服务发现和服务检索的能力，注册中心告知有哪些机器提供了什么什么服务，如果没有注册中心，HSF 只能完成简单的点对点调用。\nRedis（可选）：元数据指 HSF 服务对应的方法列表以及参数结构等信息，对 HSF 的调用过程不会产生影响。\n\n实战理解：\n\n服务提供方绑定了 12200 端口，用于接受请求并提供服务，同时将地址信息发布到地址注册中心。\n服务消费者通过地址注册中心订阅服务，根据订阅到的ip地址发起调用，地址注册中心不参与调用。\n\n集成在Pandora Boot容器中的HSF服务在本地启动后在终端输入 telnet localhost 12201 后连接到Pandora console在console中cd hsf后ls即可看到本地运行的HSF服务提供者和消费者,如下所示：\nhsf&gt;lsCurrent Unit: CENTERAs Provider side:--------------------------------------------------------------------------------------------------|                   SERVICE_NAME                   |  GROUP   |    PUB    |SERIALIZE |WRITE_MODE |--------------------------------------------------------------------------------------------------| com.demo.hsf.HelloService:1.0.0.DAILY | HSF_DEMO |     Y     | hessian2 |           |--------------------------------------------------------------------------------------------------As Consumer side:-----------------------------------------------------------------------------------------------|                   SERVICE_NAME                   |  GROUP   | ADDR_NUM  |UN_ADDR_NUM|TIMEOUT|-----------------------------------------------------------------------------------------------| com.demo.hsf.HelloService:1.0.0.DAILY | HSF_DEMO |     1     |     1     | 2000  |-----------------------------------------------------------------------------------------------\n\n3. HSF 调用方式 fast-start服务发布者最简单常用的方式就是在需要对外服务的Service上提供一个一个一个@HSFProvider注解\n@HSFProvider(serviceInterface = HelloService.class,serviceVersion = &quot;$&#123;hsf.provider.version&#125;&quot;)public class HelloServiceImpl implements HelloService &#123;    @Override    public String sayHello(String name) &#123;        return &quot;Hello, &quot; + name;    &#125;&#125;\n在Pandora Boot容器配置文件中写入相关的HSF所属组和版本号（比通过定义HSFApiProviderBean通过api的形式配置HSF服务更方便），然后在业务相关的网关中配置访问路由即可 。\n服务调用者调用者最简单的方式即统一写一个带有@Configuration注解的Config类，对需要消费的服务上添加@HSFConsumer 注解（记得在项目中增加依赖starter）,将其作为一个JavaBean交给容器进行管理。\n@Configurationpublic class HsfConfig &#123;    @HSFConsumer    private HelloService helloService;&#125;\n\n然后在业务中需要使用的地方，直接@Autowired注入即可上述例子中的API配置\n/** * 通过HSFConsumer注入hsf服务，详情见 https://gitlab.alibaba-inc.com/middleware-container/pandora-boot/wikis/spring-boot-hsf */@Controller@RequestMapping(value = &quot;invoke&quot;)public class HsfController &#123;    @Autowired    @Qualifier(&quot;helloService&quot;)    private HelloService helloService;&#125;\n如果嫌这种方法太简单，学不到真正的JavaEE 技术 ,也可以使用JavaBean的方式。\nHSFApiConsumerBean hsfApiConsumerBean = new HSFApiConsumerBean();hsfApiConsumerBean.setInterfaceName(&quot;com.alibaba.middleware.hsf.guide.api.service.HelloWorldService&quot;);// [设置] 服务的版本hsfApiConsumerBean.setVersion(&quot;1.0.0&quot;);// [设置] 服务的组别hsfApiConsumerBean.setGroup(&quot;HSF&quot;);// [订阅] HSF 服务，同步等待地址推送，默认 false (异步)，同步默认超时时间 3000 毫秒hsfApiConsumerBean.init(true);HelloService helloService = (HelloService) hsfApiConsumerBean.getObject();String hello = HelloService.sayHello(&quot;hello&quot;);\n\n亦或是在每处需要调用到的业务代码中给出注解的定义，但是不如统一定义个Config类更方便。\n@HSFConsumer(serviceVersion = &quot;1.0.0&quot;, clientTimeout = 3000, configServerCenters = &quot;hello&quot;)    private HelloService helloService;\n\nExample：例如在业务中存在需要对二方包进行RPC调用，只需要做如下的操作：\n\n在pom.xml里添加对二方包的依赖\n&lt;!-- 运输实操域 --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.demo&lt;/groupId&gt;    &lt;artifactId&gt;demo-package&lt;/artifactId&gt;    &lt;version&gt;$&#123;demo-package.version&#125;&lt;/version&gt;&lt;/dependency&gt;              ....&lt;demo-package.version&gt;1.0.56&lt;/demo-package.version&gt;\nhsf接口配置类HsfConsumer 中注册Bean\n\n\n@Configurationpublic class HsfConsumer &#123;    .....    @HSFConsumer    private DemoHsfService demoHsfService;    .....  &#125;\n\n\n在需要用到这个服务的地方用@Resource注解调用即可\n\n@Resourceprivate DemoHsfService demoHsfService;\n\n在业务中即可如本地方法调用一般执行HSF调用（当然这是同步调用）\nResult&lt;Float&gt; result = demoHsfService.function(param1,param2);\n如果在高并发的情景下，可能就涉及到异步调用，HSF中有两种异步调用的方法:\n\nFuture 调用：客户端在需要获取调用的返回结果时，通过 HSFResponseFuture.getResponse(int timeout) 主动获取结果。与FutureTask有关，创建一个新的线程去执行逻辑，在get结果出阻塞等待结果(待验证)。\nCallback 调用：Callback 调用利用 HSF 内部提供的回调机制，当指定的 HSF 服务消费完毕拿到返回结果时，HSF 框架会回调用户实现的 HSFResponseCallback 接口，客户端通过回调通知的方式获取结果。\n\n3.5 HSF内部架构如上图所示，HSF框架进一步可细分为4块领域（框架、应用、服务和配置），共11层\n\n框架提供了基础功能，负责通信、线程池、协议编解码、序列化以及连接管理相关的工作。\n\n\n名称\n功能\n扩展点介绍\n\n\n\nPacket\n请求对象到通信对象的转换工作，能够将调用层的抽象转换成为网络层定义的抽象，也完成反向转换的工作\nPacketFactory负责实现对象转换工作，如果需要支持不同协议，就需要扩展它\n\n\nSerialize\n完成序列化/反序列化工作\nSerializer对应一种序列化协议，比如：hessian2、fastjson等，如果要增加序列化协议，就需要扩展它\n\n\nThreadPool\n线程池管理服务，维护了HSF框架对于线程资源的申请、分配以及线程指标的获取\nThreadPoolManager完成线程的创建工作，服务端线程动态的创建可以选择扩展它\n\n\nFrame\n完成网络层协议编解码工作\nFramer负责完成不同RPC框架网络层协议的编解码工作，该扩展工作在IO线程上，因此要求其扩展不能阻塞\n\n\nStream\n抽象的网络链接层，使用方可以通过Stream来发起调用以及接受响应，开发者可以将Stream适配到不同的NIO框架上\nStreamLifecyleListener用于监听网络链接的建立、销毁等事件，扩展它可以知晓HSF和外部建立的链接StreamMessageListener用于监听网络层发送以及接受的数据\n\n\n\n\n\n应用主要面向服务框架的注册和发现过程，是HSF完成分布式调用的基础，用来支撑服务。\n\n\n\n名称\n功能\n扩展点介绍\n\n\n\nRegistry\n定义了注册中心客户端的抽象，完成服务注册以及服务订阅的工作，开发者可以将Registry适配到不同的注册中心实现上\nAddressListener可以监听到服务对应的地址列表AddressListenerInterceptor完成在地址监听器收到地址前的拦截工作\n\n\nProtocol\n定义了协议和流程，能够识别注册中心下推地址的类型，完成发布和消费服务的工作\nProtocolInterceptor可以拦截服务在发布和订阅中的过程\n\n\n\n服务的粒度比应用小，它包含了调用链路、地址路由以及负载均衡等功能。\n\n\n\n名称\n功能\n扩展点介绍\n\n\n\nInvocationHandler\n定义了调用的请求和响应，以责任链的形式实现了调用的拦截处理模式\nClientFilter拦截客户端发起的请求和收到的响应ServerFilter拦截服务端收到的请求和发送的响应\n\n\nRouter\n定义了路由选址过程，一次调用传入Router，Router会根据请求上下文在一组地址列表中选择一堆符合要求的地址列表\nAbstractMultiTargetRouter选址扩展，能够返回多个符合要求的RouterAbstractSingleTargetRouter选址扩展，返回单个符合要求的Router\n\n\nLoadBalance\n定义了负载均衡的抽象，提供从一组地址中选择一个调用地址的能力\nLoadBalancer负载均衡策略的抽象，比如随机选择或者轮询\n\n\n\n在服务之上是配置，用户使用API来对各层进行配置，并生成调用的代理或暴露服务。\n\n\n其实每一层的实现也是可替换可扩展的，替换的关键在于 每一层有自己的核心抽象 。\n以注册中心Registry这一层为例，主要的抽象就是Registry以及围绕注册中心推送地址的地址监听器AddressListener，地址推送逻辑都是基于AddressListener来编写的，因此用户只要实现一个Registry接口，就完全可以替换掉这一层的实现。\nHSF调用过程的简述：\n调用链路从客户端发起调用开始，经历了客户端的选址和负载均衡后，将参数对象完成序列化，经过框架协议编码后，通过网络层发送出去。服务端接受到数据后进行解码，解码获得的二进制协议派发到服务端线程完成反序列化，生成出参数对象，最终通过反射完成调用。\nIO收到网络请求后，通过Frame进行协议解析获得RequestPacket，分派给ThreadPool中的业务线程处理请求，业务线程通过RequestPacket调用Serialize反序列化请求参数等信息，返回Invocation给调用链InvocationHandler发起调用，最终反射调用业务实例ServiceInstance的方法获得业务响应后，框架将其包装为RpcResult后返回给客户端。\n4. 对比dubbo / SpringCloudHSF搭配Config Server、Diamon和Redis已经实现了微服务架构的各种基本功能。Dubbo支持使用Zoopkeeper、Nacos和Redis作为注册中心Spring Cloud ：注册 + springmvc + 一系列组件 = springcloud\n\n服务调用\n\n\nHSF: RPC（也支持HTTP）\nDubbo: RPC\nSpring Clond: Http\n\n\n服务注册：\n\n\nHSF: Config Server\nDubbo: Zookeeper\n\n\n服务监控:\n\n\nHSF: HSFOPS http://hsf.alibaba.net/\nDubbo: Dubbo admin\n\n\n服务治理：\n\n\nHSF: 提供服务查询；服务治理；服务测试等功能\nDubbo:  早期的Dubbo本身是一个RPC框架\n\n5. HSF 带着问题学习\n调用如何进行拦截和处理？\n调用如何在一批地址列表上进行路由选择？\n调用如何在给定的地址列表上选择一个？\n调用如何完成序列化？\n序列化后的二进制内容如何被发送到服务端？\n服务端如何解码调用请求？\n服务端如何分派线程处理请求？\n服务端如何反序列化请求，将其还原？\n服务端如何根据调用语义完成调用执行？\n\n5.1 序列化对比RPC流程中，序列化是开销很大的环节。尤其现在业务对象都很复杂，序列化开销更不容小觑。HSF内部集成了一些序列化方式，序列化的工具有很多，一般来说序列化后的尺寸越小，网络传输的代价就越小，但是兼容性会随之降低。目前HSF2主要用到3类序列化方式，分别是java，hessian1，hessian2\n\nJava原生序列化：将类信息用字符串的形式全量的写入二进制流，来粗暴的实现序列化。这是比较极端和稳妥的方式，效率低，但不会出错\nhessian：传递元数据和值数据，前者即即类全名，字段名；后者是各个字段对应值。 在hessian1协议里，每次写出Class A的实例时，都会写出Class A的元数据和值数据，就是会重复传输相同的元数据；HSF使用的hessian2协议中实现了跨请求元数据共享，这样只要发送过一次元数据，以后就再也不用发送了，进一步减少传输的数据量。如果要增加HSF的序列化协议，就需要扩展实现  com.taobao.hsf.io.serialize 接口即可。\n\n5.2 RPC协议效率对比协议在HSF框架中主要体现在应用层，框架定义了一种私有的RPC协议，精心设计工作在4层的私有协议，相比于工作在7层上的协议效率更高。\nDubbo框架同样使用了工作与4层的RPC协议，但是使用相同的序列化方法，Dubbo协议的请求长度是要大于HSF协议长度\n通过实验对比一下：\n针对服务com.alibaba.OrderService:1.0.0调用方法queryOrder，参数是Long，使用相同Hessian2序列化方式，Dubbo协议的请求长度是188，而HSF协议长度是98\n针对自定义参数对象ModifyOrderPriceParam，Dubbo协议的请求长度是365，而HSF协议长度是268，可以看到随着数据量提升，二者差距变得小了一些。\n如果后续要想扩展协议，只需要继承  com.taobao.hsf.protocol.AbstractDelegateProtocolInterceptor 抽象类即可\n5.3 负载均衡器HSF通常具备的负载均衡器有4中，分别是：随机、权重、一致性哈希和轮询，其中运行效率较高的是也是默认采用随机，将用户的请求反向代理到一个具体的服务提供者上。如果想自定义负载均衡器，只需要实现LoadBalancer接口 即可案例 ：该负载均衡器会选择ip地址以172开头的服务器\npublic class TargetLoadBalance implements LoadBalancer &#123;    @Override    public ServiceURL select(List&lt;ServiceURL&gt; addresses, Invocation invocation) &#123;        for (ServiceURL serviceURL : addresses) &#123;            if (serviceURL.getHost().startsWith(&quot;172&quot;)) &#123;                return serviceURL;            &#125;        &#125;        return null;    &#125;    @Override    public boolean accept(Invocation invocation) &#123;        return true;    &#125;&#125;\n\n5.4 HSF 网络层HSF2.2 之后的网络层中只有一个最基础的抽象Stream，它代表着一个通道，连接两点之间，使其能够相互通信，完成p2p连接的工作；由于客户端需要发起心跳（实现长连接保活），且写出数据后要得到返回，因此根据客户端和服务端的不同，在Stream的基础上，抽象出了ClientStream和ServerStream。除了流之外，HSF还围绕网络事件的不同类型、客户端与服务端的不同特性定义了4种监听器    ‒ ClientStreamLifecycleListener 客户端连接生命周期监听器 （管理客户端的连接）    ‒ ClientStreamMessageListener 客户端连接消息监听器 （从客户端的连接中读数据）    ‒ ServerStreamLifecycleListener 服务端连接生命周期监听器 （绑定、建立和管理服务端端连接）    ‒ ServerStreamMessageListener 服务端连接消息监听器 （向连接写入数据）如何对HSF网络层进行扩展呢？比如想要对连接进行计数操作：只需要实现一个自定义的ClientStreamLifecycleListener，可以通过继承ClientStreamLifecycleListenerAdapter来实现\npublic class ClientConnNumStats extends ClientStreamLifecycleListenerAdapter &#123;    @Override    public void connectSuccess(Client client, ClientStream stream) &#123;        // 连接计数器加一        RemotingRuntimeInfoHolder.getInstance().increaseCountConnectionsAsClient();    &#125;    @Override    public void close(Client client, ClientStream stream) &#123;        //减一        RemotingRuntimeInfoHolder.getInstance().decreaseCountConnectionsAsClient();    &#125;&#125;\n5.5 HSF对调用进行拦截和处理为了对RPC进行扩展，实现调用记录、流量控制、调用的路由等功能，需要对调用过程添加interceptor如下是对调用扩展的接口定义：该接口能够将用户扩展逻辑嵌在HSF调用链中。\n@Scope(Scope.Option.PROTOTYPE)public interface RPCFilter &#123;\tListenableFuture&lt;RPCResult&gt; invoke(InvocationHandler nextHandler, Invocation invocation) throws Throwable;    void onResponse(Invocation invocation, RPCResult rpcResult);&#125;\n对于一次调用，发起请求阶段会经过RPCFilter.invoke方法，它能拦截住HSF的请求。当请求发送到远端完成处理之后，数据被写回，当响应到客户端后，将会调用RPCFilter.onResponse方法，因为请求Invocation在发起后会被记录，所以处理响应的线程会拿着当次调用的请求Invocation和远端的响应RPCResult调用RPCFilter.onResponse方法即可。\n下面是一个对Filter进行扩展的实例：首先要明确究竟是扩展客户端还是服务端，因为这二者是不一样的子接口（ServerFilter/ClientFilter）。\n@Order(300)public class HSFServerFilter implements ServerFilter &#123;    public ListenableFuture&lt;RPCResult&gt; invoke(InvocationHandler invocationHandler,                                              Invocation invocation) throws Throwable &#123;        //process args        String[] sigs = invocation.getMethodArgSigs();        Object[] args = invocation.getMethodArgs();        System.out.println(&quot;#### intercept request&quot;);        return invocationHandler.invoke(invocation);    &#125;    public void onResponse(Invocation invocation, RPCResult rpcResult) &#123;        System.out.println(&quot;#### intercept response&quot;);        Object resp = rpcResult.getAppResponse();        System.out.println(resp);    &#125;&#125;\n之后RPCFilter会整合到调用处理器（InvocationHandler）链中，这一功能是由FilterInvocationHandler调用RPCFilterBuilder来构造RPCFilter的调用链来实现，该链的结构如下所示：\n+--------------------------------------------------------------------------------+|           com.taobao.hsf.invocation.filter.RPCFilterBuilder$HeadNode           |+--------------------------------------------------------------------------------+          |                                                            ^          v                                                            |+--------------------------------------------------------------------------------+|                 com.taobao.hsf.rpc.server.ServiceAbsenceFilter                 |+--------------------------------------------------------------------------------+          |                                                            ^          v                                                            |+--------------------------------------------------------------------------------+|         com.alibaba.middleware.hsf.guide.serverfilter.HSFServerFilter          |+--------------------------------------------------------------------------------+          |                                                            ^          v                                                            |+--------------------------------------------------------------------------------+|            com.taobao.hsf2dubbo.context.DubboRPCContextServerFilter            |+--------------------------------------------------------------------------------+          |                                                            ^          v                                                            |+--------------------------------------------------------------------------------+|           com.taobao.hsf.invocation.filter.RPCFilterBuilder$TailNode           |+--------------------------------------------------------------------------------+\n"},{"title":"阿里巴巴编码规范（Java）","url":"/2021/08/06/%E5%90%8E%E7%AB%AF/AlibabaCodeFormat/","content":"编程规约注释注释规范1. 类、类属性、类方法的注释必须使用Javadoc规范，使用/**内容*/格式，不得使用// xxx方式\n2. 所有的抽象方法（包括接口中的方法）必须要用Javadoc注释、除了返回值、参数、异常说明外，还必须指出该方法做什么事情，实现什么功能\n3. 所有的类都必须添加创建者和创建日期\n4. 方法内部单行注释，在被注释语句上方另起一行，使用//注释。方法内部多行注释使用/* */注释，注意与代码对齐\n5. 所有的枚举类型字段必须要有注释，说明每个数据项的用途\n6. 与其“半吊子”英文来注释，不如用中文注释把问题说清楚。专有名词与关键字保持英文原文即可。\n7. 代码修改的同时，注释也要进行相应的修改，尤其是参数、返回值、异常、核心逻辑等的修改\n8. 谨慎注释掉代码。在上方详细说明，而不是简单地注释掉。如果无用，则删除。\n9. 对于注释的要求：第一、能够准确反映设计思想和代码逻辑；第二、能够描述业务含义，使别的程序员能够迅速了解到代码背后的信息。完全没有注释的大段代码对于阅读者形同天书，注释是给自己看的，即使隔很长时间，也能清晰理解当时的思路；注释也是给继任者看的，使其能够快速接替自己的工作。\n10. 好的命名、代码结构是自解释的，注释力求精简准确、表达到位。避免出现注释的一个极端：过多过滥的注释，代码的逻辑一旦修改，修改注释是相当大的负担\n11. 特殊注释标记，请注明标记人与标记时间。注意及时处理这些标记，通过标记扫描，经常清理此类标记。线上故障有时候就是来源于这些标记处的代码\n\n文案规范\n中文文案排版指北\n写给大家看的中文排版指南\n\n单行注释\n注释内容与左侧的双斜线之间保留一个空格// good comment//  bad comment//bad comment\n\n文档注释\n标准的文档注释写法为 /** … */，一定要避免将其与多行注释混淆/** * good comment *//* * bad comment */\n方法描述与左侧的 * 号之间保留一个空格，与下方的参数 / 返回 / 异常说明之间保留一个空行/** * good comment * * @param id * @return * @throws *//** *bad comment * @param id * @return * @throws */\n命名风格1. 代码命名不能以下划线或者美元符号开头或者结尾2. 代码命名不能以中文拼音或者中文拼音与英文混合方式3. 类名使用UpperCamCamelCase风格，但DO、PO、DTO、VO、BO等除外4. 方法名、参数名、变量名统一使用lowerCamelCase，必须遵守驼峰命名5. 常量名全部大写，单词间用下划线隔开6. 抽象类必须以Abstract或者Base开头，异常类必须以Exception结尾，测试类以测试的类的名称开头Test结尾7. 类型与中括号紧挨相连标示数组8. POJO类中布尔类型变量不要加is前缀9. 包名统一小写，点分隔符有且有一个自然语义单词10. 避免在父子类和不同代码块中采用相同变量名11. 避免不规范的缩写命名12. 在对元素命名时用完整单词组合表达其意13. 常量和变量命名时，表示类型放在词尾，如：idList、TERMINATED_TREAD_COUNT14. 接口、类、方法、模块使用设计模式，命名时要体现具体模式15. 接口类中的方法和属性不要加任何修饰符，并加上有效的javadoc。16. 接口和实现类的命名规则：    1、对于service和dao类，实现类必须用Impl结尾；    2、如果是形容能力的接口名称，取对应的形容词为接口名 AbstractTranslator实现 Translatable接口17. 枚举类名加Enum后缀，枚举成员名称全大写，单词间用下划线隔开18. 各层命名规范：    A) Service/DAO层命名规约        1.获取单个对象的方法用get做前缀        2.获取多个对象的方法用list做前缀，如：listObjects        3.获取统计值的方法用count做前缀        4.插入方法用save/insert做前缀        5.删除方法用delete/remove做前缀        6.修改方法用update做前缀    B）领域模型命名规范        1.数据对象：xxxDO, xxx为数据库表名        2.数据传输对象：xxxDTO,xxx为业务模型相关名称        3.展示对象：xxxVO，xxx一般为网页名称        4.POJO是对DO、DTO、VO、BO的统称，禁止xxxPOJO\n常量定义1. 代码中禁止出现魔法值2. 在Long类型中赋值，数值后使用大写L3. 不要在一个常量类中维护所有常量，要根据功能分开维护4. 常量的复用层次：    1.跨应用：放在二方库中，通常在constant目录下    2.应用内：放在一方库中，通常在constant目录下    3.子工程内：放在当前子工程constant目录下    4.包内共享常量：当前包下单独的constant目录下    5.类内共享常量：直接在类内部private static final定义5. 如果变量值只在固定的范围内变化，用enum类型定义\n代码格式1. 如果大括号代码为空直接&#x27;&#123;&#125;&#x27;,大括号内有代码则：左大括号左侧不换行，右侧换行；右大括号右侧换行，左侧如果不跟else等代码换行，否则不换行2. 小括号和字符之间不能有空格，括号内字符和运算符之间有空格 如：if (a == b)3. if、for、while、do、switch与括号之间必须有空格4. 任何二目、三目运算符前后必须有空格5. 采用4个空格，禁止使用tab6. 注释的双斜线和内容要有空格7. 强制类型转换时，右括号与强制转换值之间不用空格8. 单行字符不超过120个，超过要换行9. 方法在定义和传参时，必须要加空格10. IDE的text file encoding 设置为UTF-8；IDE中 文件的换行符使用Unix格式11. 单个方法尽量不超过80行12. 不同逻辑、不同语义、不同业务之间的代码插入一个空行分隔符\nOOP规约1. 不用一个类型的对象引用来访问静态方法和静态属性，直接类名访问即可2. 所有覆写方法，必须加@Override注解3. 相同业务含义，相同参数类型才能使用java可变参数4. 外部依赖或者二方库依赖的接口，不能修改方法签名。接口过时必须用@Deprecated 注解，并说明新接口或者新服务是什么5. 不能使用过时的类或者方法6.  Object的equals方法容易抛出空指针，应使用常量或者确定值的对象来调用equals7. 所有整型包装类之间的值比较都用equals 方法比较8. 浮点数之间的等值判断，基本类型不能用==，包装类不能用equals。    解决方案：(1) 指定一个误差范围，两个浮点数的差值在此范围之内，则认为是相等的。            (2) 使用BigDecimal来定义值，再进行浮点数的运算操作。9. 定义DO类时，属性类型要数据库字段类型相匹配10. 防止精度丢失，禁止使用BigDecimal(double)方式将double对象转换成BigDecimal。建议使用BigDecimal的valueOf方法11. 基本类型和包装类型的使用标准    1.所有POJO的属性必须用包装类型    2.RPC方法的参数和返回值必须使用包装类型    3.所有局部变量使用基本变量12. 所有POJO 不要对其属性设置默认值13. 序列化类新增时不要修改其serialVersionUID字段14. 构造方法里禁止加任何业务处理逻辑，有要加在init()15. POJO类必须要写toString方法16. 禁止在POJO类中对属性xxx 同时存在isXxx()和getXxx()17. 使用索引访问用String的split方法得到数组时，需要对最后一个分隔符有无内容做检查18.   一个类有多个构造方法或者多个同名方法，要按照顺序来。19. 类中的方法顺序 ：共有方法-&gt; 私有方法 -&gt; get/set20. setter方法中参数名称和成员变量名称一致，不要在getter和setter方法中加业务逻辑21. 循环体内用StringBuilder的append方法进行扩展22. final可以修饰类，方法，变量。23. 慎用Object的clone方法24. 类成员与方法访问控制从严    1） 如果不允许外部直接通过new来创建对象，那么构造方法必须是private。         2） 工具类不允许有public或default构造方法。    3） 类非static成员变量并且与子类共享，必须是protected。    4） 类非static成员变量并且仅在本类使用，必须是private。    5） 类static成员变量如果仅在本类使用，必须是private。     6） 若是static成员变量，考虑是否为final。    7） 类成员方法只供类内部调用，必须是private。     8） 类成员方法只对继承类公开，那么限制为protected。\n集合处理1. hashCode和equals 的处理遵循以下规则：    1）只要覆写equals ，就必须要覆写hashCode    2）因为Set存储的是不重复的对象，依据hashCode和equals进行判断，所以Set存储的对象必须覆写这两个方法。    3）如果自定义对象作为Map的键，那么必须覆写hashCode和equals。2. ArrayList的subList结果不能强转ArrayList。3. 使用map的keySet()、values()、entrySet()方法返回对象后不可以对其进行添加元素的操作4. Collections类返回的对象，如：emptyList()/singletonList()等都是immutablelist不可对其进行添加或者删除元素的操作5. 在subList场景中，高度注意对原集合元素的增加或删除，均会导致子列表的遍历、增加、删除产生ConcurrentModificationException 异常6. 使用集合转数组的方法，必须使用集合的toArray(T[] array)，传入的是类型完全一致、长度为0的空数组7. 在使用Collection接口任何实现类的addAll()方法时，一定要对输入的集合做NEP判断8. 使用工具类Arrays.asList()把数组转换成集合时，不能使用其修改集合相关的方法，它的add/remove/clear方法会抛出UnsupportedOperationException异常    说明：asList的返回对象是一个Arrays内部类，并没有实现集合的修改方法。Arrays.asList体现的是适配器模式，只是转换接口，后台的数据仍是数组。9. 泛型通配符&lt;? extends T&gt;来接收返回的数据，此写法的泛型集合不能使用add方法，而&lt;? super T&gt;不能使用get方法，作为接口调用赋值时易出错10. 在无泛型限制定义的集合赋值给泛型限制的集合时，在使用集合元素时，需要进行instanceof判断，避免抛出ClassCastException异常11. 不要在foreach循环里进行元素的remove/add操作。remove元素请使用Iterator方式，如果并发操作，需要对Iterator对象加锁12. 在JDK7 版本及以上，Comparator 实现类要满足如下三个条件，不然Arrays.sort，Collections.sort 会抛IllegalArgumentException 异常。    说明：三个条件如下    1） x，y 的比较结果和y，x 的比较结果相反。    2） x&gt;y，y&gt;z，则x&gt;z。    3） x=y，则x，z 比较结果和y，z 比较结果相同。13. 集合泛型定义时，在JDK7 及以上，使用diamond 语法或全省略。14. 集合初始化时，指定集合初始值大小。15. 使用entrySet 遍历Map 类集合KV，而不是keySet 方式进行遍历16. 高度注意Map类集合K/V能不能存储null值的情况，如下表格：17. 合理利用好集合的有序性(sort)和稳定性(order)，避免集合的无序性(unsort)和不稳定性(unorder)带来的负面影响。18. 利用Set元素唯一的特性，可以快速对一个集合进行去重操作，避免使用List的contains方法进行遍历、对比、去重操作\n\n\n\n集合类\nKey\nValue\nSuper\n说明\n\n\n\nHashTable\n不允许为null\n不允许为null\nDictionary\n线程安全\n\n\nConcurrentHashMap\nHashTable\n不允许为null\n不允许为null\nAbstractMap\n\n\nTreeMap\n不允许为null\n允许为null\nAbstractMap\n线程不安全\n\n\nHashMap\n允许为null\n允许为null\nAbstractMap\n线程不安全\n\n\n\n\n并发处理1. 获取单例对象需要保证线程安全，其中的方法也要保证线程安全。2. 创建线程或线程池时请指定有意义的线程名称，方便出错时回溯。3. 线程资源必须通过线程池提供，不允许在应用中自行显式创建线程4. 线程池不允许使用Executors去创建，而是通过ThreadPoolExecutor的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险5. SimpleDateFormat 是线程不安全的类，一般不要定义为static变量，如果定义为static，必须加锁，或者使用DateUtils工具类。6. 必须回收自定义的ThreadLocal变量，尤其在线程池场景下，线程经常会被复用，如果不清理自定义的 ThreadLocal变量，可能会影响后续业务逻辑和造成内存泄露等问题。尽量在代理中使用try-finally块进行回收7. 高并发时，同步调用应该去考量锁的性能损耗。能用无锁数据结构，就不要用锁；能锁区块，就不要锁整个方法体；能用对象锁，就不要用类锁8. 对多个资源、数据库表、对象同时加锁时，需要保持一致的加锁顺序，否则可能会造成死锁。9. 在使用阻塞等待获取锁的方式中，必须在try代码块之外，并且在加锁方法与try代码块之间没有任何可能抛出异常的方法调用，避免加锁成功后，在finally中无法解锁。10. 在使用尝试机制来获取锁的方式中，进入业务代码块之前，必须先判断当前线程是否持有锁。锁的释放规则与锁的阻塞等待方式相同11. 并发修改同一记录时，避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存加锁，要么在数据库层使用乐观锁，使用version作为更新依据12. 多线程并行处理定时任务时，Timer运行多个TimeTask时，只要其中之一没有捕获抛出的异常，其它任务便会自动终止运行，如果在处理定时任务时使用ScheduledExecutorService则没有这个问题13. 资金相关的金融敏感信息，使用悲观锁策略14. 使用CountDownLatch进行异步转同步操作，每个线程退出前必须调用countDown方法，线程执行代码注意catch异常，确保countDown方法被执行到，避免主线程无法执行至await方法，直到超时才返回结果15. 避免Random实例被多线程使用，虽然共享该实例是线程安全的，但会因竞争同一seed 导致的性能下降16. 在并发场景下，通过双重检查锁（double-checked locking）实现延迟初始化的优化问题隐患(可参考 The &quot;Double-Checked Locking is Broken&quot; Declaration)，推荐解决方案中较为简单一种（适用于JDK5及以上版本），将目标属性声明为 volatile型17. volatile解决多线程内存不可见问题。对于一写多读，是可以解决变量同步问题，但是如果多写，同样无法解决线程安全问题。18. HashMap在容量不够进行resize时由于高并发可能出现死链，导致CPU飙升，在开发过程中可以使用其它数据结构或加锁来规避此风险19. ThreadLocal对象使用static修饰，ThreadLocal无法解决共享对象的更新问题\n控制语句1. 在一个switch块内，每个case要么通过continue/break/return等来终止，要么注释说明程序将继续执行到哪一个case为止；在一个switch块内，都必须包含一个default语句并且放在最后，即使它什么代码也没有2. 当switch括号内的变量类型为String并且此变量为外部参数时，必须先进行null判断3. 在if/else/for/while/do语句中必须使用大括号4. 在高并发场景中，避免使用”等于”判断作为中断或退出的条件5. 表达异常的分支时，少用if-else方式6. 除常用方法（如getXxx/isXxx）等外，不要在条件判断中执行其它复杂的语句，将复杂逻辑判断的结果赋值给一个有意义的布尔变量名，以提高可读性7. 不要在其它表达式（尤其是条件表达式）中，插入赋值语句8. 循环体中的语句要考量性能，以下操作尽量移至循环体外处理，如定义对象、变量、获取数据库连接，进行不必要的try-catch操作（这个try-catch是否可以移至循环体外）。9. 避免采用取反逻辑运算符10. 接口入参保护，这种场景常见的是用作批量操作的接口11. 下列情形，需要进行参数校验：     1） 调用频次低的方法。    2） 执行时间开销很大的方法。此情形中，参数校验时间几乎可以忽略不计，但如果因为参数错误导致 中间执行回退，或者错误，那得不偿失。    3） 需要极高稳定性和可用性的方法。     4） 对外提供的开放接口，不管是RPC/API/HTTP接口。    5） 敏感权限入口。12. 下列情形，不需要进行参数校验：    1） 极有可能被循环调用的方法。但在方法说明里必须注明外部参数检查要求。     2） 底层调用频度比较高的方法。毕竟是像纯净水过滤的最后一道，参数错误不太可能到底层才会暴露问题。一般DAO层与Service层都在同一个应用中，部署在同一台服务器中，所以DAO的参数校验，可以省略。    3） 被声明成private只会被自己代码所调用的方法，如果能够确定调用方法的代码传入参数已经做过检查或者肯定不会有问题，此时可以不校验参数。\n其他1. 在使用正则表达式时，利用好其预编译功能，可以有效加快正则匹配速度2. velocity调用POJO类的属性时，直接使用属性名取值即可，模板引擎会自动按规范调用POJO的getXxx()，如果是boolean基本数据类型变量（boolean命名不需要加is前缀），会自动调用isXxx()方法3. 后台输送给页面的变量必须加$!&#123;var&#125;——中间的感叹号4. 注意 Math.random() 这个方法返回是double类型，注意取值的范围 0≤x&lt;1（能够取到零值，注意除零异常），如果想获取整数类型的随机数，不要将x放大10的若干倍然后取整，直接使用Random对象的nextInt或者nextLong方法5. 获取当前毫秒数System.currentTimeMillis(); 而不是new Date().getTime();6. 日期格式化时，传入pattern中表示年份统一使用小写的y7. 不要在视图模板中加入任何复杂的逻辑8. 任何数据结构的构造或初始化，都应指定大小，避免数据结构无限增长吃光内存9. 及时清理不再使用的代码段或配置信息\n异常日志异常处理1. java类库中定义的可以通过预检查方式规避的RuntimeException异常不应该通过catch方式处理。如NullPointException、IndexOutOfBoundsException。2. 异常不要用作流程控制、条件控制。3. catch是要分清是稳定代码和非稳定代码，对于非稳定代码catch尽可能的按照异常类型分类。4. 捕获异常一定要做处理，如果不想处理就抛给上层调用者。5. 有try块放在事务中，catch异常后如果需要回滚事务，一定要注意手动回滚事务。6. finally块中必须对资源对象、流对象进行关闭，有异常也要catch。7. 不要在finally块中使用return8. 捕获的异常要和抛的异常匹配或者捕获的异常是抛异常的父类9. 在调用RPC、二方包、或动态生成类的相关方法时，捕获异常一定要用Throwable类拦截10. 方法的返回值可以是null，但是必须要说明什么情况返回null11. 防止NEP：    1. 返回类型是基本类型 ，return包装类型的对象。    2. 数据库查询的结果可能是null    3. 集合里的元素即时isNotEmpty，取出来的元素也可能是null    4. 远程调用返回对象时，必须要进行判空处理    5. 对于Session中的数据要进行判空处理    6. 级联调用有可能产生空指针12. 定义时区分unchecked / checked 异常，避免直接抛出new RuntimeException()，更不允许抛出Exception或者Throwable，应使用有业务含义的自定义异常。推荐业界已定义过的自定义异常，如：DAOException / ServiceException等13. 对于公司外的http/api开放接口必须使用“错误码”；而应用内部推荐异常抛出；跨应用间RPC调用优先考虑使用Result方式，封装isSuccess()方法、“错误码”、“错误简短信息”14. 避免出现重复的代码（Don&#x27;t Repeat Yourself），即DRY原则\n\n日志规约1. 应用中不可直接使用日志系统（Log4j、Logback）中的API，而应依赖使用日志框架 SLF4J中的API，使用门面模式的日志框架，有利于维护和各个类的日志处理方式统一2. 所有日志文件至少保存15天，因为有些异常具备以“周”为频次发生的特点。网络运行状态、安全相关信息、系统监测、管理后台操作、用户敏感操作需要留存相关的网络日志不少于6个月3. 应用中的扩展日志（如打点、临时监控、访问日志等）命名方式：appName_logType_logName.log。logType:日志类型，如stats/monitor/access等；logName:日志描述。这种命名的好处：通过文件名就可知道日志文件属于什么应用，什么类型，什么目的，也有利于归类查找4. 在日志输出时，字符串变量之间的拼接使用占位符的方式5. 对于trace/debug/info级别的日志输出，必须进行日志级别的开关判断6. 避免重复打印日志，浪费磁盘空间，务必在log4j.xml中设置additivity=false7. 异常信息应该包括两类信息：案发现场信息和异常堆栈信息。如果不处理，那么通过关键字throws往上抛出8. 谨慎地记录日志。生产环境禁止输出debug日志；有选择地输出info日志；如果使用warn来记录刚上线时的业务行为信息，一定要注意日志输出量的问题，避免把服务器磁盘撑爆，并记得及时删除这些观察日志9.  可以使用warn日志级别来记录用户输入参数错误的情况，避免用户投诉时，无所适从。如非必要，请不要在此场景打出error级别，避免频繁报警10. 尽量用英文来描述日志错误信息，如果日志中的错误信息用英文描述不清楚的话使用中文描述即可，否则容易产生歧义。【强制】国际化团队或海外部署的服务器由于字符集问题，使用全英文来注释和描述日志错误信息\n\n单元测试1. 好的单元测试必须遵守AIR原则2. 单元测试应该是全自动执行的，并且非交互式的。测试用例通常是被定期执行的，执行过程必须完全自动化才有意义。输出结果需要人工检查的测试不是一个好的单元测试。单元测试中不准使用System.out来进行人肉验证，必须使用assert来验证3. 保持单元测试的独立性。为了保证单元测试稳定可靠且便于维护，单元测试用例之间决不能互相调用，也不能依赖执行的先后次序4. 单元测试是可以重复执行的，不能受到外界环境的影响5. 对于单元测试，要保证测试粒度足够小，有助于精确定位问题。单测粒度至多是类级别，一般是方法级别6. 核心业务、核心应用、核心模块的增量代码确保单元测试通过7. 单元测试代码必须写在如下工程目录：src/test/java，不允许写在业务代码目录下8. 单元测试的基本目标：语句覆盖率达到70%；核心模块的语句覆盖率和分支覆盖率都要达到100%9. 编写单元测试代码遵守BCDE原则，以保证被测试模块的交付质量10. 对于数据库相关的查询，更新，删除等操作，不能假设数据库里的数据是存在的，或者直接操作数据库把数据插入进去，请使用程序插入或者导入数据的方式来准备数据11. 和数据库相关的单元测试，可以设定自动回滚机制，不给数据库造成脏数据。或者对单元测试产生的数据有明确的前后缀标识12. 对于不可测的代码在适当的时机做必要的重构，使代码变得可测，避免为了达到测试要求而书写不规范测试代码13. 在设计评审阶段，开发人员需要和测试人员一起确定单元测试范围，单元测试最好覆盖所有测试用例14. 单元测试作为一种质量保障手段，在项目提测前完成单元测试，不建议项目发布后补充单元测试用例15. 为了更方便地进行单元测试，业务代码应避免以下情况： 1.构造方法中做的事情过多。 2. 存在过多的全局变量和静态方法。 3. 存在过多的外部依赖。 4. 存在过多的条件语句16. 那是测试同学干的事情。本文是开发手册，凡是本文内容都是与开发同学强相关的。 1. 单元测试代码是多余的。系统的整体功能与各单元部件的测试正常与否是强相关的。 2. 单元测试代码不需要维护。一年半载后，那么单元测试几乎处于废弃状态。 3. 单元测试与线上故障没有辩证关系。好的单元测试能够最大限度地规避线上故障\n\n安全规约1. 隶属于用户个人的页面或者功能必须进行权限控制校验2. 用户敏感数据禁止直接展示，必须对展示数据进行脱敏3. 用户输入的SQL参数严格使用参数绑定或者METADATA字段值限定，防止SQL注入，禁止字符串拼接SQL访问数据库4. 用户请求传入的任何参数必须做有效性验证5. 禁止向HTML页面输出未经安全过滤或未正确转义的用户数据6. 表单、AJAX提交必须执行CSRF安全验证7. 在使用平台资源，譬如短信、邮件、电话、下单、支付，必须实现正确的防重放的机制，如数量限制、疲劳度控制、验证码校验，避免被滥刷而导致资损8. 发贴、评论、发送即时消息等用户生成内容的场景必须实现防刷、文本内容违禁词过滤等风控策略\n\nMySQL数据库建表规约1. 表达是与否概念的字段，必须使用is_xxx的方式命名，数据类型是unsigned tinyint（1表示是，0表示否）2. 表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下划线中间只出现数字。数据库字段名的修改代价很大，因为无法进行预发布，所以字段名称需要慎重考虑3. 表名不使用复数名词4. 禁用保留字，如desc、range、match、delayed等，请参考MySQL官方保留字5. 主键索引名为pk_字段名；唯一索引名为uk_字段名；普通索引名则为idx_字段名6. 小数类型为decimal，禁止使用float和double7. 如果存储的字符串长度几乎相等，使用char定长字符串类型8. varchar是可变长字符串，不预先分配存储空间，长度不要超过5000，如果存储长度大于此值，定义字段类型为text，独立出来一张表，用主键来对应，避免影响其它字段索引效率9. 表必备三字段：id, create_time, update_time10. 表的命名最好是遵循“业务名称_表的作用”11. 库名与应用名称尽量一致12. 字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循： 1） 不是频繁修改的字段。 2） 不是varchar超长字段，更不能是text字段。3） 不是唯一索引的字段。13. 如果修改字段含义或对字段表示的状态追加时，需要及时更新字段注释14. 单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表15. 合适的字符存储长度，不但节约数据库表空间、节约索引存储，更重要的是提升检索速度\n\n索引规约1. 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引2. 超过三个表禁止join。需要join的字段，数据类型必须绝对一致；多表关联查询时，保证被关联的字段需要有索引3. 在varchar字段上建立索引时，必须指定索引长度，没必要对全字段建立索引，根据实际文本区分度决定索引长度即可4. 页面搜索严禁左模糊或者全模糊，如果需要请走搜索引擎来解决5. 如果有order by的场景，请注意利用索引的有序性。order by 最后的字段是组合索引的一部分，并且放在索引组合顺序的最后，避免出现file_sort的情况，影响查询性能6. 利用覆盖索引来进行查询操作，避免回表7. 利用延迟关联或者子查询优化超多分页场景8. SQL性能优化的目标：至少要达到 range 级别，要求是ref级别，如果可以是consts最好9. 建组合索引的时候，区分度最高的在最左边10. 防止因字段类型不同造成的隐式转换，导致索引失效11. 创建索引时避免有如下极端误解： 1） 宁滥勿缺。认为一个查询就需要建一个索引。 2） 宁缺勿滥。认为索引会消耗空间、严重拖慢记录的更新以及行的新增速度。 3） 抵制惟一索引。认为业务的惟一性一律需要在应用层通过“先查后插”方式解决。\n\nSQL语句1. 不要使用count(列名)或count(常量)来替代count(*)，count(*)是SQL92定义的标准统计行数的语法，跟数据库无关，跟NULL和非NULL无关2. count(distinct col) 计算该列除NULL之外的不重复行数，注意 count(distinct col1, col2) 如果其中一列全为NULL，那么即使另一列有不同的值，也返回为03. 当某一列的值全是NULL时，count(col)的返回结果为0，但sum(col)的返回结果为NULL，因此使用sum()时需注意NPE问题4. 使用ISNULL()来判断是否为NULL值5. 代码中写分页查询逻辑时，若count为0应直接返回，避免执行后面的分页语句6. 不得使用外键与级联，一切外键概念必须在应用层解决7. 禁止使用存储过程，存储过程难以调试和扩展，更没有移植性8. 数据订正（特别是删除、修改记录操作）时，要先select，避免出现误删除，确认无误才能执行更新语句9. in操作能避免则避免，若实在避免不了，需要仔细评估in后边的集合元素数量，控制在1000个之内10. 如果有国际化需要，所有的字符存储与表示，均以utf-8编码，注意字符统计函数的区别11. TRUNCATE TABLE 比 DELETE 速度快，且使用的系统和事务日志资源少，但TRUNCATE无事务且不触发trigger，有可能造成事故，故不建议在开发代码中使用此语句\n\nORM映射1. 在表查询中，一律不要使用 * 作为查询的字段列表，需要哪些字段必须明确写明2. POJO类的布尔属性不能加is，而数据库字段必须加is_，要求在resultMap中进行字段与属性之间的映射3. 不要用resultClass当返回参数，即使所有类属性名与数据库字段一一对应，也需要定义；反过来，每一个表也必然有一个POJO类与之对应4. sql.xml配置参数使用：#&#123;&#125;，#param# 不要使用$&#123;&#125; 此种方式容易出现SQL注入5. iBATIS自带的queryForList(String statementName,int start,int size)不推荐使用6. 不允许直接拿HashMap与Hashtable作为查询结果集的输出7. 更新数据表记录时，必须同时更新记录对应的gmt_modified字段值为当前时间8. 不要写一个大而全的数据更新接口。传入为POJO类，不管是不是自己的目标更新字段，都进行update table set c1=value1,c2=value2,c3=value3; 这是不对的。执行SQL时，不要更新无改动的字段，一是易出错；二是效率低；三是增加binlog存储9. @Transactional事务不要滥用。事务会影响数据库的QPS，另外使用事务的地方需要考虑各方面的回滚方案，包括缓存回滚、搜索引擎回滚、消息补偿、统计修正等10. &lt;isEqual&gt;中的compareValue是与属性值对比的常量，一般是数字，表示相等时带上此条件；&lt;isNotEmpty&gt;表示不为空且不为null时执行；&lt;isNotNull&gt;表示不为null值时执行\n\n工程结构应用分层1. 图中默认上层依赖于下层，箭头关系表示可直接依赖，如：开放接口层可以依赖于Web层，也可以直接依赖于Service层，依此类推\n\n\n\n\n• 开放接口层：可直接封装Service方法暴露成RPC接口；通过Web封装成http接口；进行网关安全控制、流量控制等。• 终端显示层：各个端的模板渲染并执行显示的层。当前主要是velocity渲染，JS渲染，JSP渲染，移动端展示等。• Web层：主要是对访问控制进行转发，各类基本参数校验，或者不复用的业务简单处理等。• Service层：相对具体的业务逻辑服务层。• Manager层：通用业务处理层，它有如下特征： 1） 对第三方平台封装的层，预处理返回结果及转化异常信息。 2） 对Service层通用能力的下沉，如缓存方案、中间件通用处理。 3） 与DAO层交互，对多个DAO的组合复用。• DAO层：数据访问层，与底层MySQL、Oracle、Hbase等进行数据交互。• 外部接口或第三方平台：包括其它部门RPC开放接口，基础平台，其它公司的HTTP接口。\n2.（分层异常处理规约）在DAO层，产生的异常类型有很多，无法用细粒度的异常进行catch，使用catch(Exception e)方式，并throw new DAOException(e)，不需要打印日志，因为日志在Manager/Service层一定需要捕获并打印到日志文件中去，如果同台服务器再打日志，浪费性能和存储。在Service层出现异常时，必须记录出错日志到磁盘，尽可能带上参数信息，相当于保护案发现场。如果Manager层与Service同机部署，日志方式与DAO层处理一致，如果是单独部署，则采用与Service一致的处理方式。Web层绝不应该继续往上抛异常，因为已经处于顶层，如果意识到这个异常将导致页面无法正常渲染，那么就应该直接跳转到友好错误页面，加上用户容易理解的错误提示信息。开放接口层要将异常处理成错误码和错误信息方式返回。\n3. • DO（Data Object）：此对象与数据库表结构一一对应，通过DAO层向上传输数据源对象。\n    • DTO（Data Transfer Object）：数据传输对象，Service或Manager向外传输的对象。\n    • BO（Business Object）：业务对象，由Service层输出的封装业务逻辑的对象。\n    • AO（Application Object）：应用对象，在Web层与Service层之间抽象的复用对象模型，极为贴近展示层，复用度不高。\n    • VO（View Object）：显示层对象，通常是Web向模板渲染引擎层传输的对象。\n    • Query：数据查询对象，各层接收上层的查询请求。注意超过2个参数的查询封装，禁止使用Map类来传输。\n\n二方库依赖1.定义GAV遵从以下规则： 1） GroupID格式：com.&#123;公司/BU &#125;.业务线 [.子业务线]，最多4级。 说明：&#123;公司/BU&#125; 例如：alibaba/taobao/tmall/aliexpress等BU一级；子业务线可选。 正例：com.taobao.jstorm 或 com.alibaba.dubbo.register 2） ArtifactID格式：产品线名-模块名。语义不重复不遗漏，先到中央仓库去查证一下。 正例：dubbo-client / fastjson-api / jstorm-tool 3） Version：详细规定参考下方2. 二方库版本号命名方式：主版本号.次版本号.修订号 1）主版本号：产品方向改变，或者大规模API不兼容，或者架构不兼容升级。 2） 次版本号：保持相对兼容性，增加主要功能特性，影响范围极小的API不兼容修改。 3） 修订号：保持完全兼容性，修复BUG、新增次要功能特性等。3. 线上应用不要依赖SNAPSHOT版本（安全包除外）4. 二方库的新增或升级，保持除功能点之外的其它jar包仲裁结果不变。如果有改变，必须明确评估和验证5. 二方库里可以定义枚举类型，参数可以使用枚举类型，但是接口返回值不允许使用枚举类型或者包含枚举类型的POJO对象6. 依赖于一个二方库群时，必须定义一个统一的版本变量，避免版本号不一致7. 禁止在子项目的pom依赖中出现相同的GroupId，相同的ArtifactId，但是不同的Version8. 底层基础技术框架、核心数据管理平台、或近硬件端系统谨慎引入第三方实现9. 所有pom文件中的依赖声明放在&lt;dependencies&gt;语句块中，所有版本仲裁放在&lt;dependencyManagement&gt;语句块中10. 二方库不要有配置项，最低限度不要再增加配置项11.为避免应用二方库的依赖冲突问题，二方库发布者应当遵循以下原则：   1）精简可控原则。移除一切不必要的API和依赖，只包含 Service API、必要的领域模型对象、Utils类、常量、枚举等。如果依赖其它二方库，尽量是provided引入，让二方库使用者去依赖具体版本号；无log具体实现，只依赖日志框架。   2）稳定可追溯原则。每个版本的变化应该被记录，二方库由谁维护，源码在哪里，都需要能方便查到。除非用户主动升级版本，否则公共二方库的行为不应该发生变化。\n\n服务器1. 高并发服务器建议调小TCP协议的time_wait超时时间2. 调大服务器所支持的最大文件句柄数（File Descriptor，简写为fd）3. 给JVM环境参数设置-XX:+HeapDumpOnOutOfMemoryError参数，让JVM碰到OOM场景时输出dump信息4. 在线上生产环境，JVM的Xms和Xmx设置一样大小的内存容量，避免在GC 后调整堆大小带来的压力5. 服务器内部重定向使用forward；外部重定向地址使用URL拼装工具类来生成，否则会带来URL维护不一致的问题和潜在的安全风险\n\n设计规约1. 存储方案和底层数据结构的设计获得评审一致通过，并沉淀成为文档2. 在需求分析阶段，如果与系统交互的User超过一类并且相关的User Case超过5个，使用用例图来表达更加清晰的结构化需求3. 如果某个业务对象的状态超过3个，使用状态图来表达并且明确状态变化的各个触发条件4. 如果系统中某个功能的调用链路上的涉及对象超过3个，使用时序图来表达并且明确各调用环节的输入与输出5. 如果系统中模型类超过5个，并且存在复杂的依赖关系，使用类图来表达并且明确类之间的关系6. 如果系统中超过2个对象之间存在协作关系，并且需要表示复杂的处理流程，使用活动图来表示7. 需求分析与系统设计在考虑主干功能的同时，需要充分评估异常流程与业务边界8. 类在设计与实现时要符合单一原则9. 谨慎使用继承的方式来进行扩展，优先使用聚合/组合的方式来实现10. 系统设计时，根据依赖倒置原则，尽量依赖抽象类与接口，有利于扩展与维护11. 系统设计时，注意对扩展开放，对修改闭合12. 系统设计阶段，共性业务或公共行为抽取出来公共模块、公共配置、公共类、公共方法等，避免出现重复代码或重复配置的情况13. 避免如下误解：敏捷开发 = 讲故事 + 编码 + 发布14. 系统设计主要目的是明确需求、理顺逻辑、后期维护，次要目的用于指导编码15. 设计的本质就是识别和表达系统难点，找到系统的变化点，并隔离变化点16. 系统架构设计的目的：    1.确定系统边界。确定系统在技术层面上的做与不做。    2.确定系统内模块之间的关系。确定模块之间的依赖关系及模块的宏观输入与输出。    3.确定指导后续设计与演化的原则。使后续的子系统或模块设计在规定的框架内继续演化。    4.确定非功能性需求。非功能性需求是指安全性、可用性、可扩展性等17. 在做无障碍产品设计时，需要考虑到：    1. 所有可交互的控件元素必须能被tab键聚焦，并且焦点顺序需符合自然操作逻辑。    2.用于登陆校验和请求拦截的验证码均需提供图形验证以外的其它方式。    3.自定义的控件类型需明确交互方式。\n\n\n抄袭自:https://www.jianshu.com/p/1884cdc54409https://github.com/ClarkWong/treehouse\n\n","categories":["后端"],"tags":["后端"]},{"title":"Java 程序员常读书单整理","url":"/2021/08/21/%E5%90%8E%E7%AB%AF/JavaBooks/","content":"Java 程序员常读书单整理，附下载地址，助力构建最强知识体系。但不限于 Java，包括设计模式、计算机网络、操作系统、数据库、数据结构与算法、大数据、架构、面试等等。\n\n”二哥，能不能给一套 Java 电子书的链接啊，最好是成体系的；我现在就想好好的学习，感觉和公司的一些同事差距有点大，想追赶上。纸质书有点沉，天天带在手边很不方便，尤其是上下班坐地铁的时候，都感觉看纸质书不太好意思，电子书不仅携带方便，还能不知不觉。“\n\n说实话，被很多小伙伴问过这样的问题，于是我下狠心，整理了半个多月的时间，终于从各个搜索网站上收集了上百本常用的 Java 电子书，真的是吃奶劲都使上了！\n确实，计算机方面的书籍都比较贵，而技术更新迭代又非常快，天天买纸质书确实不太能跟上节奏。那么，现在好了，再也不用担心这些问题了。\n\n入门\n工具\n框架\nStruts2\nSpring\nNetty\n\n\n数据库\nSQL\nMySQL\nRedis\nMongoDB\n\n\n并发编程\n底层\n性能优化\n设计模式\n操作系统\nLinux基础知识\nLinux环境编程\nLinux内核\n\n\n计算机网络\nLinux网络编程\nwireshark\n\n\n数据结构与算法\n面试\n大数据\n架构\n扩展\n其他语言\nC\nC++\nJavaScript\nPython\ngo\nJavaWeb\nJSP\nKotlin\ngroovy\n\n\nDDD\n区块链\n人工智能\n搜索引擎\n网络安全\n消息队列\n云计算\nAR&amp;VR\nDocker\nIoT\nKubernets\n测试\n\n\n管理\n加餐\n活着\n免责声明\n\n简单说一下我为什么要花半个多月的时间来整理这份书单。主要是因为很多读者的知识体系是零散的，不成系统的，况且技术书籍这么庞杂。有了我这份清单之后，那些没有经验或者经验有限的初学者，在学习的时候思路瞬间就开阔了许多：少走弯路，利用有限的精力，更加高效地学习。\n想应聘初级 Java 工程师，那只需要阅读入门、工具、框架和数据库方面的书籍就行了；\n如果想应聘 Java 高级工程师，那么就需要阅读并发编程、底层、性能优化方面的书籍；\n如果还想更进一步，那么就要着手阅读设计模式、操作系统、计算机网络、数据结构与算法等方面的书籍；\n记住一点，在应聘之前，请恶补一下面试方面的资料；\n如果时间充沛，大数据、架构、管理方面的书籍可以读起来；\n如果还有时间，DDD、区块链、人工智能、搜索引擎、网络安全、消息队列、云计算、容器、智能家居等等方面的书籍，就可以读起来了；\n作为一名程序员，技术方面也不能太过局限，想学习第二种编程语言的话，C、C++、JavaScript、Python、go 都可以选择；\n技术学累了，可以读一读理财金融方面的书籍，比如说香帅北大金融学课、李笑来的学习学习再学习，思维认知方面，强烈推荐《沉默的大多数》，我的偶像王小波的散文集。\n最后，不管怎样，活着最重要！\n入门\nJava 程序员进阶之路       百度云下载链接  密码:1thn\nHead First Java       百度云下载链接 提取码:c07s \nJava 核心技术卷       百度云下载链接 提取码:1fvj \nJava 编程思想       百度云下载链接  密码:9xcr\nJava 8 实战       百度云下载链接 提取码:nfbm \nJava 核心知识点整理       百度云下载链接 提取码:e6tl \nJava 基础核心总结       百度云下载链接 提取码:x2qi \n第一行代码 Java       百度云下载链接 提取码:zhuk \n疯狂 Java 讲义       百度云下载链接 提取码:em2k \n黑马程序员 Java 自学宝典       百度云下载链接 提取码:7mm0 \nJava 软件开发复习提纲       百度云下载链接 提取码:ztfu \nJava 程序设计语言       百度云下载链接 提取码:xc2a \nJava 从入门到精通       百度云下载链接 提取码:2msp \nJava 从小白到大牛       百度云下载链接 提取码:4oon \nJava 技术手册       百度云下载链接 提取码:wx6l \nJava 趣味编程 100 例       百度云下载链接 提取码:gfaq \nJava 入门 123       百度云下载链接 提取码:tdb0 \nJava 网络编程       百度云下载链接 提取码:6ovu \nGitHub 上标星 115k+ 的 Java 教程       百度云下载链接  密码:dz95\n\n工具\nMaven 实战       百度云下载链接  密码:daj5\nMaven 入门指南松哥版       百度云下载链接  密码:bztw\nGit 权威指南       百度云下载链接  密码:sdvy\nEclipse 插件开发学习笔记       百度云下载链接  密码:ri78\n日志系统手册（Log4j、SLF4J、Logback、Log4j 2）       百度云下载链接  密码:fxxy\nIntelliJ IDEA 简体中文专题教程（电子版-2015）       百度云下载链接  密码:wskm\nGitHub入门与实践       百度云下载链接  密码:kidr\n\n框架\nSpringBoot实战(第4版)       百度云下载链接  密码:y6c6\nSpringMVC 入门指南松哥版       百度云下载链接  密码:1j0h\nMyBatis 从入门到精通       百度云下载链接  密码:8vjv\nMyBatis 入门指南松哥版       百度云下载链接  密码:7zj7\nHibernate 实战       百度云下载链接  密码:piv6\n\nStruts2\n开发技巧和整合策略-Struts2       百度云下载链接  密码:htn3\nStruts2 技术内幕——深入解析 Struts2 架构设计与实现原理       百度云下载链接  密码:2mv2\n\nSpring\nSpring 知识点概述       百度云下载链接  密码:1hcq\nSpring 入门指南松哥版       百度云下载链接  密码:zvob\nSpring 技术手册       百度云下载链接  密码:ox17\nSpring 揭秘       百度云下载链接  密码:4lj7\nSpring 实战       百度云下载链接  密码:lw0b\n\nNetty\nNetty 进阶之路 跟着案例学       百度云下载链接  密码:iwij\nNetty 权威指南       百度云下载链接  密码:4n6n\nNetty 实战       百度云下载链接  密码:gy3p\n\n数据库SQL\nHead First SQL       百度云下载链接  密码:u979\nSQL 必知必会       百度云下载链接  密码:qv4z\nSQL 学习指南       百度云下载链接  密码:hdf0\n\nMySQL\nMySQL 必知必会       百度云下载链接  密码:q9cu\n深入浅出MySQL       百度云下载链接  密码:ri07\nMySQL 技术内幕 innodb 存储引擎       百度云下载链接  密码:uetn\nMySQL 技术内幕 SQL 编程       百度云下载链接  密码:wxzb\nMySQL 性能调优与架构设计       百度云下载链接  密码:1464\n高性能 MySQL       百度云下载链接  密码:bxrk\n\nRedis\nRedis 入门指南       百度云下载链接  密码:e2sk\nRedis 设计与实现       百度云下载链接  密码:spsz\nRedis 深度历险：核心原理与应用实践       百度云下载链接  密码:uzwc\nRedis 实战       百度云下载链接  密码:otjw\nRedis 入门指南松哥版       百度云下载链接  密码:iuj9\nRedis 源代码分析       百度云下载链接  密码:8q33\n\nMongoDB\nMongoDB 权威指南       百度云下载链接  密码:zivs\n\nMongoDB实战(第二版)       百度云下载链接  密码:bhxe\n\n数据库系统基础教程       百度云下载链接  密码:nmee\n\n自己动手设计数据库       百度云下载链接  密码:tj8g\n\nSQL+Server+2008 实战       百度云下载链接  密码:5m2v\n\n\n并发编程\nJava 并发编程之美       百度云下载链接  密码:hrgi\n精通 Java 并发编程       百度云下载链接  密码:ld0w\n深入浅出 Java 多线程       百度云下载链接  密码:drjx\n实战 Java 高并发程序设计       百度云下载链接  密码:usiw\nJava 并发编程实战       百度云下载链接  密码:r0ay\nJava 并发编程的艺术       百度云下载链接  密码:x8b7\nJava 多线程编程实战指南       百度云下载链接  密码:v31b\n\n底层\n深入理解 Java 虚拟机-周志明       百度云下载链接  密码:ke1i\n深入理解 Java 虚拟机总结       百度云下载链接  密码:ixev\n深入理解 Java 内存模型       百度云下载链接  密码:k3c6\n实战 Java 虚拟机 JVM 故障诊断与性能优化       百度云下载链接  密码:jzd7\nJava JDK 学习笔记       百度云下载链接  密码:9o05\n\n性能优化\n修改代码的艺术       百度云下载链接  密码:eg5x\n编写高质量代码：改善 Java 程序的 151 个建议       百度云下载链接  密码:hlnn\n代码整洁之道       百度云下载链接  密码:ghyd\n代码之美精选版       百度云下载链接  密码:zlxp\n码出高效：Java 开发手册       百度云下载链接  密码:uiok\n嵩山版阿里巴巴 Java 开发手册       百度云下载链接  密码:pplh\n重构       百度云下载链接  密码:ksqr\nEffective Java       百度云下载链接  密码:y6ur\nJava 程序性能优化       百度云下载链接  密码:b8w7\nJava 程序员修炼之道       百度云下载链接  密码:wvx1\nJava 工程师修炼之道       百度云下载链接  密码:gmlu\nJava 性能权威指南       百度云下载链接  密码:0av5\nJVM 性能优化       百度云下载链接  密码:enbu\nTomcat 性能优化       百度云下载链接  密码:388n\nOracle 性能优化求生指南       百度云下载链接  密码:bcgd\nMySQL 性能优化的 21 个最佳实践       百度云下载链接  密码:ex1h\n\n设计模式\n23 种设计模式知识要点       百度云下载链接  密码:w55h\n大话设计模式       百度云下载链接  密码:909m\n设计模式：可复用面向对象软件的基础       百度云下载链接  密码:rdgw\n设计模式之禅       百度云下载链接  密码:x0wx\n深入浅出设计模式       百度云下载链接  密码:yuvv\n Head First 设计模式       百度云下载链接  密码:gkn5\n\n操作系统\n深入理解计算机系统       百度云下载链接  密码:819r\nLinux 与 Unix shell 编程指南       百度云下载链接  密码:z79w\n操作系统原理       百度云下载链接  密码:4llf\n操作系统之哲学原理       百度云下载链接  密码:0jj6\n程序是怎样跑起来的       百度云下载链接  密码:wa9c\n计算机是怎样跑起来的       百度云下载链接  密码:mnvn\n认识操作系统       百度云下载链接  密码:2sm9\nWindows 内核原理与实现       百度云下载链接  密码:lpv9\n现代操作系统原书       百度云下载链接 提取码:7673\n计算机系统概论       百度云下载链接  密码:xudx\n\nLinux基础知识\n鸟哥的 Linux 私房菜       百度云下载链接  密码:yzsl\n循序渐进Linux（第2版）       百度云下载链接  密码:tney\nLinux 程序设计       百度云下载链接  密码:cems\nLinux 命令行与 shell 脚本编程大全       百度云下载链接  密码:tr5u\n\nLinux环境编程\nLinux-Unix 系统编程手册       百度云下载链接  密码:7i9n\nLinux 高性能服务器编程       百度云下载链接  密码:xupv\nUnix 环境高级编程       百度云下载链接  密码:6d05\n\nLinux内核\n深入理解 Linux 内核       百度云下载链接  密码:imav\n深入 Linux 内核架构       百度云下载链接  密码:vnhj\n Linux 内核源代码情景分析       百度云下载链接  密码:o08i\n\n计算机网络\n计算机网络-自顶向下方法       百度云下载链接  密码:d3tj\n图解 HTTP       百度云下载链接  密码:45aw\n图解 TCP IP       百度云下载链接  密码:2qe9\n网络是怎样连接的       百度云下载链接  密码:p8l7\nHTTP 超全混总       百度云下载链接  密码:412z\nJava2 网络协议内幕       百度云下载链接  密码:pwml\nTCPIP 详解       百度云下载链接  密码:q7cg\nTCP IP 网络编程       百度云下载链接  密码:vrlt\nHTTP权威指南       百度云下载链接  密码:o0gn\n\nLinux网络编程\nLinux 多线程服务端编程       百度云下载链接  密码:2rp4\nUnix 网络编程       百度云下载链接  密码:6c3l\n深入理解 Linux 网络技术内幕       百度云下载链接  密码:xrjs\n\nwireshark\nWireshark数据包分析实战       百度云下载链接  密码:by6w\nWireshark网络分析的艺术       百度云下载链接  密码:12h5\nWireshark网络分析就这么简单       百度云下载链接  密码:166d\n\n数据结构与算法\n啊哈算法       百度云下载链接  密码:txid\n编程珠玑       百度云下载链接  密码:2tv6\n编程珠玑续       百度云下载链接  密码:me0y\n大话数据结构       百度云下载链接  密码:i70v\n趣学算法       百度云下载链接  密码:qv4y\n数据结构与算法分析-Java 描述       百度云下载链接  密码:b0l2\n数字图像处理-Java 语言算法描述       百度云下载链接  密码:7v5n\n算法       百度云下载链接  密码:9m6f\n算法导论       百度云下载链接  密码:n4fn\n算法图解       百度云下载链接  密码:685s\nJava 常用算法       百度云下载链接  密码:ybvr\nJava 数据结构和算法       百度云下载链接  密码:qupj\nBAT LeetCode 刷题手册       百度云下载链接  密码:8w3m\n\n面试\n2020年字节跳动Java 工程师面试题       百度云下载链接  密码:iozq\nGoogle 师兄的刷题笔记       百度云下载链接  密码:5ttz\nBAT面试常问80题       百度云下载链接  密码:c54x\n一线互联网企业面试题       百度云下载链接  密码:wjrr\n编程之美       百度云下载链接  密码:ng5q\n程序员面试宝典       百度云下载链接  密码:6rr8\n剑指Offer：名企面试官精讲典型编程题       百度云下载链接  密码:lbsn\n程序员代码面试指南 IT名企算法与数据结构题目最优解       百度云下载链接  密码:0djm\n如何刷力扣       百度云下载链接  密码:h14s\n力扣最优解       百度云下载链接  密码:o28k\n2020最新Java面试题资料       百度云下载链接  密码:mlf8\n最新Java程序员面试宝典       百度云下载链接  密码:u5gh\nJavaGuide 面试突击       百度云下载链接  密码:e0p4\nJava 核心面试知识整理       百度云下载链接  密码:387r\nJava面试题以及答案       百度云下载链接  密码:y4ef\n面试必问之jvm与性能优化       百度云下载链接  密码:y6iu\nSpring 面试题       百度云下载链接  密码:77ud\nDubbo 面试题       百度云下载链接  密码:cl5a\n简历模板与优化       百度云下载链接  密码:1cb0\n\n大数据\n大数据-涂子沛       百度云下载链接  密码:xhym\n数据之巅-涂子沛       百度云下载链接  密码:gb3t\nKafaka 权威指南       百度云下载链接  密码:xb4p\nSpark 快速大数据分析       百度云下载链接  密码:d9qx\nSpark 快速数据处理       百度云下载链接  密码:xvug\nHadoop 权威指南       百度云下载链接  密码:wh8m\nHadoop 技术内幕       百度云下载链接  密码:c945\n\n架构\n大型网站技术架构 核心原理与案例分析       百度云下载链接  密码:r5k1\n高性能高并发服务器架构       百度云下载链接  密码:ofa1\n架构风格与基于网络的软件架构设计       百度云下载链接  密码:a0lf\n架构之美       百度云下载链接  密码:lfxq\n大型网站系统与 Java 中间件实践       百度云下载链接  密码:tboh\n亿级流量网站架构核心技术       百度云下载链接  密码:fwer\n\n扩展其他语言C\nC程序设计语言（第二版，中文版，B.W.Kernighan、D.M.Ritchie 著）       百度云下载链接  密码:bzj8\nC Primer Plus       百度云下载链接  密码:7qru\nC 和指针       百度云下载链接  密码:oaum\nC 陷阱与缺陷       百度云下载链接  密码:diao\nC 专家编程       百度云下载链接  密码:ipzt\n深度探索 C 对象模型       百度云下载链接  密码:z6vp\n数据结构与算法分析——C 语言描述       百度云下载链接  密码:k7kj\n\nC++\n牛客校招面试题（附答案与解析）c++篇       百度云下载链接  密码:h7im\nC++ 面试题库       百度云下载链接  密码:qhrg\n大规模 C++程序设计       百度云下载链接  密码:llij\n深度探索C++对象模型       百度云下载链接  密码:l9l3\n深入理解c11新特性解析与应用       百度云下载链接  密码:g7st\nC++ Primer       百度云下载链接  密码:ehzj\nC++标准程序库—自修教程与参考手册       百度云下载链接  密码:bdv2\nC++性能优化指南       百度云下载链接  密码:h94d\nC++语言的设计和演化       百度云下载链接  密码:3yx1\nEffective.Modern.C++        百度云下载链接  密码:58u1\nEffective+STL中文版：50条有效使用STL的经验       百度云下载链接  密码:em3y\nEffectiveC++中文版（第三版）       百度云下载链接  密码:cu9o\nMore Effective C++中文       百度云下载链接  密码:xlvw\nSTL源码剖析–侯捷       百度云下载链接  密码:pc9e\n\nJavaScript\nJavaScript王者归来       百度云下载链接  密码:xz1j\n超实用的JavaScript代码段       百度云下载链接  密码:s5bz\n单页Web应用  JavaScript从前端到后端       百度云下载链接  密码:dm3c\n你不知道的JavaScript       百度云下载链接  密码:z7il\n实战ES2015深入JavaScript现代应用开发       百度云下载链接  密码:aigg\n数据结构与算法JavaScript描述       百度云下载链接  密码:dt4g\nES6深入浅出       百度云下载链接  密码:06ic\nJavaScript DOM编程艺术       百度云下载链接  密码:9ke7\nJavaScript.DOM高级程序设计       百度云下载链接  密码:ug61\nJavaScript宝典(第6版)       百度云下载链接  密码:lotv\nJavaScript编程全解       百度云下载链接  密码:39ee\nJavaScript从入门到精通       百度云下载链接  密码:awbd\nJavaScript高级程序设计(第2版)       百度云下载链接  密码:pvkw\nJavaScript捷径教程       百度云下载链接  密码:yzs8\nJavaScript框架高级编程       百度云下载链接  密码:glh3\nJavascript框架设计       百度云下载链接  密码:rk3a\nJavaScript面向对象编程指南       百度云下载链接  密码:g63p\nJavaScript启示录       百度云下载链接  密码:20r5\nJavaScript权威指南第六版       百度云下载链接  密码:3j90\nJavaScript入门经典(第3版)       百度云下载链接  密码:g9xm\nJAVASCRIPT设计模式       百度云下载链接  密码:7xvl\nppk谈JavaScript       百度云下载链接  密码:99q9\nJavaScript语言精髓与编程实践       百度云下载链接  密码:omr4\nJavaScript语言精粹       百度云下载链接  密码:h347\nJavaScript 异步编程       百度云下载链接  密码:xeab\nJavaScript 开发技术大全       百度云下载链接  密码:5tdd\n\nPython\nPython+Cookbook第三版中文v2.0.0       百度云下载链接  密码:y68v\n编程小白的第一本Python入门书       百度云下载链接  密码:n8d8\n可爱的Python_中文版       百度云下载链接  密码:o6cf\n利用Python进行数据分析       百度云下载链接  密码:08zf\n深入浅出：使用Python编程       百度云下载链接  密码:vyya\n用Python进行自然语言处理       百度云下载链接  密码:0sx5\nPython高性能编程       百度云下载链接  密码:j4js\nPython编程：从入门到实践       百度云下载链接  密码:rchj\nPython+Web开发：测试驱动方法       百度云下载链接  密码:pfmk\npython-basic       百度云下载链接  密码:te3f\nbyte-of-python-chinese-edition       百度云下载链接  密码:uzip\nPython基础教程(第2版)       百度云下载链接  密码:r8qx\nPython进阶-v1.1       百度云下载链接  密码:x6tf\nPython核心编程(第二版)       百度云下载链接  密码:4nkr\nPython最佳实践指南（中）       百度云下载链接  密码:aldu\nPYTHON自然语言处理【中文版】       百度云下载链接  密码:3tgu\nPython源码剖析（陈儒-2008-电子工业出版）       百度云下载链接  密码:s81x\nPython网络数据采集       百度云下载链接  密码:7x8s\n流畅的 Python       百度云下载链接  密码:ssjd\n\ngo\n学习 go 语言       百度云下载链接  密码:grvq\ngo 语言编程       百度云下载链接  密码:131i\n\nJavaWeb\nJAVA EE WEB开发实例精解       百度云下载链接  密码:m7l0\nJava Web入门经典       百度云下载链接  密码:m8x5\nJava Web设计模式之道       百度云下载链接  密码:khgy\nJava_Web轻量级开发全体验       百度云下载链接  密码:9x7q\nJava.Web开发学习手册       百度云下载链接  密码:lxu8\n\nJSP\nJSP 程序设计       百度云下载链接  密码:o8im\nJSP 技术手册       百度云下载链接  密码:a6pw\nJSP 应用开发详解       百度云下载链接  密码:7myk\nServlet 和 JSP 学习指南       百度云下载链接  密码:mdqy\n\nKotlin\nkotlin-in-chinese       百度云下载链接  密码:53om\nkotlin-for-android-developers-zh       百度云下载链接  密码:m9nz\n\ngroovy\ngroovy 程序设计       百度云下载链接  密码:xmjl\n\nDDD\n领域驱动设计.软件核心复杂性应对之道       百度云下载链接  密码:yc7f\n领域驱动设计精简版       百度云下载链接  密码:9e3x\n\n区块链人工智能\n机器学习与实战       百度云下载链接  密码:buvz\n\n搜索引擎\n开发自己的搜索引擎–Lucene+Heritrix       百度云下载链接  密码:h1oi\nSolrJ教程       百度云下载链接  密码:p0s6\nElasticsearch 权威指南       百度云下载链接  密码:9m8e\nElasticsearch 技术解析与实战       百度云下载链接  密码:yg98\n\n网络安全\nJava 加密与解密的艺术       百度云下载链接  密码:1kgn\n\n消息队列\nRabbitMQ实战 高效部署分布式消息队列       百度云下载链接  密码:26s7\n\n云计算\n大话云计算       百度云下载链接  密码:efwj\n\nAR&amp;VRDocker\n第一本Docker书       百度云下载链接  密码:7dz6\nDocker入门指南松哥版       百度云下载链接  密码:q175\nSpring Cloud与Docker微服务架构实战       百度云下载链接  密码:yeem\n\nIoTKubernets\nKUBERNETES权威指南  从DOCKET到KURBERNETES实践全接触       百度云下载链接  密码:njo1\n\n测试\n有效的单元测试       百度云下载链接  密码:kbc4\n\n管理\n人月神话       百度云下载链接  密码:ctf3\n人件       百度云下载链接  密码:39iz\n微管理：给你一个技术团队，你该怎么管（全彩）       百度云下载链接  密码:u6ml\n\n加餐\n编程人生       百度云下载链接  密码:mmba\n程序员修炼之道：从小工到专家       百度云下载链接  密码:7yle\n代码大全       百度云下载链接  密码:geyj\n黑客与画家       百度云下载链接  密码:eyzn\n奇思妙想：15 位计算机天才及其重大发现       百度云下载链接  密码:fm21\n图灵的秘密       百度云下载链接  密码:oa92\n我编程我快乐       百度云下载链接  密码:tqnx\n《阿里技术参考图册》（算法篇）       百度云下载链接  密码:4eev\n《阿里技术参考图册》（研发篇）       百度云下载链接  密码:hq1u\n程序员必知的硬核知识大全       百度云下载链接  密码:dp1p\nhow-to-be-a-programmer-cn       百度云下载链接  密码:kar9\n卓有成效的程序员       百度云下载链接  密码:6511\n程序员的职业素养       百度云下载链接  密码:n2zg\n程序员内功修炼-V2.0       百度云下载链接  密码:xmg5\n设计原本（中文版）       百度云下载链接  密码:zaxe\n数学之美       百度云下载链接  密码:mbmh\n淘宝技术这十年       百度云下载链接  密码:b4u6\n如何变得有思想  阮一峰博客文集       百度云下载链接  密码:7yyh\n沉默的大多数       百度云下载链接  密码:6vcc\n香帅北大金融学课 线下大课       百度云下载链接  密码:cfcm\n学习学习再学习       百度云下载链接  密码:vup6\n学习正则表达式       百度云下载链接  密码:icft\n自己动手写网络爬虫       百度云下载链接  密码:cz9n\nCh3-Ch5-超人气博客是怎样炼成的       百度云下载链接  密码:34v0\n深入理解Nginx：模块开发与架构解析-陶辉       百度云下载链接  密码:k9zc\n深入剖析Tomcat-高清-书签       百度云下载链接  密码:o77f\nWEB服务_原理与技术       百度云下载链接  密码:gvoc\n由浅入深学Java—基础、进阶与必做260题       百度云下载链接  密码:r1tk\nJava与模式       百度云下载链接  密码:56lw\nJava游戏高级编程       百度云下载链接  密码:mp4i\nJava应用架构设计 模块化模式与OSGi       百度云下载链接  密码:vgm6\nJava典型模块与项目实战大全       百度云下载链接  密码:svgn\n\n活着\n程序员健康指南       百度云下载链接  密码:pl0i\n颈椎康复指南       百度云下载链接  密码:ouhh\n\n免责声明书籍全部来源于网络其他人的整理，我这里只是收集整理了他们的链接，如有侵权，马上联系我，我立马删除对应链接。我的邮箱：&#57;&#x38;&#x33;&#52;&#51;&#x36;&#48;&#x37;&#x36;&#x40;&#x71;&#113;&#46;&#x63;&#111;&#x6d;\n","tags":["后端开发"]},{"title":"通俗地解释脏读、不可重复读、幻读","url":"/2021/08/24/%E5%90%8E%E7%AB%AF/Serializable/","content":"1.数据库 事务隔离级别分为四种（级别递减）：Serializable （串行化）：顾名思义，可串行化的，也即并发事务串行执行。很显然，该级别可以避免前面讲到的所有问题：“脏读”、“不可重复读”和“幻读”。代价是处理事务的吞吐量低，严重浪费数据库的性能，因此要慎用此事务隔离级别。\n最严格的级别，事务串行执行，资源消耗最大；\n下面演示Serializable如何解决这些问题：\n1. 小明连接数据库去查询自己本学期的成绩，他设置session(当前连接)的事务隔离级别为Serializable：\nxiaoming&gt; set session transaction isolation level serializable;Query OK, 0 rows affected (0.00 sec) xiaoming&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| SERIALIZABLE   |+----------------+1 row in set (0.00 sec)\n\n2. 小明开始查询成绩，由于还没有录入，因此没有成绩：\nxiaoming&gt; begin;Query OK, 0 rows affected (0.00 sec) xiaoming select * from scores where name = &#x27;xiaoming&#x27;;Empty set (0.00 sec)\n\n3. 这时小明的班主任王老师也连接数据库来录入成绩，可是他会卡在插入第一条成绩信息这里, 如下所示，insert语句迟迟不会返回：\nmr.wang&gt; begin;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; insert into scores(name, score) values (&#x27;xiaoming&#x27;, 69);\n\n4. 小明结束本次查询：\nxiaoming&gt; commit;Query OK, 0 rows affected (0.00 sec)\n\n5. 这时王老师插入第一条成绩才完成：\nmr.wang&gt; insert into scores(name, score) values (&#x27;xiaoming&#x27;, 69);Query OK, 1 row affected (3.42 sec)\n\n6. 如果小明久久不结束查询，还会导致王老师录入成绩超时：\nxiaoming&gt; insert into scores(name, score) values (&#x27;xiaoming&#x27;, 69);ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction\n\n从上面的例子我们可以看出，如果一个session设置隔离级别为Serializable时，其执行事务时会阻塞其他并发事务，从上面的错误信息中我们也可以看出应该是通过某种锁来实现的。既然是这样，那么“脏读”、“不可重复读”和“幻读”自然是不可能发生了。\nREPEATABLE READ（重复读） ：也即在一个事务范围内相同的查询会返回相同的数据，保证了一个事务不会修改已经由另一个事务读取但未提交（回滚）的数据。避免了“脏读取”和“不可重复读取”的情况，但不能避免“幻读”，但是带来了更多的性能损失。延续上面的栗子：\n1. 小明很开心自己考了69分，于是他连接到数据库查询自己的成绩来炫耀给小伙伴，由于Repeatable Read是默认的事务隔离级别，因此这次他不需要进行修改：\nxiaoming&gt; select @@tx_isolation;+-----------------+| @@tx_isolation  |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec) xiaoming&gt; begin;Query OK, 0 rows affected (0.00 sec) xiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;+----+----------+-------+| id | name     | score |+----+----------+-------+|  1 | xiaoming |    69 |+----+----------+-------+1 row in set (0.00 sec)\n\n2. 不幸的是，小明的班主任王老师复查试卷后，发现小明的成绩多加了10分，于是他连接到数据库来修改小明的成绩：\nmr.wang&gt; begin;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; update scores set score = 59 where name = &#x27;xiaoming&#x27;;Query OK, 1 row affected (0.00 sec)Rows matched: 1  Changed: 1  Warnings: 0 mr.wang&gt; commit;Query OK, 0 rows affected (0.00 sec)\n\n3. 接着小明觉得还不尽兴，于是又查一次，还是69分，可怜的是他不知道自己其实是不及格的：\nxiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;+----+----------+-------+| id | name     | score |+----+----------+-------+|  1 | xiaoming |    69 |+----+----------+-------+1 row in set (0.00 sec)\n\n可见Repeatable Read的确可以解决“不可重复读”的问题，小明在一次事务中2次查询的成绩都是一样的，即使2次查询中王老师修改了成绩。注意我们演示的场景中，王老师是针对一条已有的记录进行了Update， 如果王老师是新增即Insert小明的成绩，那么小明的2次查询的结果还是不一样的，如下所示：\n1.首先小明第一次查询, 没有成绩\nxiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;Empty set (0.00 sec)\n\n2. 然后王老师录入成绩\nmr.wang&gt; begin;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; insert into scores(name,score) values (&quot;xiaoming&quot;, 59);Query OK, 1 row affected (0.00 sec) mr.wang&gt; commit;Query OK, 0 rows affected (0.00 sec)\n\n3. 最后小明再次查询成绩，这次有了：\nxiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;+----+----------+-------+| id | name     | score |+----+----------+-------+|  1 | xiaoming |    59 |+----+----------+-------+1 row in set (0.00 sec)\n\n通过上述例子，我们可以看出Repeatable Read也是存在以下问题的：\na. 幻读，也即在一次事务范围内多次进行查询，如果其他并发事务中途插入了新的记录，那么之后的查询会读取到这些“幻影”行。\n另外，我们也需要注意，不可重复读对应的是修改即Update，幻读对应的是插入即Insert。\nREAD COMMITTED （提交读）：顾名思义，就是读已提交，一个事务只能看到其他并发的已提交事务所作的修改，是大多数主流数据库的默认事务等级，保证了一个事务不会读到另一个并行事务已修改但未提交的数据，避免了“脏读取”，但不能避免“幻读”和“不可重复读取”。该级别适用于大多数系统。\n下面通过例子来演示Read Committed解决“脏读”：\n1. 小明连接数据库去查询自己本学期的成绩，他设置session(当前连接)的事务隔离级别为Read Committed：\nxiaoming&gt; set session transaction isolation level read committed;Query OK, 0 rows affected (0.00 sec) xiaoming&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set (0.00 sec)\n\n2. 就在这个时候，小明的班主任王老师也连接了数据库去登记学生本学期的成绩：\nmr.wang&gt; begin;  Query OK, 0 rows affected (0.00 sec)    mr.wang&gt; insert into scores(name,score) values (&quot;xiaoming&quot;, 59);  Query OK, 1 row affected (0.00 sec)  \n\n3. 当王老师还没有提交事务时，小明刚好开始查询自己的成绩，结果他没查到成绩，因为王老师还没提交：\nxiaoming&gt; begin;Query OK, 0 rows affected (0.00 sec) xiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;  Empty set (0.00 sec)\n\n4. 小明查成绩之后，王老师发现自己登错了成绩，其实小明考了69分，于是他回滚了当前事务, 并重新录入了小明的正确成绩:\nmr.wang&gt; rollback;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; begin;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; insert into scores(name,score) values (&quot;xiaoming&quot;, 69); Query OK, 1 row affected (0.00 sec) mr.wang&gt; commit;Query OK, 0 rows affected (0.00 sec)\n\n5. 接着，小明又查了一次成绩，这次他查到了，他很开心，因为他及格了\nxiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;  +----+----------+-------+| id | name     | score |+----+----------+-------+|  1 | xiaoming |    69 |+----+----------+-------+1 row in set (0.00 sec)\n\n虽然解决了“脏读”问题，但是Read Committed不能保证在一个事务中每次读都能读到相同的数据，因为在每次读数据之后其他并发事务可能会对刚才读到的数据进行修改。就像上面，小明在一次事务中2次读取成绩返回的结果不一样。这也反映出了Read Committed事务隔离级别存在以下问题：\na. 不可重复读， 也即一个事务范围内两个相同的查询却返回了不同数据\nRead Uncommitted（未提交读） ：顾名思义，就是读未提交，也就是说事务所作的修改在未提交前，其他并发事务是可以读到的。\n事务中的修改，即使没有提交，其他事务也可以看得到，会导致“脏读”、“幻读”和“不可重复读取”。\n1. 假设现在有个学生小明连接到数据库去读取自己本学期的成绩，它设置session(当前连接)的事务隔离级别为Read Uncommitted：\nxiaoming&gt; select @@tx_isolation;+-----------------+| @@tx_isolation  |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set (0.00 sec) xiaoming&gt; set session transaction isolation level read uncommitted;Query OK, 0 rows affected (0.00 sec) xiaoming&gt; select @@tx_isolation;+------------------+| @@tx_isolation   |+------------------+| READ-UNCOMMITTED |+------------------+1 row in set (0.00 sec)\n\n2. 就在这个时候，小明的班主任王老师也连接了数据库去登记学生本学期的成绩：\nmr.wang&gt; begin;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; insert into scores(name,score) values (&quot;xiaoming&quot;, 59);Query OK, 1 row affected (0.00 sec)\n\n3. 当王老师还没有提交事务时，小明刚好开始查询自己的成绩，结果他查到自己考了59分，他伤心的要死：\nxiaoming&gt; begin;Query OK, 0 rows affected (0.00 sec) xiaoming&gt; select * from scores where name = &#x27;xiaoming&#x27;;+----+----------+-------+| id | name     | score |+----+----------+-------+|  1 | xiaoming |    59 |+----+----------+-------+1 row in set (0.00 sec)\n\n4. 小明查成绩之后，王老师发现自己登错了成绩，其实小明考了69分，于是他回滚了当前事务, 并重新录入了小明的正确成绩:\nmr.wang&gt; rollback;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; begin;Query OK, 0 rows affected (0.00 sec) mr.wang&gt; insert into scores(name,score) values (&quot;xiaoming&quot;, 69);Query OK, 1 row affected (0.00 sec) mr.wang&gt; commit;Query OK, 0 rows affected (0.00 sec)\n\n5. 小明也没有复查成绩，因此整个寒假都过的很不开心，毕竟自己没有”及格”！\n通过上述场景，我们发现，Read Uncommitted这个最低的事务隔离级别存在以下这些问题：\na. 允许脏读(dirty reads)，就像上面王老师录入的错误成绩(脏数据)被小明读到一样\n2.脏读、不可重复读、幻读：也许有很多读者会对上述隔离级别中提及到的 脏读、不可重复读、幻读 的理解有点吃力，我在这里尝试使用通俗的方式来解释这三种语义：\n脏读：所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。\n也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。\n不可重复读：事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。\n也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。\n幻读：事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。\n也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。\n","categories":["后端"],"tags":["后端"]},{"title":"图解 Java 内存模型","url":"/2023/02/05/%E5%90%8E%E7%AB%AF/jvm-memory-model/","content":"1. Java 内存模型的总体设计Java 虚拟机在执行 Java 程序的过程中会把它管理的内存划分成若干个不同的数据区域\n线程私有的：\n\n  程序计数器\n  虚拟机栈\n  本地方法栈\n\n线程共享的：\n\n  堆\n  方法区 （JDK1.7及之前）\n  直接内存 （JDK1.7及之前）\n  元空间 （JDK1.8及之后）\n\n其结构如下图所示：\n\n2. 线程共享区（堆与方法区）的设计堆是 JVM 内存中最大的一块内存空间，该内存被所有线程共享，几乎所有对象和数组都被分配到了堆内存中。堆被划分为新生代和老年代，新生代又被进一步划分为 Eden 和 Survivor 区，最后 Survivor 由 From Survivor 和 To Survivor 组成，新生代中的 Eden:From Survivor:To Survivor 的比例是 8:1:1。\n2.1 新生代新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代\n\nEden 区 ：  Java 新对象的出生地（如果新创建的对象占用内存很大，则直接分配到老  年代）。当 Eden 区内存不够的时候就会触发 MinorGC，对新生代区进行  一次垃圾回收。\n\n\n S1(ServivorFrom):上一次 GC 的幸存者，作为这一次 GC 的被扫描者。\nS2(ServivorTo):保留了一次 MinorGC 过程中的幸存者。\n\n系统执行Minor GC时，将把 Eden 和 ServivorFrom 区域中存活的对象从Eden区和From区复制到另一个幸存者空间To区后并将原位置清空，然后交换From区和To区的标记，所以每次，总有一个幸存者空间总是空的\n经过多次 GC 循环后（15），存活下来的对象被移动到老年代。通常，这是通过设置年轻一代对象的年龄阈值来实现的，然后他们才有资格提升到老一代。\n2.2 老年代主要存放应用程序中生命周期长的内存对象。\n老年代的对象比较稳定，所以 MajorGC 不会频繁执行。在进行 MajorGC 前一般都先进行  了一次 MinorGC，使得有新生代的对象晋身入老年代，导致空间不够用时才触发。当无法找到足  够大的连续空间分配给新创建的较大对象时也会提前触发一次 MajorGC 进行垃圾回收腾出空间。   \nMajorGC 采用标记清除算法：首先扫描一次所有老年代，标记出存活的对象，然后回收没  有标记的对象。MajorGC 的耗时比较长，因为要扫描再回收。MajorGC 会产生内存碎片，为了减  少内存损耗，我们一般需要进行合并或者标记出来方便下次直接分配。当老年代也满了装不下的  时候，就会抛出 OOM（Out of Memory）异常。\n2.3 方法区方法区（Method Area）与 Java 堆一样，是所有线程共享的内存区域,用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等,虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫 Non-Heap（非堆），目的应该是与 Java 堆区分开。\n运行时常量池（Runtime Constant Pool）是方法区的一部分。Class 文件中除了有类的版本/字段/方法/接口等描述信息外，还有一项信息是常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将类在加载后进入方法区的运行时常量池中存放。运行期间也可能将新的常量放入池中，这种特性被开发人员利用得比较多的是 String.intern()方法。受方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。\n2.3.1 永久代jdk1.6及之前方法区 是由永久代来实现的，以至于这个时期说方法区就是指永久代，永久代，运行时常量池（包括字符串常量池），静态变量存放在永久代上\njdk1.7 时期方法区在HotSpot中由永久代（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现\n永久代(Permanent Generation), 用于存储被 JVM 加载的类信息、常量、静  态变量、即时编译器编译后的代码等数据，HotSpot VM把GC分代收集扩展至方法区, 即使用Java  堆的永久代来实现方法区。\n\n在 Java6 版本中，永久代在非堆内存区，静态变量存放在永久代上；\n\n到了 Java7 版本，永久代的静态变量和运行时常量池被合并到了堆中，类型信息、字段、方法、常量则继续留在永久代；\n\n而到了 Java8，永久代（方法区）被元空间取代了。 具体描述在下一节\n2.3.2 元空间jdk1.8及之后，取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中\n\n\nwhy?为永久代设置空间大小是很难确定的,且对永久代进行调优较困难\n在某些场景下，如果动态加载类过多，容易产生 Perm 区的 OOM。如果某个实际 Web 工程中，因为功能点比较多，在运行过程中，要不断动态加载很多类，经常出现 OOM。而元空间和永久代最大的区别在于，元空间不在虚拟机中，而是使用本地内存，所以默认情况下，元空间的大小仅受本地内存限制\n3.线程私有空间3.1 程序计数器存储指向下一条指令的地址，即将要执行的指令代码。\n多线程在一个特定的时间段内只会执行其中某一个线程方法，CPU会不停的做任务切换，这样必然会导致经常中断或恢复。为了能够准确的记录各个线程正在执行的当前字节码指令地址，所以为每个线程都分配了一个PC寄存器，每个线程都独立计算，不会互相影响。\n它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域（因为太简单了\n3.2 虚拟机栈是描述java方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧（Stack Frame）  用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成  的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。\n栈帧（ Frame）是用来存储数据和部分过程结果的数据结构，同时也被用来处理动态链接  (Dynamic Linking)、 方法返回值和异常分派（ Dispatch Exception）。\n栈帧随着方法调用而创建，随着方法结束而销毁——无论方法是正常完成还是异常完成（抛出了在方法内未被捕获的异  常）都算作方法结束\n3.3 本地方法区本地方法栈则为  Native 方法服务，就是执行C语言代码的栈（因为JVM底层依赖C实现）\n4. JVM 总详细内存图\nPS.参考\n磨刀不误砍柴工：欲知JVM调优先了解JVM内存模型.md\n\nJava 内存区域详解\n\n\nJVM 基础 - JVM 内存结构\n\n\n","categories":["后端"],"tags":["后端"]},{"title":"IO多路复用中的select poll和epoll","url":"/2023/01/24/%E5%90%8E%E7%AB%AF/io-multiplexing-select-poll-epoll/","content":"Select ,Poll 和Epoll目前流程的多路复用IO实现主要包括四种: select、poll、epoll\nselect函数签名与参数\nint select(int nfds,            fd_set *restrict readfds,            fd_set *restrict writefds,            fd_set *restrict errorfds,            struct timeval *restrict timeout);\nreadfds、writefds、errorfds 是三个文件描述符集(fd)合。select 会遍历每个集合的前 nfds 个描述符，分别找到可以读取、可以写入、发生错误的描述符，统称为“就绪”的描述符。然后用找到的子集替换参数中的对应集合，返回所有就绪描述符的总数。\ntimeout 参数表示调用 select 时的阻塞时长。如果所有文件描述符都未就绪，就阻塞调用进程，直到某个描述符就绪，或者阻塞超过设置的 timeout 后，返回。如果 timeout 参数设为 NULL，会无限阻塞直到某个描述符就绪；如果 timeout 参数设为 0，会立即返回，不阻塞。\n\nselect目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。\n\nselect最大的缺陷就是单个进程所打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024。\n\n\n对socket进行扫描时是线性扫描，性能开销大,采用轮询的方法，调用 select 时会陷入内核，这时需要将参数中的 fd_set 从用户空间拷贝到内核空间,内核需要遍历传递进来的所有 fd_set 的每一位，不管它们是否就绪。\n\n\npollint poll(struct pollfd *fds, nfds_t nfds, int timeout);\n其中 fds 是一个 pollfd 结构体类型的数组，调用 poll() 时必须通过 nfds 指出数组 fds 的大小，即文件描述符的数量。\npoll没有最大连接数的限制，原因是它是基于链表来存储的，poll 和 select 几乎没有区别。poll 在用户态通过数组方式传递文件描述符，在内核会转为链表方式存储，没有最大数量的限制\n从性能开销上看，poll 和 select 的差别不大。\n\n大量的fd的数组被整体复制于用户态和内核地址空间之间，而不管这样的复制是不是有意义。\npoll还有一个特点是“水平触发”，如果报告了fd后，没有被处理，那么下次poll时会再次报告该fd。\n\nepollselect、poll 模型都只使用一个函数，而 epoll 模型使用三个函数：epoll_create、epoll_ctl 和 epoll_wait。\nepoll 是对 select 和 poll 的改进，避免了“性能开销大”和“文件描述符数量少”两个缺点。\n简而言之，epoll 有以下几个特点：\n\n  使用红黑树存储文件描述符集合\n  使用队列存储就绪的文件描述符\n  每个文件描述符只需在添加时传入一次；通过事件更改文件描述符状态\n\n一开始说，epoll 是对 select 和 poll 的改进，避免了“性能开销大”和“文件描述符数量少”两个缺点。\n\n对于“文件描述符数量少”，select 使用整型数组存储文件描述符集合，而 epoll 使用红黑树存储，数量较大。\n\n对于“性能开销大”，epoll_ctl 中为每个文件描述符指定了回调函数，并在就绪时将其加入到就绪列表，因此 epoll 不需要像 select 那样遍历检测每个文件描述符，只需要判断就绪列表是否为空即可。这样，在没有描述符就绪时，epoll 能更早地让出系统资源。\n\n\n相当于时间复杂度从 $O(n)$ 降为 $O(1)$\n此外，每次调用 select 时都需要向内核拷贝所有要监听的描述符集合，而 epoll 对于每个描述符，只需要在 epoll_ctl 传递一次，之后 epoll_wait 不需要再次传递。这也大大提高了效率。\nselect 只支持水平触发，epoll 支持水平触发和边缘触发。\n触发方式水平触发（LT，Level Trigger）：当文件描述符就绪时，会触发通知，如果用户程序没有一次性把数据读/写完，下次还会发出可读/可写信号进行通知。\n当 epoll_wait() 检测到描述符事件到达时，将此事件通知进程，进程可以不立即处理该事件，下次调用 epoll_wait() 会再次通知进程。是默认的一种模式，并且同时支持 Blocking 和 No-Blocking。#\n边缘触发（ET，Edge Trigger）：仅当描述符从未就绪变为就绪时，通知一次，之后不会再通知。\n和 LT 模式不同的是，通知之后进程必须立即处理事件，下次再调用 epoll_wait() 时不会再得到事件到达的通知。\n很大程度上减少了 epoll 事件被重复触发的次数，因此效率要比 LT 模式高。只支持 No-Blocking，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。\n区别：边缘触发效率更高，减少了事件被重复触发的次数，函数不会返回大量用户程序可能不需要的文件描述符。\n水平触发、边缘触发的名称来源：\n数字电路当中的电位水平，高低电平切换瞬间的触发动作叫边缘触发，而处于高电平的触发动作叫做水平触发。\n\n总的对比\n  select：调用开销大（需要复制集合）；集合大小有限制；需要遍历整个集合找到就绪的描述符\n  poll：poll 采用数组的方式存储文件描述符，没有最大存储数量的限制，其他方面和 select 没有区别\n  epoll：调用开销小（不需要复制）；集合大小无限制；采用回调机制，不需要遍历整个集合\n\n使用情景##select 应用场景select 的 timeout 参数精度为 1ns，而 poll 和 epoll 为 1ms，因此 select 更加适用于实时要求更高的场景，比如反应堆的控制，\n其移植性更好，几乎被所有主流平台所支持。  \npoll 应用场景poll 没有最大描述符数量的限制，如果平台支持并且对实时性要求不高，应该使用 poll 而不是 select。\n需要同时监控小于 1000 个描述符，就没有必要使用 epoll，因为这个应用场景下并不能体现 epoll 的优势。\n需要监控的描述符状态变化多，而且都是非常短暂的，也没有必要使用 epoll。\n因为 epoll 中的所有描述符都存储在内核中，造成每次需要对描述符的状态改变都需要通过 epoll_ctl() 进行系统调用，频繁系统调用降低效率。并且epoll 的描述符存储在内核，不容易调试。\nepoll 应用场景只需要运行在 Linux 平台上，并且有非常大量的描述符需要同时轮询，而且这些连接最好是长连接。\n参考1.【操作系统】I/O 多路复用，select / poll / epoll 详解\n","categories":["后端"],"tags":["后端"]},{"title":"Java IO 模型笔记","url":"/2023/01/24/%E5%90%8E%E7%AB%AF/unix-io-java-impl/","content":"0.UNXI IO模型简介在 Unix 系统里，磁盘的文件读写、网络通讯等功能的核心部分都是 I/O， open， read ， write ，connect 等系统调用都属于 I/O 操作。因为 I/O 操作都比较耗时，因此有了阻塞、非阻塞、同步、异步等不同 I/O 模型。  \nI/O 操作引发的阻塞是指进程中断执行，等待其它的工作（通常是比较耗时的）准备就绪再恢复。阻塞可能出现在两个阶段：  \n\n阶段一：等待数据就绪（例如从硬盘读取数据完成） \n阶段二：把数据从内核复制到用户空间，把数据从内核缓冲区复制到应用进程缓冲区\n按照《Unix Network Programming》（下称 UNP）的分类，Unix 有 5 种 I/O 模型：\n\n\n阻塞式 I/O （ Blocking I/O）\n非阻塞式 I/O （NonBlocking I/O）\nI/O 多路复用 （I/O multiplexing）\n信号驱动 I/O ( signal-driven I/O )\n异步 I/O （asynchronous I/O )\n\n1. 阻塞式 I/O （ Blocking I/O）简单来说就是调用IO的应用进程被阻塞，直到数据复制到应用进程缓冲区中才返回。\n常见的有C语言里的read()和wirte()函数\n下面是阻塞式IO的一个Java实现\npublic void start() &#123;        serverSocket = new ServerSocket(super.bindPort);        log.info(&quot;Start listing at :&quot;+serverSocket.getLocalPort());        while(true)&#123;            try &#123;                //阻塞                Socket socket = serverSocket.accept();                InputStream in = socket.getInputStream();                OutputStream out = socket.getOutputStream();                int maxLen = 2048;                byte[] contextBytes = new byte[maxLen];                //这里也会被阻塞，直到有数据准备好                int realLen = in.read(contextBytes, 0, maxLen);                String message = new String(contextBytes , 0 , realLen);                out.write(responseHTML.getBytes());                out.close();                in.close();                socket.close();            &#125;catch (Exception e)&#123;                log.error(&quot;Error From port:&quot;+serverSocket.getLocalPort());            &#125;        &#125;    &#125;\n\n在阻塞式IO的基础上，我们可以使用线程池，让每一个线程承接一个socket连接，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I/O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质： 1. 利用多核。 2. 当I/O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。\npublic class MTBIOServerThread implements Runnable&#123;        private final Socket socket;        public MTBIOServerThread(Socket socket)&#123;            this.socket = socket;        &#125;        @Override        public void run() &#123;            try &#123;                InputStream in = socket.getInputStream();                OutputStream out = socket.getOutputStream();                int maxLen = 2048;                byte[] contextBytes = new byte[maxLen];                //这里也会被阻塞，直到有数据准备好                int realLen = in.read(contextBytes, 0, maxLen);                String message = new String(contextBytes , 0 , realLen);                log.info(&quot;Receive request %&quot;+count++);                out.write(responseHTML.getBytes());                out.close();                in.close();                socket.close();            &#125;catch (Exception e)&#123;                log.error(&quot;Error From port:&quot;+e.getMessage());            &#125;        &#125;    &#125;    ServerSocket serverSocket;    @SneakyThrows    @Override    public void start() &#123;        ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newCachedThreadPool();        serverSocket = new ServerSocket(super.bindPort);        log.info(&quot;MultiThreadBIOServer Start listing at :&quot;+serverSocket.getLocalPort());        while(true)&#123;            Socket socket = serverSocket.accept();            executor.execute(new MTBIOServerThread(socket));        &#125;    &#125;\n\n接收到客户端的socket后，业务的处理过程可以交给一个线程来做，但还是改变不了socket被一个一个一个的做accept()和read()的情况。\n总的来说，阻塞式 I/O 很难应对高并发的应用场景，因为每次阻塞，都有一个进程被搁置起来，直到完成工作，才会去处理下一个请求。\ntodo 压力测试\n压力测试环境：网络：局域网服务器：\nOS：Windows 10RAM：8GCPU：i5 1035G4JDK 1.8\n测试机有八个子节点，共同运行在如下的计算机上\nOS：UbuntuRAM：16GCPU：i5 1135G7软件：locust\n\n单线程BIO服务器能取得的最好成绩是在100User的条件下，平均每秒能得到3000RPS的成绩，如果提大幅度高User到300或者是500及以上，会导致几乎显著提高的的Failure，这是因为单线程服务器的限制，多个IO同时到来会收到阻塞\n接下来相同的软件环境，让我们测试多线程服务器\n直接6000 User 拉满\n多线程服务器可以在近乎6000 Client下 0% Failure 的情况下，取得3000RPS的成绩\n接下来让我们考虑一下C10K问题\n模拟10000个User\n这时候RPS率有所增加，但是Failure可以达到 30%，而且非常消耗系统资源\n接下来终极测试 100000个UserRPS仍能保持3000-4000的水平，但是每个请求的处理延迟大大增加\n2.非阻塞式 I/O （NonBlocking I/O）在非阻塞式模型下，I/O 操作启动后，如果工作还未完成，内核会马上返回一个错误消息（EWOULDBLOCK或者EAGAIN 等) ，而不是像阻塞式一样等到完成工作再交出进程。\n应用进程执行系统调用之后，内核返回一个错误码。应用进程可以继续执行，但是需要不断的执行系统调用来获知 I/O 是否完成，这种方式称为轮询(polling)。  \n由于 CPU 要处理更多的系统调用，因此这种模型是比较低效的。\n3.I/O 多路复用如果一个 Web 服务器没有 I/O 复用，那么每一个 Socket 连接都需要创建一个线程去处理。如果同时有几万个连接，那么就需要创建相同数量的线程。并且相比于多进程和多线程技术，I/O 复用不需要进程线程创建和切换的开销，系统开销更小。\nI/O 多路复用可以让单个进程具有处理多个 I/O 事件的能力。又被称为 Event Driven I/O，即事件驱动 I/O，multiplexing 使用 select、 poll 等函数实现，使阻塞发生在 select 等函数里，而不是阻塞进程。。\nselect 可以同时监听多个文件描述符，它执行后会处于等待状态，当有一个或者多个文件描述符变成“就绪”状态，就会继续向下执行，如此循环。\n使用 select 或者 poll 等待数据，并且可以等待多个套接字中的任何一个变为可读，这一过程会被阻塞，当某一个套接字可读时返回。之后再使用 recvfrom 把数据从内核复制到进程中。\nJava NIO 常见概念NIO 实现了 IO 多路复用中的 Reactor 模型，一个线程 Thread 使用一个选择器 Selector 通过轮询的方式去监听多个通道 Channel 上的事件，从而让一个线程就可以处理多个事件。\n通过配置监听的通道 Channel 为非阻塞，那么当 Channel 上的 IO 事件还未到达时，就不会进入阻塞状态一直等待，而是继续轮询其它 Channel，找到 IO 事件已经到达的 Channel 执行。\n我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。\n创建选择器并注册通道\nSelector selector = Selector.open();//通道ServerSocketChannel ssChannel = ServerSocketChannel.open();// 配置监听的通道 Channel 为非阻塞ssChannel.configureBlocking(false);ssChannel.register(selector, SelectionKey.OP_ACCEPT);\n通过选择器监听事件\nint num = selector.select();\n获取到达的事件\nSet&lt;SelectionKey&gt; keys = selector.selectedKeys();Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();while (keyIterator.hasNext()) &#123;    SelectionKey key = keyIterator.next();    if (key.isAcceptable()) &#123;        // ...    &#125; else if (key.isReadable()) &#123;        // ...    &#125;    keyIterator.remove();&#125;\n 事件循环\n因为一次 select() 调用不能处理完所有的事件，并且服务器端有可能需要一直监听事件，因此服务器端处理事件的代码一般会放在一个死循环内。\n注意，selector.select();是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。\nwhile (true) &#123;    int num = selector.select();    Set&lt;SelectionKey&gt; keys = selector.selectedKeys();    Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();    while (keyIterator.hasNext()) &#123;        SelectionKey key = keyIterator.next();        if (key.isAcceptable()) &#123;            // ...        &#125; else if (key.isReadable()) &#123;            // ...        &#125;        keyIterator.remove();    &#125;&#125;\n\n一个简单的Java NIO 服务器实现：\nSelector selector = Selector.open();        ServerSocketChannel ssChannel = ServerSocketChannel.open();        ssChannel.configureBlocking(false);        ssChannel.register(selector, SelectionKey.OP_ACCEPT);        ServerSocket serverSocket = ssChannel.socket();        InetSocketAddress address = new InetSocketAddress(&quot;0.0.0.0&quot;, bindPort);        serverSocket.bind(address);        log.info(&quot;NIOServer Start listing with address : :&quot;+address);        while (true) &#123;                       int n = selector.select();            Set&lt;SelectionKey&gt; keys = selector.selectedKeys();            Iterator&lt;SelectionKey&gt; keyIterator = keys.iterator();            ByteBuffer readBuffer = ByteBuffer.allocate(1024);            ByteBuffer writeBuffer = ByteBuffer.allocate(1024);            while (keyIterator.hasNext()) &#123;                SelectionKey key = keyIterator.next();                /*防止下次select方法返回已处理过的通道*/                keyIterator.remove();                /*ssc通道只能对链接事件感兴趣*/                try &#123;                    if (key.isAcceptable()) &#123;                        ServerSocketChannel serverSocketChannel = (ServerSocketChannel) key.channel();                        // 服务器会为每个新连接创建一个 SocketChannel                        SocketChannel sChannel = serverSocketChannel.accept();                        sChannel.configureBlocking(false);                        // 这个新连接主要用于从客户端读取数据                        sChannel.register(selector, SelectionKey.OP_READ);                    &#125;                    /*（普通）通道感兴趣读事件且有数据可读*/                    if (key.isValid()&amp;&amp;key.isReadable()) &#123;                        SocketChannel sChannel = (SocketChannel) key.channel();                        sChannel.read(readBuffer);                        // readDataFromSocketChannel(sChannel)                        readBuffer.clear();                        key.interestOps(key.interestOps()|SelectionKey.OP_WRITE);                    &#125;                    /*通道感兴趣写事件且底层缓冲区有空闲*/                    if(key.isValid()&amp;&amp;key.isWritable())&#123;                        SocketChannel sChannel = (SocketChannel) key.channel();                        writeBuffer = ByteBuffer.wrap(responseHTML.getBytes());                        if(sChannel.isOpen())&#123;                            sChannel.write(writeBuffer);                            key.interestOps(key.interestOps() &amp; (~SelectionKey.OP_WRITE));                            sChannel.close();                        &#125;                    &#125;                &#125;catch (Exception e)&#123;                    e.printStackTrace();                    key.channel().close();                    key.cancel();                &#125;            &#125;        &#125;\n\n压力测试NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I/O操作都是纯CPU操作，没有必要开启多线程。\n模拟的NIO服务器也是一个单线程服务器在有1000-3000User时，NIO服务器可以保证1%上下的 Failure，但是在3000-10000User时，Failure率则能提高到10%上下，最终提高到100000User时候，单次请求的response时间也大幅度上升\n让我们对照一下Spring框架下的Tomacat服务器该服务器采用一个多线程的NIO模型可以看出在1000-5000的低负载下，该服务器可以在0 Failure下在8000RPS的压力下运行，在主键提高到10000User后，Failue率逐渐上升，并最终到达100000User，Failure率在30%以上，但是tomcat服务器相比于前面的多线程BIO服务器，平均响应时间较低\nPS1.使用NIO != 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。\n4. 信号驱动 I/O应用进程使用 sigaction 系统调用，内核立即返回，应用进程可以继续执行，也就是说等待数据阶段应用进程是非阻塞的。内核在数据到达时向应用进程发送 SIGIO 信号，应用进程收到之后在信号处理程序中调用 recvfrom 将数据从内核复制到应用进程中。\n相比于非阻塞式 I/O 的轮询方式，信号驱动 I/O 的 CPU 利用率更高。\n5.异步 I/O异步IO则是采用“订阅-通知”模式: 即应用程序向操作系统注册IO监听，然后继续做自己的事情。当操作系统发生IO事件，并且准备好数据后，在主动通知应用程序，触发相应的函数\n异步 I/O 与信号驱动 I/O 的区别在于，异步 I/O 的信号是通知应用进程 I/O 完成，而信号驱动 I/O 的信号是通知应用进程可以开始 I/O。\n注意在JAVA NIO框架中，我们说到了一个重要概念“selector”(选择器)。它负责代替应用查询中所有已注册的通道到操作系统中进行IO事件轮询、管理当前注册的通道集合，定位发生事件的通道等操操作；\n但是在JAVA AIO框架中，由于应用程序不是“轮询”方式，而是订阅-通知方式，所以不再需要“selector”(选择器)了，改由channel通道直接到操作系统注册监听。\nJAVA AIO框架中，只实现了两种网络IO通道“AsynchronousServerSocketChannel”(服务器监听通道)、“AsynchronousSocketChannel”(socket套接字通道)。但是无论哪种通道他们都有独立的fileDescriptor(文件标识符)、attachment(附件，附件可以使任意对象，类似“通道上下文”)，并被独立的SocketChannelReadHandle类实例引用。\n参考\nJava IO/NIO/AIO\nJava NIO浅析\n\n","categories":["后端"],"tags":["后端"]},{"title":"树莓派ZeroW 安装kali折腾记录","url":"/2023/07/09/%E6%8A%98%E8%85%BE/raspberry-pi-zero-kali-log/","content":"0. 序言最近不经意间看到树莓派降价的新闻两年了！！！树莓派6月价格骨折！眼看它起高楼，眼看它楼塌了\n，tb上450就能搞到一块8G的4B，但是最近经济紧缩政策之下，规划400预算也不是一件容易的事情，而且宿舍里有一个还算稳定的X86软路由，对树莓派也就是简简单单用kali抓个包（觉得单独买一块监听网卡不值得），碰巧又看到了b站上折腾bad usb 项目：P4wnP1_ALOA\n的项目,由此发现了树莓派Zero W，这玩意虽然性能不好，但是只要145r，还有树莓派的核心竞争力-社区支持，于是火速下单搞了一块，顺带东哥家买了32G的内存卡&amp;读卡器。\n1. 系统刷写因为WSL这么折腾都读不到读卡器的缘故，又不想装一个物理机，索性直接用 Raspberry Pi Imager 刷写SD卡了之，这玩意还能下各种镜像，感觉还行。\n其实更推荐的方式不是刷入kali官方镜像，而是直接去刷P4wnP1_ALOA的镜像：\n\n项目地址 https://github.com/RoganDawes/P4wnP1_aloa\n镜像下载 https://github.com/RoganDawes/P4wnP1_aloa/releases/tag/v0.1.1-beta\n\n因为其中自带kali，而刷官方镜像还需要去装P4wnP1_ALOA，很麻烦的\n2.启动前配置这里给两种配网方式：通过wifi连接树莓派和通过usb连接树莓派，（都是基于SSH）\n2.1 wi-fi配置参考：[教學] Raspberry Pi Zero W 如何 headless 安裝 Kali Linux\n\n用 Notepad 打開 SD Card 上 wpa_supplicant.conf，填入你的接入wifi的信息：\nnetwork=&#123;        ssid=&quot;homenet&quot;        psk=68002fbdacc8812f89c06a2fb6542b2b1126853983a59e0076e5f56df9c5543b        id_str=&quot;home&quot;        priority=2&#125;\n\n在WSL等Linux环境中执行wpa_passphrase，计算出接入wifi的psk\nwpa_passphrase &quot;My-Wifi-SSID&quot; &quot;My-Password&quot;\n\nexample：\nxrervip@F-pc:/mnt/c/Users/fzquantum$ wpa_passphrase &quot;Mi 10S&quot; &quot;66666666&quot;network=&#123;        ssid=&quot;Mi 10S&quot;        #psk=&quot;66666666&quot;        psk=912a419249f483a6a5aff81211b462d6938ea03c85babfc06b393b53c6c0175a&#125;\n记得补充  id_str=&quot;home&quot; 字段然后写入 sd卡boot分区  wpa_supplicant.conf 文件中\n除此之外，notepad打开boot根目录下的 interfaces 文件，给该接入点配置上DHCP ，不然可能就分配不了IP地址进而无法连接了。\n2.2 usb网络配置2.3 后续配置都是一些优化选项，不配置也行，个人感觉最有用的是avahi-daemon.service,这个可以让你通过域名hostname + &quot;.local&quot;而不是ip的方式直接访问你的树莓派\nsudo apt update# configure timezone and locales for terminal access.sudo dpkg-reconfigure tzdatasudo dpkg-reconfigure locales# use raspi-config to change the boot option to console mode so as to save memory usage to avoid GUI on boot up.# and change hostname as requiredsudo raspi-config# start mDNS so that you can use hostname + &quot;.local&quot; instead of IP addresssudo systemctl enable avahi-daemon.servicesudo systemctl start avahi-daemon.service\n\n3. WiFi-Crack3.1 创建监听接口wlan0monairmon-ng check kill &amp;&amp; airmon-ng start wlan0\n\n执行airmon-ng check kill会关闭很多服务，例如之前配的域名解析avahi-daemon.service，导致需要去翻ip地址；但是同时也会关闭现有的wi-fi连接 ，减少抓包的时候的干扰,不想这么做的话，可以执行下面的命令。\nairmon-ng start wlan0\n\n3.2 采集流量airodump-ng wlan0mon\n\n\n3.3 选择目标，抓取握手包以抓取98:97:CC:61:40:??为例：\nairodump-ng wlan0mon --bssid 74:5A:7A:B0:77:14 -c 1 -w /root/crack/xiangle521/xiangle521\n\n参数：\n\nbssid 抓取对象的ssid\nc 信道 注意信道要选择正确的\nw 输出抓包文件的地址\n\n为了更快的抓到握手包，对其进行掉线攻击，设备重连后我们便可以抓到WPA握手包\naireplay-ng wlan0mon -0 0 -a 74:5A:7A:B0:77:14 \n\n参数：\n\n-0 攻击方式\n-a 攻击目标的ssid\n\n更精准的攻击方式是附带上客户端的mac地址 用参数 -c 附加\n3.4 hashcat 跑包4. P4wnP1_ALOAtodo\n","categories":["折腾"],"tags":["折腾"]},{"title":"红米2 安装 postmarketOS(基于 Alpine Linux)及后续玩法","url":"/2022/07/03/%E6%8A%98%E8%85%BE/redmi2linux/","content":"本来笔者想买一个Armbian的斐讯N1盒子来运行一些docker容器，但是突然想到有一部闲置的红米2，于是乎便寻找方法看看能否将其刷入Linux解锁更多玩法。\n红米2增强版拥有2G RAM和 16G ROM 和晓龙410处理器，作为手机早已过时，但是作为一台ARM服务器则绰绰有余。\n刷机1.进入fastboot模式关机情况下，电源键+音量减进入fastboot模式，因为红米2 发行的年代尚且不流行BL锁，所以无需考虑解锁问题。\n2. 刷入postmarketOS系统2.1 检查是否刷入了最新固件\n使用了安卓版本为5以上的MIUI可以跳过此步骤\n使用了安卓版本为4的的MIUI请更新固件,(不过更简单的方式是线刷一个安卓5的MIUI)下载红米 2/2A (wt86047) 稳定版刷机包 MIUI9\n\n固件下载地址：https://www.androidfilehost.com/?w=files&amp;flid=303434\n红米2有增强&amp;标配区分，小米给红米2挺多个设备名\n标配(官方4.4) 2014811、2014812…(太多不列出来了，一般201481x对于刷第三方来说没特殊区分)\n增强(官方5.1) wt86047(移动)、wt88047(联通&amp;电信)\n对于标准版 下载连接中对应的wt88047的文件，增强版下载wt86047\n不知道的话，打开设置，导航到“手机信息”，并记下“型号”标题下方的型号\n\n 2014811, 2014812, 2014817 2014818, 2014819,  2014821 ：wt88047.\n 2014813,  2014112 ： wt86047.\n\n下载固件文件后，在miui里通过adb sideload 安装\n在设备中，选择“高级”，“ADB Sideload”，然后滑动开始sideload在电脑命令行输入如下指令\nadb sideload firmware.zip\n\n2.2 安装lk2nd作为2nd bootloader虽然小米已经给我们提供了一个默认的bootloader，但是还需要在原有基础上额外安装一个自定义的bootloader 来给运行linux环境提供更多硬件支持，因此需要安装lk2nd\nGithub项目地址：lk2nd，请在github的release页面里下载lk2nd-msm8916.img 文件（k2nd-msm8916.img）\n建议安装最新版lk2nd，因为0.9版本只开放了单CPU，而0.11版之后才能开启全部四核心。刷入lk2nd指令如下：\nfastboot flash boot lk2nd-msm8916.imgfastboot reboot\n\n没问题的话，重启后手机会显示如下的画面：lk2nd的主界面\n2.3 刷入 postmarketOS固件下载地址：https://images.postmarketos.org/bpo/v22.06/xiaomi-wt88047/\n这里有三个ROM 随便选一个下载即可，反正最后也使用终端和手机进行交互，GUI不是很重要。\nPhosh_mt88047.imgPhosh_mt88047_boot.img\n\n三种UI如下图所示：\n重启后手机显示lk2nd界面，重新连接到电脑的fastboot，在电脑的命令行中执行如下的fastboot指令刷入ROM\nfastboot flash boot phosh-18-xiaomi-wt88047-boot.imgfastboot flash userdata phosh-18-xiaomi-wt88047.imgfastboot erase systemfastboot reboot\n\nPS1:lk2nd 0.10.0 版本之后，不需要再刷入传统的*-boot.img文件，所以可以考虑跳过刷入该文件。\n刷机完成后，重启手机，进入系统！\n安装软件1.解锁手机进入图形界面postmarketOS提供的默认用户名：user 密码 147147 PIN 147147，使用该密码解锁手机即可进入系统\n2.开启SSH ServerpostmarketOS 默认不开启sshd，因此我们需要手动开启，在手机上的终端机软件中输入如下的指令：\nsudo service sshd start #开启SSH Server 服务sudo rc-update add sshd # 开机启动SSHD 服务\n\n再说一遍sudo密码 147147 \n开启后手机连接到局域网就可以ssh连接到终端了\nssh user@IP地址\n有需要的话可以编辑 sshd_config 文件，postmarketOS 没有预置nano vim等编辑器，所以使用vi编辑\nsudo vi /etc/ssh/sshd_config\n\n3. 包管理器apk postmarketOS使用apk作为包管理\n 换源前首先看一下PostmarketOS的Alpine Linux版本（cat /etc/alpine-release），目前的PostmarkOS的内核版本应该是3.16：\n然后编辑源配置文件\nsudo vi /etc/apk/repositories\n增加源地址\nhttp://mirrors.aliyun.com/alpine/v3.16/mainhttp://mirrors.aliyun.com/alpine/v3.16/community\n替换源地址后，更新一下\nsudo apk updatesudo apk upgrade -a\n\n4.安装Bash并设为默认终端PostmarkOS默认的Bash为ash，为了更好的使用选择更熟悉的Bash作为默认终端\nsudo apk add bash #安装bashsudo vi /etc/passwd #修改默认配置\n以root和user账户为例修改其默认终端\nroot:x:0:0:root:/root:/bin/ash↓root:x:0:0:root:/root:/bin/bashuser:x:10000:10000:Linux User,,,:/home/user:/bin/ash↓user:x:10000:10000:Linux User,,,:/home/user:/bin/bash\n\n还有一种方式就是直接用chsh指令例如：\nchsh -s /bin/bash\n\n5. 安装Nano作为编辑器相比于vi，nano更适合新手使用,用下面的指令可以一键安装\nsudo apk add nano \n便可以使用nano来编辑一些系统文件\n6.安装docker给旧手机安装linux，主要目的就是利用docker来运行各种容器。\nsudo apk add docker #安装dockersudo service docker start #启动docker服务sudo rc-update add docker default #设置docker为自启动\n根据网上的教程， postmarketOS中的docker可能会因为防火墙的原因导致docker的端口无法通过外部访问。\n正确解决这个问题的手段是通过配置防火墙规则允许docker通信,但是省事的方法是鉴于手机服务器的用途，直接停用防火墙。\nsudo service nftables stopsudo rc-update del nftables\n然后安装可视化图形工具Portainer看看是否能正常使用,同时作为日常管理容器的工具，\ndocker pull portainer/portainer docker run -d -p 9000:9000 --restart=always --name portainer -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer\n初始化之后就可以正常使用了\n开启定时计划运行服务 cronsudo rc-update add crond default\n可选优化1. 停用GUI（可选）停用GUI可以节省大量内存，用更多的资源来运行我们的容器等服务。\n根据官网wiki上的介绍https://wiki.postmarketos.org/wiki/Phosh#Starting_Phosh对于我们之前安装的 phosh 镜像，其GNOME图形界面的维持是靠tinydm这个图形界面管理器实现的，因此停用GUI只需要禁用该服务便能停用GUI。\nsudo rc-update del tinydm\n然后reboot重启即可，大约可以节约出500MB以上的内存空间\n这样开机就不会进入图形界面，卡在loading界面，过一段时间后便自动息屏。\n需要恢复只需要运行\nsudo rc-update add tinydm default\n\n2. 停用modemmanager（可选） ModemManager用来控制移动宽带（2G/3G/4G）设备和连接，提供统一的高层API接口，类似于NetworkManager进行网络连接的移动宽带设备/连接，说白了就是可以用来管理手机卡,如果不需要插入上网卡做热点机的话，可以考虑将其停用。 sudo rc-update del modemmanager需要恢复只需要运行下面的指令：\nsudo rc-update add modemmanager default","categories":["折腾"],"tags":["折腾"]},{"title":"AmongUs私服游玩指南","url":"/2022/02/13/%E5%B7%A5%E5%85%B7/AmongUs20210630/","content":"首要配置文件方法一点击下面的连接下载regionInfo.json\n方法二自己创建点击网址https://impostor.github.io/Impostor/要在私人服务器上玩，请按照以下步骤操作：输入服务器 IP 并下载单击“下载服务器文件”按钮。IP      120.53.249.36 端口    22023 确保文件名为 regionInfo.json\nWindows\n点我下载游戏文件（需要后台登录运行Steam）\n下载regionInfo.json \n按键盘上的Windows键 + R 打开运行框并粘贴以下内容：\n\n%APPDATA%\\..\\LocalLow\\Innersloth\\Among Us\n\n然后按 Enter 或单击“确定”。（提示没有对应的目录请启动一次游戏然后关闭）4. 复制下载的文件并将其粘贴到打开的文件夹中并覆盖原有的。5. 您现在可以通过打开among-us并单击“在线”在您的服务器上玩。6. 要切换回原始服务器，请更改右下角的区域。\nAndroid下载APK安装包并安装com.innersloth.spacemafia_2021.6.30.apk\n下载服务器文件并覆盖现有的 regionInfo.json 文件，现在有两种方法1.（手动）打开手机中的文件管理器 进入 目录下面的 ，覆盖相应的文件，（提示没有对应的目录请启动一次游戏然后关闭）\n内部存储/Android/data/com.innersloth.spacemafia/files\n无法访问请下载安装最新版MT管理器-&gt;MT管理器酷安下载 通过系统授予MT管理器访问/Android/data/ 目录的权限即可2.（自动）下载自动修改应用程序：Crewmate-switcherPS：由于 Android 11和MIUI 12(Android 10) 有防止应用访问其他应用文件的保护，请使用方法1.项目地址：https://github.com/NaokiStark/Crewmate-switcher/蓝奏云分流：https://wwa.lanzouv.com/ivLgn00co09g在应用主界面填写服务器IP和端口号点击SWITCH按钮即可:IP      120.53.249.36 端口    22023  \niOS 如果您的手机已越狱，您可以从 pixelomer 的 repo 安装 ImpostorConfig 调整或下载 regionInfo.json 文件并使用 Filza 将其复制到 /var/mobile/Containers/Data/Application/Among Us/Documents。\n如何修改用户名？Windows手动操作：\n0.修改用户名前需要进入一次游戏 输入信息进入主界面，最好修改语言为简中 （因为修改用户名需要给用户配置文件加只读权限，所以不能再从游戏内修改）\n\n按键盘上的Windows键 + R 打开运行框并粘贴以下内容：\n\n%APPDATA%\\..\\LocalLow\\Innersloth\\Among Us\n\n然后按 Enter 或单击“确定”。（提示没有对应的目录请启动一次游戏然后关闭）2.进入目录用文本编辑器（记事本）打开playerPrefs 文件，文件中第一个单词即为用户名，修改为你想要的数值即可，记得保存。3.在文件夹中右键 playerPrefs 文件 点击属性，在属性窗口中的属性一栏中点击只读前的框，将其设置为只读属性。4.点击确认即可.\nAndroid\n下载安装最新版MT管理器-&gt;MT管理器酷安下载 通过系统授予MT管理器访问/Android/data/ 目录的权限即可\n\nPS : 如果需要修改游戏内某项设置，或者进入游戏提示输入生日出现bug卡住的话，记得取消playerPrefs 文件的只读属性。\n","categories":["工具"],"tags":["工具"]},{"title":"欢迎使用teamspeak3","url":"/2021/10/19/%E5%B7%A5%E5%85%B7/invitToTeamspeak3/","content":"\n\n\n\nTeamSpeak 3 Server Invitation\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou have been invited to this TeamSpeak 3 Server:\n\n\n    \n    121.89.218.85:9987      \n\n\nURL: ts3server://121.89.218.85\n\n\n\nIf TeamSpeak 3 is installed on your computer, you are now being redirected to the server.If you are not automatically redirected within 5 seconds, please click HERE instead.\n\n\n\n\n\n","categories":["工具"],"tags":["工具"]},{"title":"Python 调用 HTTP API 接口模板","url":"/2021/08/09/%E5%B7%A5%E5%85%B7/PythonHttpAPI/","content":"搜索引擎上获取的代码大多鱼龙混杂，因此自己写一个保存以待后用\n#!/usr/bin/env python# -*- coding:utf-8 -*-#@Time  : 2021/8/9 20:30#@Author: f#@File  : main.pyimport requestsdef sendPost(param1,param2):        base_url = &#x27;http://url/&#x27;    data =&#123;        &#x27;param1&#x27;:param1,        &#x27;param2&#x27;:param2    &#125;    headers = &#123;        &#x27;User-Agent&#x27;: &#x27;Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)&#x27;,        &#x27;Accept&#x27;: &#x27;text/html, application/xhtml+xml, */*&#x27;    &#125;        session = requests.session()    response = session.post(base_url, data=data,headers=headers, verify=False)        print(response.text)if __name__ == &#x27;__main__&#x27;:    param1=&#x27;param1&#x27;    param2=&#x27;param2&#x27;    sendPost(param1,param2)\n","categories":["工具"],"tags":["工具"]},{"title":"TeamSpeak快速帮助","url":"/2021/08/03/%E5%B7%A5%E5%85%B7/TeamSpeak%E5%BF%AB%E9%80%9F%E5%B8%AE%E5%8A%A9/","content":"TeamSpeak快速帮助：TeamSpeak资源下载\n这里给两个下载地址：\n\nhttps://wwa.lanzoui.com/ilq7Es5231e TeamSpeak中文绿色版，不需要安装，开箱即用\nhttps://wwa.lanzoui.com/iMYHls52alg安装版，需要走一遍安装流程建议有功夫的话使用安装版  \n俺的Teamspeak地址：IP：快速连接121.89.218.85或者是域名 记忆ts.xrervip.tk  \n\n快速连接点我快速连接到121.89.218.85如果没有安装请点击\n使用方法下载下面来说说使用方法，此处会从安装开始说起，以方便新用户进行使用。建议不要使用某国内公司制作的中文翻译版ts1.cn，该版本过旧，无法登陆现有的大部分 TeamSpeak 服务器\n第一步，下载 TeamSpeak 此处可以前往 TeamSpeak 官网 teamspeak.com 进行下载，也可以通过转存蓝奏云地址进行下载，解决国内在官网下载速度过慢的问题这里给两个下载地址：\n\nhttps://wwa.lanzoui.com/ilq7Es5231e TeamSpeak中文绿色版，不需要安装，开箱即用\nhttps://wwa.lanzoui.com/iMYHls52alg安装版，需要走一遍安装流程建议有功夫的话使用安装版ps：安装版可能需要中文语音包下载地址 https://github.com/jitingcn/TS3-Translation_zh-CN/releases\n\n连接至服务器快速连接点我快速连接到121.89.218.85\n手动连接点击主界面上面的工具栏中 连接(Connect) - 连接，在 服务器域名或地址（Server Nickname or Address） 的位置输入服务器地址（121.89.218.85 或者ts.xrervip.tk），昵称（ Nickname） 位置输入昵称后，点击 连接(Connect) 即可。PS：俺的Teamspeak地址：121.89.218.85\n常见问题如何设置感应麦？（在嘈杂的环境中对队友特别舒适）点击工具栏中的工具(Tools) ，在菜单中打开最下方设置(Options) 菜单目录 ，选择第四栏输入(Capture) 选项卡。可以在右侧的 配置 中看到 语音感应激活(Capture Voice Activation)选项，模式选择 Volume Gate。\n下方的滑杆代表感应灵敏度，您可以通过点击 开始测试(Begin test) 用平时的嗓音进行测试。一般情况下，推荐打开下方数字信号处理的回声抑制(Echo reduction) 回声消除(Echo cancellation) 以及 消除背景噪音，但具体请根据个人情况及设备的不同，自行判断。\n\n感应麦可能出现的问题？ 话别人只能听到后半句 / 录入过多杂音一般此情况为灵敏度配置不当导致的。通过调节语音感应激活中提到的滑杆，滑杆越往左越灵敏，不断地测试，找到适合自己的灵敏度即可解决此问题。\n内容抄袭自https://ts.wevg.org/why-teamspeak/\n\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n","categories":["工具"],"tags":["工具"]},{"title":"使用PowerShell下载文件","url":"/2021/10/02/%E5%B7%A5%E5%85%B7/powershellDownload/","content":"使用PowerShell下载文件\npowershell (new-object System.Net.WebClient).DownloadFile(&#x27;文件的URL&#x27;,&#x27;文件本地存储的地址&#x27;)\n例如\npowershell (new-object System.Net.WebClient).DownloadFile(&#x27;http://121.89.218.85/frp_0.37.1_windows_amd64.zip&#x27;,&#x27;C:\\Users\\Administrator\\frp_0.37.1_windows_amd64.zip&#x27;)\n\n","categories":["工具"],"tags":["工具"]},{"title":"teamspeak3","url":"/2021/08/02/%E5%B7%A5%E5%85%B7/teamspeak3/","content":"快速获取帮助：TeamSpeak资源下载这里给两个下载地址：\n\nhttps://wwa.lanzoui.com/ilq7Es5231e TeamSpeak中文绿色版，不需要安装，开箱即用\nhttps://wwa.lanzoui.com/iMYHls52alg安装版，需要走一遍安装流程建议有功夫的话使用安装版  \n俺的Teamspeak地址：121.89.218.85\n\n什么是 TeamSpeakTeamSpeak (简称TS) 是一套专有的VoIP软件，使用者可以用耳机和麦克风，通过客户端软件连线到指定的服务器，与在服务器内频道的其他使用者进行通话。是一种很像电话会议的方式。 通常 TeamSpeak 的使用者大多为多人连线游戏的玩家，与同队伍的玩家进行通讯。在游戏的对战方面，语音对话通讯具有竞争优势。\n简单来说，就是一款语音软件，那么有的人可能会问了，那我为什么不直接使用游戏内的语音软件，或者其他的，例如 Discord 或者 YY语音呢？\n为什么我们使用 TeamSpeak为什么不用 YY 语音使用YY需要绑定个人手机，注册需要花1毛钱发短信  \n首先，先说一下广告方面，yy的弹窗和花里胡哨的推广是真的难受，而且还会占用大量的硬件系统资源和宝贵的网络带宽。\n其次，捆绑软件方面，安装 YY 后，同时会捆绑 YY浏览器等软件。\n第三，YY语音并不支持语音感应(感应麦克风，即达到一定分贝才会录入)，自由麦什么杂音都给你收进去，除此之外YY语音还会有明显的网络延迟\n除此之外，YY不授权自主建立服务器，而TeamSpeak允许用户在自己的计算机上建立32人以下的TeamSpeak服务器\n总而言之，一个语音交流软件，界面干净没有广告没有延迟，那它就是满分的语音软件,很可惜，YY没有做到上面的任意一点\n为什么不用 Discord这个原因很简单，被墙了，就算上了延迟也很高\n为什么使用 TeamSpeak首先 TeamSpeak 没有广告，没有捆绑软件，可以单独调节每个用户的音量大小等等等等。至于服务器方面，TeamSpeak 的服务器一般都是自行租赁或架设的。支持毫秒级超低延迟，适合于对语音即时通讯有严格要求的团队游戏、远程会议等场合 ，管理员可以单独调整每个玩家的语音音量。\n除此之外，如果您想的话，甚至可以在自己的服务器搭建一台 TeamSpeak 服务器。\n使用方法下载下面来说说使用方法，此处会从安装开始说起，以方便新用户进行使用。建议不要使用某国内公司制作的中文翻译版ts1.cn，该版本过旧，无法登陆现有的大部分 TeamSpeak 服务器\n第一步，下载 TeamSpeak 此处可以前往 TeamSpeak 官网 teamspeak.com 进行下载，也可以通过转存蓝奏云地址进行下载，解决国内在官网下载速度过慢的问题这里给两个下载地址：\n\nhttps://wwa.lanzoui.com/ilq7Es5231e TeamSpeak中文绿色版，不需要安装，开箱即用\nhttps://wwa.lanzoui.com/iMYHls52alg安装版，需要走一遍安装流程建议有功夫的话使用安装版ps：安装版可能需要中文语音包下载地址 https://github.com/jitingcn/TS3-Translation_zh-CN/releases\n\n连接至服务器点击主界面上面的工具栏中 连接(Connect) - 连接，在 服务器域名或地址（Server Nickname or Address） 的位置输入服务器地址（121.89.218.85 或者ts.xrervip.tk），昵称（ Nickname） 位置输入昵称后，点击 连接(Connect) 即可。PS：俺的Teamspeak地址：121.89.218.85\n常见问题如何设置感应麦？（在嘈杂的环境中对队友特别舒适）点击工具栏中的工具(Tools) ，在菜单中打开最下方设置(Options) 菜单目录 ，选择第四栏输入(Capture) 选项卡。可以在右侧的 配置 中看到 语音感应激活(Capture Voice Activation)选项，模式选择 Volume Gate。\n下方的滑杆代表感应灵敏度，您可以通过点击 开始测试(Begin test) 用平时的嗓音进行测试。一般情况下，推荐打开下方数字信号处理的回声抑制(Echo reduction) 回声消除(Echo cancellation) 以及 消除背景噪音，但具体请根据个人情况及设备的不同，自行判断。\n\n感应麦可能出现的问题？ 话别人只能听到后半句 / 录入过多杂音一般此情况为灵敏度配置不当导致的。通过调节语音感应激活中提到的滑杆，滑杆越往左越灵敏，不断地测试，找到适合自己的灵敏度即可解决此问题。\n内容抄袭自https://ts.wevg.org/why-teamspeak/\n","categories":["工具"],"tags":["工具"]},{"title":"美团24暑期实习面经","url":"/2023/03/24/%E9%9D%A2%E8%AF%95/2023-meituan-intern/","content":"美团 【转正实习】后端开发工程师\n官网投递，3月18日（周六）笔试 a了3.7题 3月20日（周一）约了3月21日一面3月23日发了二面通知，约了24日的二面面试官友善度尚可，至少不刁难\n一面 50min\n\n自我介绍\n研究生的研究方向\n简历上写的项目两个选一个具体介绍 问了项目里一些概念，情景\n项目里用到了几种数据库表，表结构？\nTCP 为什么需要四次挥手\nHTTP 在计网参考模型里是哪个层的\nHTTP 1.0 和 1.1 的区别\n项目里用到了Redis的哪几种数据结构\nRedis 里List是怎么扩增的（按照java里hashmap回答了Hash的扩增 不太对）\n介绍一下Mysql的几种索引类型\n介绍一下聚簇索引和非聚簇索引 \n介绍一下 B+树 B树\n项目里用到了MyBatis，介绍一下？\n用到了什么数据库连接池 （阿里的Druid）\n数据库连接池有什么用\n有没有看过Druid 的源代码（没有）\n\n算法题：leetcode：143. 重排链表 （mid）\n反问\n\n套了一下面试评价（回答是 算法和计算机基础还行 工程能力欠缺 ）\n\n二面 40min\n\n自我介绍\n问一下兴趣爱好 （聊天）\n了解chatgpt吗，是否应用在学习和开发中（聊天）\n都用过什么编程语言，为什么选择java，年度代码量 （聊天）\n面试官看了下简历上的github页面，介绍了一下repo（聊天）\n最近在读什么技术类书籍（聊天）\n简历上两个项目，自选一个深入介绍一下，问了很多项目相关的问题 大概就是技术选型 ，为什么用这种技术，问的不是很深入，也问了项目相关的概念\n有没有系统地学习过操作系统相关的知识\n了解计算机网络吗\n知道RPC吗，介绍一下\n具体介绍一下 HTTP 报文的详细结构 （Url Header Body 那一套）\n选一个简历上列举的技能领域，详细问（面试前简单刷了一遍mysql，面试官接下来就问数据库相关的八股）\nmysql 索引介绍，索引有几种具体的数据结构（B+树之类） \n上一问回答了B+树 B 树 Hash索引 ，进一步解释一下这几种索引的区别，优劣\n还有什么索引？ 回答了 全文索引 但是面试官说不是 （面后想了一下可能是Trie树）\n介绍一下全文索引 怎么构建\n了解Elasticsearch 吗（知道这个是什么 但是不了解 应该之前提到了全文索引）\n怎么看MySQL中一个查询用没有用索引 （explain ）\n介绍一下什么是 Mysql 事务\n介绍一下 Mysql 常见的几种锁\n介绍一下 Mysql 事务的隔离级别\n介绍一下乐观并发控制与悲观并发控制\n学习数据库时怎么查阅技术资料 （博客+论文）\n有没有读过数据库相关论文（说了一下关系型数据库的奠基作 还有些其他的）\n了解OLAP吗 为什么最近没人用了 （编了点）\n对SQL和No-SQL数据库的简单理解和举例\n介绍一下读过的几篇数据库相关论文\n面试官提到了 VoltDB （好像是数据库领域一篇顶会提出的db）问看没看过（没有）\n遇到领域内的新问题，如何解决 （问老师呗，还能咋办）\n\n反问\n\n套了一下面试评价（回答是 还行）\n问一下组里的技术栈\n\n算法题：面试官看没多少时间了，直接说懒得出了\noc：二面晚上八点hr打电话，确认了工资和入职时间，说下周一正式发offer\n","categories":["面经"],"tags":["面经"]},{"title":"下载 4399 FLASH 游戏","url":"/2021/08/28/%E8%84%9A%E6%9C%AC%E5%B0%8F%E5%AD%90/4399download/","content":"快速帮助http://sda.4399.com/4399swf/\n后面拼接上HTML文件中找到的swf后缀文件相对的相对地址，例如\nhttp://sda.4399.com/4399swf/upload_swf/ftp/20070524/4.swf\n\n\n年份够久 就可以有情怀Adobe Flash Player——一个足够暴露年龄的名词，如果你的网龄足够长的话，一定不会感到陌生，但是早在2017年，Adobe 就宣布会在2020年底前停止对 Flash 的支持和开发。现在，各种浏览器纷纷宣布他们的 Flash 淘汰计划，其中就包括了微软，随着2021年的到来，Adobe 也正式终止了旗下 Flash 产品的支持，因此我们再也无法像往常一样在 Chrome 浏览器中游玩例如4399提供的 Flash 游戏  \n\n“公司已经选择关闭Flash，因为其他技术（如HTML5）已经足够成熟，足以提供Flash播放器可行的替代品”。不过他同时也说：“在互联网时代，很少有技术能产生如此深远而积极的影响。” \n\n首先在前端抓取4399的游戏加载地址Flash 游戏文件一般后缀都是 swf 文件，于是打开 F12 检查 HTML文件在JavaScript代码中用文本匹配搜索有关 .swf 后缀的文本地址\n例如图中的 _strGamePath=&quot;/upload_swf/ftp/20070524/4.swf&quot;;\n不过很显然 这只是一个相对地址，仅凭相对地址我们是没有办法下载的,我们还需要一个绝对地址\n继续分析网页的结构，在 js 文件夹下有一个 serversda.js 文件,打开它我们会发现有关 FTP 服务器的描述\n\nvar webServer = &quot;//sda.4399.com/4399swf&quot;;    var sPicServer = &quot;img.4399.net:8080&quot;;\n其中 http://sda.4399.com/4399swf 就是我们要找的前缀在后面再拼接上我们的之前找到的swf相对地址，用浏览器或下载工具打开，就可以下载游戏文件了  \n\n安装无广告无插件的国际版adobe flash player下载地址1：https://www.lanzoui.com/b083kq90h 密码：cyxt  \n将下载的 swf 文件用 adobe flash player 打开即可运行\n\n","categories":["脚本小子"],"tags":["脚本小子"]},{"title":"中文文案排版指北","url":"/2021/08/06/%E9%80%9A%E7%94%A8%E5%BC%80%E5%8F%91/chinese-copywriting-guidelines/","content":"中文文案排版指北Other languages:\n\nEnglish\nChinese Traditional\nChinese Simplified\n\n\n目录\n\n\n中文文案排版指北\n目录\n空格\n中英文之间需要增加空格\n中文与数字之间需要增加空格\n数字与单位之间无需增加空格\n全角标点与其他字符之间不加空格\n-ms-text-autospace to the rescue?\n\n\n标点符号\n不重复使用标点符号\n\n\n全角和半角\n使用全角中文标点\n数字使用半角字符\n遇到完整的英文整句、特殊名词，其內容使用半角标点\n\n\n名词\n专有名词使用正确的大小写\n不要使用不地道的缩写\n\n\n争议\n链接之间增加空格\n简体中文使用直角引号\n\n\n工具\n谁在这样做？\n参考文献\n\n\n\n\n\n空格「有研究显示，打字的时候不喜欢在中文和英文之间加空格的人，感情路都走得很辛苦，有七成的比例会在 34 岁的时候跟自己不爱的人结婚，而其余三成的人最后只能把遗产留给自己的猫。毕竟爱情跟书写都需要适时地留白。\n与大家共勉之。」\n中英文之间需要增加空格正确：\n\n在 LeanCloud 上，数据存储是围绕 AVObject 进行的。\n\n错误：\n\n在LeanCloud上，数据存储是围绕AVObject进行的。\n\n\n在 LeanCloud上，数据存储是围绕AVObject 进行的。\n\n完整的正确用法：\n\n在 LeanCloud 上，数据存储是围绕 AVObject 进行的。每个 AVObject 都包含了与 JSON 兼容的 key-value 对应的数据。数据是 schema-free 的，你不需要在每个 AVObject 上提前指定存在哪些键，只要直接设定对应的 key-value 即可。\n\n例外：「豆瓣FM」等产品名词，按照官方所定义的格式书写。\n中文与数字之间需要增加空格正确：\n\n今天出去买菜花了 5000 元。\n\n错误：\n\n今天出去买菜花了 5000元。\n\n\n今天出去买菜花了5000元。\n\n数字与单位之间无需增加空格正确：\n\n我家的光纤入户宽带有 10Gbps，SSD 一共有 10TB。\n\n错误：\n\n我家的光纤入户宽带有 10 Gbps，SSD 一共有 20 TB。\n\n另外，度／百分比与数字之间不需要增加空格：\n正确：\n\n今天是 233° 的高温。\n\n\n新 MacBook Pro 有 15% 的 CPU 性能提升。\n\n错误：\n\n今天是 233 ° 的高温。\n\n\n新 MacBook Pro 有 15 % 的 CPU 性能提升。\n\n全角标点与其他字符之间不加空格正确：\n\n刚刚买了一部 iPhone，好开心！\n\n错误：\n\n刚刚买了一部 iPhone ，好开心！\n\n-ms-text-autospace to the rescue?Microsoft 有个 -ms-text-autospace 的 CSS 属性可以实现自动为中英文之间增加空白。不过目前并未普及，另外在其他应用场景，例如 OS X、iOS 的用户界面目前并不存在这个特性，所以请继续保持随手加空格的习惯。\n标点符号不重复使用标点符号正确：\n\n德国队竟然战胜了巴西队！\n\n\n她竟然对你说「喵」？！\n\n错误：\n\n德国队竟然战胜了巴西队！！\n\n\n德国队竟然战胜了巴西队！！！！！！！！\n\n\n她竟然对你说「喵」？？！！\n\n\n她竟然对你说「喵」？！？！？？！！\n\n全角和半角不明白什么是全角（全形）与半角（半形）符号？请查看维基百科词条『全角和半角』。\n使用全角中文标点正确：\n\n嗨！你知道嘛？今天前台的小妹跟我说「喵」了哎！\n\n\n核磁共振成像（NMRI）是什么原理都不知道？JFGI！\n\n错误：\n\n嗨! 你知道嘛? 今天前台的小妹跟我说 “喵” 了哎!\n\n\n嗨!你知道嘛?今天前台的小妹跟我说”喵”了哎!\n\n\n核磁共振成像 (NMRI) 是什么原理都不知道? JFGI!\n\n\n核磁共振成像(NMRI)是什么原理都不知道?JFGI!\n\n数字使用半角字符正确：\n\n这件蛋糕只卖 1000 元。\n\n错误：\n\n这件蛋糕只卖 １０００ 元。\n\n例外：在设计稿、宣传海报中如出现极少量数字的情形时，为方便文字对齐，是可以使用全角数字的。\n遇到完整的英文整句、特殊名词，其內容使用半角标点正确：\n\n乔布斯那句话是怎么说的？「Stay hungry, stay foolish.」\n\n\n推荐你阅读《Hackers &amp; Painters: Big Ideas from the Computer Age》，非常的有趣。\n\n错误：\n\n乔布斯那句话是怎么说的？「Stay hungry，stay foolish。」\n\n\n推荐你阅读《Hackers＆Painters：Big Ideas from the Computer Age》，非常的有趣。\n\n名词专有名词使用正确的大小写大小写相关用法原属于英文书写范畴，不属于本 wiki 讨论內容，在这里只对部分易错用法进行简述。\n正确：\n\n使用 GitHub 登录\n\n\n我们的客户有 GitHub、Foursquare、Microsoft Corporation、Google、Facebook, Inc.。\n\n错误：\n\n使用 github 登录\n\n\n使用 GITHUB 登录\n\n\n使用 Github 登录\n\n\n使用 gitHub 登录\n\n\n使用 gｲんĤЦ8 登录\n\n\n我们的客户有 github、foursquare、microsoft corporation、google、facebook, inc.。\n\n\n我们的客户有 GITHUB、FOURSQUARE、MICROSOFT CORPORATION、GOOGLE、FACEBOOK, INC.。\n\n\n我们的客户有 Github、FourSquare、MicroSoft Corporation、Google、FaceBook, Inc.。\n\n\n我们的客户有 gitHub、fourSquare、microSoft Corporation、google、faceBook, Inc.。\n\n\n我们的客户有 gｲんĤЦ8、ｷouЯƧquﾑгє、๓เςг๏ร๏Ŧt ς๏гק๏гคtเ๏ภn、900913、ƒ4ᄃëв๏๏к, IПᄃ.。\n\n注意：当网页中需要配合整体视觉风格而出现全部大写／小写的情形，HTML 中请使用标准的大小写规范进行书写；并通过 text-transform: uppercase;／text-transform: lowercase; 对表现形式进行定义。\n不要使用不地道的缩写正确：\n\n我们需要一位熟悉 JavaScript、HTML5，至少理解一种框架（如 Backbone.js、AngularJS、React 等）的前端开发者。\n\n错误：\n\n我们需要一位熟悉 Js、h5，至少理解一种框架（如 backbone、angular、RJS 等）的 FED。\n\n争议以下用法略带有个人色彩，即：无论是否遵循下述规则，从语法的角度来讲都是正确的。\n链接之间增加空格用法：\n\n请 提交一个 issue 并分配给相关同事。\n\n\n访问我们网站的最新动态，请 点击这里 进行订阅！\n\n对比用法：\n\n请提交一个 issue 并分配给相关同事。\n\n\n访问我们网站的最新动态，请点击这里进行订阅！\n\n简体中文使用直角引号用法：\n\n「老师，『有条不紊』的『紊』是什么意思？」\n\n对比用法：\n\n“老师，‘有条不紊’的‘紊’是什么意思？”\n\n工具\n\n\n仓库\n语言\n\n\n\nvinta/paranoid-auto-spacing\nJavaScript\n\n\nhuei90/pangu.node\nNode.js\n\n\nhuacnlee/auto-correct\nRuby\n\n\nsparanoid/space-lover\nPHP (WordPress)\n\n\nnauxliu/auto-correct\nPHP\n\n\nricoa/copywriting-correct\nPHP\n\n\nhotoo/pangu.vim\nVim\n\n\nsparanoid/grunt-auto-spacing\nNode.js (Grunt)\n\n\nhjiang/scripts/add-space-between-latin-and-cjk\nPython\n\n\n谁在这样做？\n\n\n网站\n文案\nUGC\n\n\n\nApple 中国\nYes\nN/A\n\n\nApple 香港\nYes\nN/A\n\n\nApple 台湾\nYes\nN/A\n\n\nMicrosoft 中国\nYes\nN/A\n\n\nMicrosoft 香港\nYes\nN/A\n\n\nMicrosoft 台湾\nYes\nN/A\n\n\nLeanCloud\nYes\nN/A\n\n\n知乎\nYes\n部分用户达成\n\n\nV2EX\nYes\nYes\n\n\nSegmentFault\nYes\n部分用户达成\n\n\nApple4us\nYes\nN/A\n\n\n豌豆荚\nYes\nN/A\n\n\nRuby China\nYes\n标题达成\n\n\nPHPHub\nYes\n标题达成\n\n\n少数派\nYes\nN/A\n\n\n力扣 LeetCode\nYes\nYes\n\n\n参考文献\nGuidelines for Using Capital Letters\nLetter case - Wikipedia\nPunctuation - Oxford Dictionaries\nPunctuation - The Purdue OWL\nHow to Use English Punctuation Corrently - wikiHow\n格式 - openSUSE\n全角和半角 - 维基百科\n引号 - 维基百科\n疑问惊叹号 - 维基百科\n\n\n抄袭自https://github.com/mzlogin/chinese-copywriting-guidelines\n\n","categories":["通用开发"],"tags":["通用开发"]},{"title":"How to Read a Paper (怎样阅读论文)","url":"/2023/08/16/%E6%9D%82%E8%B0%88/how-to-read-paper/","content":"0. Three Pass Approach作者介绍了一个”Three pass”的看论文阅读方法，目的是为了在人们阅读论文细节之前有一个大体的掌握。第一遍是掌握论文的大体意思；第二遍是查阅论文的主题，但是不看论文的细节；第三遍是帮助你更佳深度的了解论文细节。\n1. The first pass第一遍的目的是对全文有一个快速的掌握，并依据第一遍获得的信息决定要不要读更多遍。第一遍论文包括以下几个步骤：\n\n仔细阅读论文的标题,摘要，和简介;\n阅读章节和子章节的标题，但是忽视所有其他的内容；\n如果有数学内容，简单浏览，确定其理论基础；\n阅读总结；\n简单阅读引用，剔除那些已经看过的论文；\n\n在读完第一遍后，你应该有以下收获：\n\n文章类别: 这是一篇什么类型的文章，是实验性的论文？还是对现有系统的分析？\n内容：有哪些论文跟这篇论文相关？依据了哪些理论来分析问题？\n正确性：论文的设想是否是正确的？\n贡献：文章主要的贡献是什么？\n清晰度：文章是否写的好，写的足够清晰？\n在读完第一遍后，你可以决定是否要更多遍论文。\n\n不读的原因可能有：\n\n文章不够吸引你\n你对文章当前领域的知识储备还不够，需要更多的知识才能看懂\n文章做了错误的猜想\n\n2. The Second Pass在第二遍过程中，要采用更多的注意力来阅读论文，但是忽视论文的证明过程。\n\n仔细的看论文中的图片，表格，关注一下细节：坐标抽是否正确标记？结论是否具有统计意义？往往是细节之中，能够窥探出真正出色的工作和水文之间的区别；\n标记论文中涉及的、你并未读过的参考文献，之后进一步阅读\n\n对于有经验的读者而言，第二遍可能会占用至多一个小时；读完第二遍，你应该能掌握论文内容，总结全文主旨了。\n不过，有时候即使是这样读完一遍，也未必就能读懂论文：论文可能涉及你陌生的领域，有太多陌生术语；作者可能采用了你不了解的证明或实验技术；甚至，这篇论文可能写得不行。\n现在你可以有以下几个选择：\n\n把论文放一边，期望在以后的研究生涯中不再需要这一知识点；\n在阅读背景材料以后，返回继续阅读论文继续坚持并阅读第三遍论文\n\n3. The Third Pass第三遍的目的是，复现论文，重构实验结果：和作者做一样的猜想，重构作者的研究工作。通过将重构工作和论文工作进行比较，不仅可以轻易地发现论文的创新点，还有隐藏着的失败点和猜想。\n进入第三遍，最重要的事情强调三遍：细节！细节！细节！找出作者陈述中的每一个假设，亲自挑战它，提出自己的思考。如此，对于论文的证明和其中的技术，你便会有更为深刻的理解。\n4. 文献调研怎么做？作者同样总结一个”三步法”：\n\n善用学术搜索引擎，（比如google学术，Arxiv）找出3-5篇相关领域近期最高引用的论文；了解这些论文的工作原理，并阅读其中的related work部分，幸运的话，这些内容可以直接帮你完成文献综述；\n在这些论文的参考文献中，找出其共同引用的论文，或者重复出现的作者姓名； 访问这些关键人物网站，查看他们近期发表的论文，也可以看看他们参加了哪些顶级会议？访问顶级会议的网站，浏览会议最近的进程和记录；\n汇总在会议和引用的论文中查到的高质量论文，和第一步中的高引用论文，基本就能构成你文献综述的出版内容了。\n\n最后，三步法可以迭代进行。\n\n抄袭自ATA https://open.atatech.org/articles/224491\n\n","categories":["杂谈"],"tags":["论文"]},{"title":"个人年度游戏评价总结","url":"/2022/01/10/%E6%9D%82%E8%B0%88/my-game-of-the-year/","content":"仅评价2021财年发布的单机作品或持续运营的在线游戏，全是个人主观喜好，没有一丢丢客观，人生建议有风险，涉及剧透须谨慎。\n我的年度最佳游戏继往开来的《生化危机8》经过《生化危机7》对第一人称和重新走回生存恐怖的道路的试水，《生化危机8》从各个方面都是一部更加成熟的作品，出色地延续了自《生化危机7》设定的道路：小到钥匙，曲柄，各种徽章，草药，子弹和背包管理，大到收集物品解锁一道道紧闭的房间增加活动的区域，以及背后不断响起的沉重的脚步声，在一个封闭但不是特别复杂而机关重重的洋馆里解密探险，这就是最原汁原味的《生化危机》的氛围；个人因为初见的原因选择使用简单难度花费了大约6个小时的时间通关，这六个小时可以说是酣畅淋漓，意犹未尽，相比于前代的大宅，生化危机8 在场景的设计上也是更加丰富多彩，从连接着各个公爵据点，有那么一丝丝开放世界的意思的村庄，还有似曾相识于《生化危机4》的中世纪艺术风格城堡；诡谲的贝内文托家的密室逃脱奇景和《江学主义好》都镇不住邪的恐怖巨婴；白雪皑皑的群峰与雪山下的湖泊和屹立的风车；蒸汽朋克工业机械传动美感的地下工厂与钢铁军团流水线；每个箱庭世界都能将该章节游戏氛围渲染的恰到好处。\n对于关卡设计，可以说本作有那么一丝集历代生化危机于大成的意思了：\n\n首先说到村庄本身，作为生化危机8的开篇场景，同时作为地图的枢纽的村庄，在开始阶段充当一个新手村，让玩家快速适应游戏节奏，配合脚本演出和中后期少量的怪物的战斗，同时在完成四大副本（对就是四大公爵的剧情）解密获得关键道具来解锁之前不能进入的区域，获得新的装备和资源，可以说是对战斗外加探索元素的一种游戏内表现。\n作为本作重头戏的城堡，可以说是对生化危机7的大宅乃至生化危机1的洋馆的一种继承，城堡之中又在存档点作为枢纽可以按剧情前后划分为多个小厅，通过不庞大但是精致而复杂而又沟壑纵横的场景配合可以让人松口气的安全屋，玩家解锁了这一道门获得这个房间的道具进而解锁下一道门最终将密闭空间中原本各种闭锁的区域连接起来，让原本恐惧的场景随着探索带来的熟悉变得不再恐怖，这便是生化危机在最开始带给玩家的一种正反馈和沉浸式的体验，游玩这一章仿佛又让人回到那个危机四伏而又无比熟悉的的贝克庄园。\n贝内文托家，这一章玩家不再可以装备武器，离逃生就差一部摄像机，在密室逃脱的基础上引入了一种历代少见的的日式恐怖游戏那种无法预测什么时候会吓玩家一跳的灵异风格，不说了，再回想一下就要换裤子了，还好章节结束这种风格即点到为止，我只能说还好制作组很讲武德，不然能不能通关就是另一回事了。\n矿洞，风车和沼泽，这个章节仿佛又回到了生化危机 456那种快节奏的动作游戏中去，这几代boss往往巨大无比，配合高强度的脚本演出和QTE&amp;体术让玩家快节奏的探索并最终击破BOSS的各个阶段完成章节，紧张的战斗节奏和氛围渲染深谙动作游戏的冒险之道。\n武举人的工厂，这章节将游戏的维度从平面扩展到垂直，类似7代中米娅在邮轮上的桥段然而制作水准上更上一层楼，通过电梯作为安全屋配合上上下下的地形将各个楼层连接起来，不同楼层不同风格，兼具狭隘的空间和复杂机械运作的宏大场面，复用场景的同时不丧失探索的新鲜感，最后的BOSS战开着魔改的挖掘机左机枪右机炮电锯护体大战武举人的万磁王机甲，有一种将控制权转给铁御（泰坦陨落）的喜悦，玩了之后非常开心，浑身充满了力量。说到游戏性上，除了生化危机基础的打怪拿钥匙开门打BOSS看播片之外，本作还引入了经济系统与收集元素，击败小怪和BOSS亦或是收集场景中的宝藏在商人处能兑换金额不等的货币，拿着这些货币又可以购买补给品，武器升级乃至武器本身，甚至还引入了有打猎抓鱼制作属性升级这些在RPG作品中大量运用的系统；顺道一提，本代的火力水平相比于前代也是更加豪华，因为不再局限于7代的洋馆生存恐怖探索解密，多种不同风格的箱庭世界就不再需要对玩家手头可操控的火力进行限制，同时武器系统很有历代特色：刮痧的小手枪，近距离打出高输出的霰弹枪，高射速的冲锋枪，中距离万金油的突击步枪，远距离精准射手步枪，和伤害爆表的指定武器马格南以及必不可少的榴弹，武器系统和手感即使是偏向于动作射击游戏玩家也能有较好的体验，而操控克里斯突袭村庄的剧本，更是带来了一种类似于COD系列的新鲜感(一转攻势追着怪打)。\n\n在玩完生化危机7之后，我当时并没有对续作的些许期待，或许是因为生化危机7的结局比较圆满，并没有给人留下那种荡气回肠意犹未尽的感觉，也可能是卡普空对改变的自信不足，并没有给结局挖坑吊着玩家，8代虽然是付出牺牲下的好结局，但是还给玩家留下了许多疑问，比如成年后亭亭玉立的萝丝，老父亲伊森是否真的死了，BSAA欧洲分部究竟发生了什么，克里斯继续要克那些队友等等，无不给系列粉丝留下了期待和论坛上津津乐道的话题。\n除了游戏内容本身，卡普空对于RE引擎的运用和优化也到了炉火纯青的地步，至少在画面赏心悦目的同时让我的1066m在2k分辨率中画质下不复杂场景下能保持六十帧的有些场景少许掉帧的较为良好的优化。综上，鉴于，因为我认为生化危机8不仅是当前最好的一部生化危机，在个人心目中更有评价为我的年度游戏的资格，至少是COVID19大流行之后各大厂家的日渐摆烂货不对板的大背景下达到了大众玩家预期的一部作品。\n个人年度最佳多人游戏回归游戏性初衷的《双人成行》获得 TGA 2021 年度游戏在很多人眼中实至名归，但是在我眼中，它似乎并不十分般配历年来年度游戏的体量，有一种4399大合集的感觉，不过有一说一的是《双人成行》的玩法确实极其丰富，不好玩就赔1000美刀，法克奥斯卡老哥真的是肯尼迪坐敞篷车————脑洞大开；开发组似乎也不吝啬在一个章节中部署如此丰富的玩法，章节结束之后就弃之不用是否有些可惜，不过《双人成行》能在画质的进步逐渐产生边界效应的今天这个世代回归游戏制作的初衷–让所有人都爱上游戏的乐趣，给玩家带来令人感动的快乐，很有任天堂式游戏理念，着实令人欣慰；各种论坛上对《双人成行》的溢美之词不必再多讲，这也是一款给我带来很多欢乐的游戏（虽然只玩到了一半），但很可惜是是，除了对硬件的要求（PS：核显不能玩）之外，一个举手投足的朋友仿佛是更难的要求（什么男童成形），所以说不是每个玩家都有另一个人可以和自己成行（我的建议是退款）。\n个人年度最佳服务型游戏（网游）《Apex Legend》在2019年初，《Apex Legend》的发布上线3天吸千万玩家，并随着外挂的泛滥导致很多玩家退坑热度逐渐下降；但是不可否认的是，《Apex Legend》游戏本身质量过硬，起源2引擎的运动和酣畅淋漓的打击感再加上快节奏让其体验在吃鸡类游戏中只能说是无出其右，重生娱乐的稳健运营并引入许多诸多创新性优秀机制的更为这个游戏引入了源头活水般的活力。随着《Apex Legend》第七赛季的到来，地图奥林匹斯和传奇地平线的更新再加上登陆steam平台同时伴随着Vtuber文化的推波助流乃至衍生文化产生，让《Apex Legend》在国内的热度重新点燃并吸引了很多新玩家；作为一款大逃杀游戏，除了大逃杀游戏本身的设计思路之外，《Apex Legend》更强调以动制静，炫酷的身法（不能滑铲的第一人称游戏都不是好游戏 ———— 洲哥），英雄技能之间的机制配合，三人组队团队思路的运营，易上手难精通，同时每季度稳定的内容更新，让其成为一部可以与朋友们共同游（zuo）玩（lao）的可玩性非常高的服务型网络游戏。\n个人年度最佳竞速游戏《极限竞速地平线 5》 ，主要是其他没啥可比的，游戏本身质量也非常优秀，不过其实个人不是特别喜欢这种纯开车的游戏，感觉纯竞速很枯燥，看风景又会腻 ，但是不得不不承认这部游戏的无论是系统还是内容上都非常优秀 。\n个人年度最佳移动游戏（手游）诚然，《原神》无论是在体量，游戏系统，内容呈现上来说，在近几年体量壮大商业模式成熟但是总体质量下滑的的移动游戏中都是当之无愧的王牌；但是，《原神》在我这里能取得这个评价的原因仅仅是他的赛道是手机游戏（暂不考虑PC端和PS端）。和其他日渐偏向社交向或者模式化的手游相比，《原神》的横空出世无疑是一种降维打击，给移动平台带来了一种沉浸式的开放世界体验；当然，把欣赏的眼光放到大型游戏时，原神的光芒就没有那么闪耀了，单就开放世界来说，《刺客信条起源》都比它不知道高到那里去了。\n下面开始评价我认为的年度最佳移动游戏：《荒野乱斗》，暂且不说运营和最近几次版本更新上的问题，我认为《荒野乱斗》的底子是非常优秀的，保持了休闲手游拿得起，放得下的风格;相比于移动平台的其他英雄对战游戏，Supercell的制作团队是对休闲手游的制作有着独到的理解，对碎片化时间的利用无疑是非常优秀的，再加上协调的艺术风格和音乐，极简但是有那么一点操作空间的操作体验，我只能说，闲下来玩两把真的很舒服。对于《荒野乱斗》，可能玩过几局之后后就觉得没什么意思了或者坐大牢了，但过短则几个小时长则几天又会想捡起来再玩,这或许就是手机游戏一开始的初心罢了。\n个人年度最失望游戏Grand Theft Auto：三部曲– 决定版（重制版）总的来说就挺失望的，可能是对Rockstar的作品心理预期太高了，使用虚幻4重置的Grand Theft Auto 3 三部曲很难在当今的时代达到还算合格的水准，最绷不住的的一点就是圣安地列斯的雾气机制取消了，让本来庞大的地图显得特别袖珍，尤其是在高空的视角，就挺出戏的。（现在的版本已经选择可以开关，但还是给我留下了很深的印象）。不过唯一的好处貌似是Switch 平台也有给她爱游戏可以玩了，这波利好NS。\n目前先想到这么多，就这把。\n","categories":["杂谈"],"tags":["评鉴"]},{"title":"数据仓库的分层概念","url":"/2024/01/05/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E7%9A%84%E5%88%86%E5%B1%82%E6%A6%82%E5%BF%B5/","content":"1. 业务视角的数据仓库分层概念\nODS层 (Operation Data Store)：​ mysql -&gt; hive放在这里​ ，是从业务数据库或日志中直接采集上来的业务原生数据，不做任何清洗，转换，聚合，保持业务数据现状。该层数据的作用是：第一方便数据问题的追溯，第二对于业务数据也是一个很好的备份。\nDWD层（Data warehouse detail）：​ ODS 表的清洗的结果，或者从外部团队接入的数据，是对数据进行了一定处理的hive表层级​ \nDWA层（在业务这边用DWA替代DWM-Data Warehouse Middle层）：​ 大宽表，一般是多张dwd表的聚合得到多维度的数据（聚合结果），就定义而言即为dwm层​； 数据在该层进行轻度汇总，基于分析场景合并多个业务过程，确定维度和度量。该层数据的作用是：指标计算口径下沉，统一计算口径。复用关联计算，减少数据扫描。\nMID层（在我理解中就是DWM层，但在这属于新层次）：​ 中间表，dwd到dwa 或者dwa到dws的中间过程有比较多的共用部分，会抽出mid层，这一层仅对本业务透出，就是仅对本业务透出的中间层的中间层​ 。\nDWS层（Data Warehouse Service）：​ 一般是面向业务的聚合层，比如对某个业务具体指标的透出就可以放在dws层，就比如新手任务的指标就可以放在这层\nAPP层​ 如果要将结果数据写入mysql/es/clickhouse，我们就看先把结果数据放在这里。这是一个面向业务使用层面，数据将在该层与应用场景进行映射，一张数据表对应一个数据需求。\n\n2.数据分层原理和作用\n\n\n\n层级缩写\n中文名称\n英文名称\n分层特征\n描述\n\n\n\nODS\n数据贴源层\nOriginal data store\n某一时刻业务数据快照。\n是从业务数据库或日志中直接采集上来的业务原生数据，不做任何清洗，转换，聚合，保持业务数据现状。该层数据的作用是：第一方便数据问题的追溯，第二对于业务数据也是一个很好的备份。\n\n\nDWD\n数据明细层\nData warehouse detail\n与ODS粒度一致。\n清洗、加工、转换和集成。划分主题和确定业务过程。数据在该层进行清洗、加工、转换和集成，但不做数据汇总。在该层开始对数据进行主题划分，确定业务过程和数据粒度。该层数据的作用是：保证样本数据质量，提升业务明细数据的可用性。\n\n\nDWA\n数据聚合层\nData warehouse aggregation\n统一计算口径，逻辑封装。\n基于实体的轻度汇总和标签处理。数据在该层进行轻度汇总，基于分析场景合并多个业务过程，确定维度和度量。该层数据的作用是：指标计算口径下沉，统一计算口径。复用关联计算，减少数据扫描。\n\n\nDM\n数据集市层\nData market\n1. 多维指标汇总。 2.数据立方体构建。\n数据在该层进行多维数据立方体汇总，划分核心维度和非核心维度，对数据服务进行分级保障。\n\n\nAPP\n数据应用层\nApplication\n派生/衍生指标。合并数据呈现需求结果。\n业务结果层，面向业务使用层面，数据在该层与应用场景进行映射，一张数据表对应一个数据需求。\n\n\nDIM\n公共维度层\nDimension\n业务观察视角。一经生成几乎不变。\n业务观察视角。\n\n\n\n\n\n\n\n\n\n","categories":["数据库"],"tags":["数据仓库"]},{"title":"MySQL创建一千万条测试数据","url":"/2023/12/17/mysql-10M-data/","content":"MySQL创建一千万条测试数据，用于瞎捣鼓\n1.创建User表：DROP TABLE IF EXISTS `users`;CREATE TABLE `users`  (  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT &#x27;主键&#x27;,  `name` varchar(222) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT &#x27;名称&#x27;,  `age` int(11) NULL DEFAULT NULL COMMENT &#x27;年龄&#x27;,  `addr` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT &#x27;&#x27; COMMENT &#x27;地址&#x27;,  `create_date` datetime(0) NULL DEFAULT NULL COMMENT &#x27;创建时间&#x27;,  PRIMARY KEY (`id`) USING BTREE,  INDEX idx_age (age) COMMENT &#x27;年龄索引&#x27;,  INDEX idx_name (name) COMMENT &#x27;姓名索引&#x27;) ENGINE = MyISAM AUTO_INCREMENT = 1 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;\n\n2. 创建存储过程DROP PROCEDURE IF EXISTS pro_users ;CREATE PROCEDURE pro_users()BEGIN    DECLARE count int  DEFAULT 0 ; -- 计数\tDECLARE max int ; -- 插入数据条数\tDECLARE name_length INT;    DECLARE first_name VARCHAR(2);    DECLARE last_name VARCHAR(4);    DECLARE age INT;    DECLARE city VARCHAR(16);    DECLARE addr VARCHAR(128);\tSET max = 10000000 ;\t-- 开始执行循环\tWHILE count &lt; max  DO        SET name_length = ROUND(RAND() * 1) + 2;        SET first_name = SUBSTRING(&#x27;赵钱孙李周吴郑王冯陈唐卫蒋沈韩杨朱秦尤许何吕施张孔曹严华金魏陶姜董谢邹丁柏水薛章云苏潘葛石范彭郎鲁韦昌马苗凤花方俞任袁柳乔岑程邱秋顾梅盛林刁钟徐高夏蔡田姚谭纪程&#x27;, FLOOR(RAND() * 49) + 1, 1);        SET last_name = SUBSTRING(&#x27;一二三四五六七八九十&#x27;, FLOOR(RAND() * 10) + 1, name_length - 1);        SET age = FLOOR(RAND() * 100) + 1;        SET city = CASE FLOOR(RAND() * 10)        WHEN 0 THEN &#x27;北京&#x27;        WHEN 1 THEN &#x27;上海&#x27;        WHEN 2 THEN &#x27;广州&#x27;        WHEN 3 THEN &#x27;深圳&#x27;        WHEN 4 THEN &#x27;重庆&#x27;        WHEN 5 THEN &#x27;天津&#x27;        WHEN 6 THEN &#x27;苏州&#x27;        WHEN 7 THEN &#x27;南京&#x27;        WHEN 8 THEN &#x27;杭州&#x27;        WHEN 9 THEN &#x27;成都&#x27;        END;        SET addr = CONCAT(city, &#x27;市&#x27;,         CASE FLOOR(RAND() * 4)        WHEN 0 THEN &#x27;东&#x27;        WHEN 1 THEN &#x27;南&#x27;        WHEN 2 THEN &#x27;西&#x27;        WHEN 3 THEN &#x27;北&#x27;        END, &#x27;区&#x27;,         CASE FLOOR(RAND() * 4)        WHEN 0 THEN &#x27;东&#x27;        WHEN 1 THEN &#x27;南&#x27;        WHEN 2 THEN &#x27;西&#x27;        WHEN 3 THEN &#x27;北&#x27;        END, &#x27;县&#x27;,        CASE FLOOR(RAND() * 4)        WHEN 0 THEN &#x27;东&#x27;        WHEN 1 THEN &#x27;南&#x27;        WHEN 2 THEN &#x27;西&#x27;        WHEN 3 THEN &#x27;北&#x27;        END, &#x27;镇&#x27;,        CASE FLOOR(RAND() * 10)        WHEN 0 THEN &#x27;A&#x27;        WHEN 1 THEN &#x27;B&#x27;        WHEN 2 THEN &#x27;C&#x27;        WHEN 3 THEN &#x27;D&#x27;        WHEN 4 THEN &#x27;E&#x27;        WHEN 5 THEN &#x27;F&#x27;        WHEN 6 THEN &#x27;G&#x27;        WHEN 7 THEN &#x27;H&#x27;        WHEN 8 THEN &#x27;I&#x27;        WHEN 9 THEN &#x27;J&#x27;        END, &#x27;小区&#x27;,         FLOOR(RAND() * 20) + 1, &#x27;号楼&#x27;,         FLOOR(RAND() * 20) + 1, &#x27;单元&#x27;,         FLOOR(RAND() * 5) + 1, &#x27;0&#x27;, FLOOR(RAND() * 3) + 1, &#x27;室&#x27;);\t\tINSERT INTO `users` ( `name`, `age`, `addr`, `create_date` )\t\tVALUES\t(CONCAT(first_name, last_name), age, addr, NOW() );\t\t\t    \tSET count = count + 1; \tEND WHILE;\tEND ;call pro_users();\n\nRefer抄袭自MySQL深分页场景下的性能优化\n"},{"title":"SIMD简介","url":"/2024/08/24/%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/SIMD/","content":"1. SIMD是什么● SIMD表示单指令多数据，即一条CPU指令可以同时处理多条数据。● 以下图的加法为例，左侧的标量计算需要4个CPU指令才能算完，右侧的SIMD运算只需要1个CPU指令就能算完，即同时处理4组数据。● 由此可见，SIMD的计算效率更高。SIMD适合计算密集型任务的优化。\n","categories":["体系结构"],"tags":["体系结构"]},{"title":"数据库事务处理技术","url":"/2021/08/30/%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93/Database-transaction-processing-techniques/","content":" 第22讲 数据库事务处理技术为了更好的性能，我们需要并行处理数据库事务\n什么是并发控制？就比如我们买票\n如果大家同时买起点终点、日期、车次相同 的车票，会否买到座位相重复的车票？\n很显然如果服务不能很好的进行并发控制，就会导致一张票被卖了两次，进而出现我们不想要的结果\n常见的三种并发问题：\n\n丢失修改（同一数据被两个事务同时操作，其中一个事务的结果被另一个事务的结果覆盖）\n不可重复读（第一次读和第二次读结果不一样）\n脏读（读到了已被回滚的数据）\n\n什么是事务事务是数据库管理系统提供的控制数据操作的一种手段，通过这一手段，应 用程序员将一系列的数据库操作组合在一起作为一个整体进行操作和控制， 以便数据库管理系统能够提供一致性状态转换的保证。\n一个事务可处理一个数据或一条记录（从帐户A过户5000到帐户B上），也可能处理一批数据或一批记录\n例如：下面的操作即为一个事务\nread(A);A := A – 5000;write(A);read(B);B := B + 5000;write(B);\n\n所以说\n并发控制就是 通过事务微观 交错执行次序 的正确安排， 保证事务宏观上的独立性、完整性和正确性\n事务的ACID特性\n原子性Atomicity : DBMS能够保证事务的一组更新操作是原子不可分的，即对 DB而言，要么全做，要么全不做\n\n一致性Consistency⭐: DBMS保证事务的操作状态是正确的，符合一致性的操作 规则，不能出现三种典型的不一致性。它是进一步由隔离性来保证的。\n\n隔离性Isolation: DBMS保证并发执行的多个事务之间互相不受影响。例如两个 事务T1和T2, 即使并发执行，也相当于或 者先执行了T1,再执行T2;或者先执行了T2,再执行T1。\n\n持久性Durability: DBMS保证已提交事 务的影响是持久的，被撤销事务的影响是可恢复的。\n\n\n并发调度什么是事务调度(schedule)：一组事务的基本步(读、写、其他控 制操作如加锁、解锁等)的一种执行顺序称为对这组事务的一个调度。 \n并发(或并行)调度：多个事务从宏观上看是并行执行的，但其微观上的基本 操作(读、写)则是交叉执行的。\n事务调度之正确性当且仅当在这个并发调度下所得到的新数据库结果与分别串行地运行这些事务所得的新数据库完全一致，则说调度是正确的。\n事务调度之可串行性如果不管数据库初始状态如何，一个调度对数据库状态的影响都和某个串行调度相同，则我们说这个调度是可串行化的 (Serializable)或具有可串行性(Serializability)。\n\n\n可串行化调度一定是正确的并行调度，但正确的并行调度，却未必都是可串行化的调度\n并行调度的正确性是指内容上结果正确性，而可串行性是指形式上结果正确性，便于操作。\n可串行化的等效串行序列不一定唯一\n\n事务调度之冲突调度中一对连续的动作，它们满足：如果它们的顺序交换，那么涉及的事务中至少有一个事务的行为会改变。\n有冲突的两个操作是不能交换次序的，没有冲突的两个事务是可交换的\n\n同一个事务的任何两个操作都是冲突的\n\n\n  不同事务对同一元素的两个写操作是冲突的\n  不同事务对同一元素的一读一写操作是冲突的\n\n事务调度之冲突可串行性一个调度，如果通过交换相邻两个无冲突的操作能够转换到某一个串行的调度，则称此调度为冲突可串行化的调度。    \n\n  冲突可串行性是比可串行性要严格的概念\n  满足冲突可串行性，一定满足可串行性；反之不然\n\n冲突可串行性判别算法\n构造一个前驱图(有向图)\n\n结点是每一个事务Ti。如果Ti的一个操作与Tj的一个操作发生冲突，且Ti在 Tj前执行，则绘制一条边，由Ti指向Tj, 表征Ti要在Tj前执行。\n\n测试检查: 如果此有向图没有环，则是冲突可串行化的\n\n\n一道习题：冲突可串行的判定\n基于封锁的并发控制方法锁的概念锁是控制并发的一种手段，是数据库元素上的并发控制标志\n关于锁的基本知识点\n  每一数据元素都有唯一的锁\n  每一事务读写数据元素前，要获得锁\n  如果被其他事务持有该元素的锁，则要等待\n  事务处理完成后要释放锁\n  锁本身并不能保证冲突可串行性，只是为调度提供了控制的手段，具体如何使用锁需要说明——不同协议\n\n封锁协议之锁的类型排他锁X只有一个事务能读和写，其他任何事务都不能读、写\n共享锁S所有事务都可以读，但任何事务都不能写\n更新锁U初始读，以后可以升级为写\n增量锁I区分增量更新和其他类型的更新\n封锁协议0级到3级协议（加锁的时机）\n 0级协议  有写要求的数据对象A加排他锁，不再访 问后即刻解锁。可防止丢失修改，但允许 脏读，允许重复读错误\n 1级协议 有写要求的数据对象A加排他锁，事务提 交时刻解锁。可防止丢失修改，可恢复,防止脏读，允许重复读错误\n 2级协议  有写要求的数据对象A加排他锁，事务提 交时刻解锁。有读要求的数据对象B加共 享锁，不再访问后即刻解锁。可防止丢失 修改，防止脏读，防止重复读错误，但是不能解决幻读\n 3级协议 有写要求的数据对象A加排他锁，事务提 交时刻解锁。有读要求的数据对象B加共 享锁，事务提交时刻解锁。防止所有不一致性\n\n脏读、不可重复读、幻读： 脏读：\n所谓的脏读，其实就是读到了别的事务回滚前的脏数据。比如事务B执行过程中修改了数据X，在未提交前，事务A读取了X，而事务B却回滚了，这样事务A就形成了脏读。\n也就是说，当前事务读到的数据是别的事务想要修改成为的但是没有修改成功的数据。\n 不可重复读：\n事务A首先读取了一条数据，然后执行逻辑的时候，事务B将这条数据改变了，然后事务A再次读取的时候，发现数据不匹配了，就是所谓的不可重复读了。\n也就是说，当前事务先进行了一次数据读取，然后再次读取到的数据是别的事务修改成功的数据，导致两次读取到的数据不匹配，也就照应了不可重复读的语义。\n 幻读：\n事务A首先根据条件索引得到N条数据，然后事务B改变了这N条数据之外的M条或者增添了M条符合事务A搜索条件的数据，导致事务A再次搜索发现有N+M条数据了，就产生了幻读。\n也就是说，当前事务读第一次取到的数据比后来读取到数据条目少。\nSQL之隔离性级别读未提交(read uncommitted) —相当于0级协议 \n读已提交 (read committed) —相当于1级协议 \n可重复读(repeatable read)—相当于2级协议\n可串行化(serializable) —相当于3级协议 \n详细说明\n两段封锁协议是一种基于锁的并发控制方法。读写数据之前，每个事务中所有封锁请求先于任何一个解锁请求。\n两阶段：加锁段和解锁段。加锁段不能有解锁操作，解锁段不能有加锁操作。\n 作用\n两段封锁协议是可以保证冲突可串行性的。\n注意：两段封锁协议是可能产生死锁的协议\n基于时间戳的并发控制方法基于时间戳的并发控制方法：借助于时间戳，强制使一组并发事务的交叉执行，等价于一个特定顺序的串行执行\n具体操作就是执行时判断冲突，如无冲突，予以执行；如有冲突，则撤销事务，并 重启该事务，此时该事务获得了一个更大的时间戳， 表明是后执行的事务。\n有哪些冲突：\n\n读-读无冲突；\n\n读-写或写-读冲突；\n\n写-写冲突\n\n\n具体规则：\n对DB中的每个数据元素x，系统保留其上的最大时间戳\nRT(x): 即R-timestamp(x) 读过该数据事务中最大的时间戳，即最后读x的事务的时间戳。\nWT(x): 即W-timestamp(x)写过该数据事务中最大的时间戳，即最后写x的事务的时间戳。\n事务的时间戳\nTS(T) 即TimeStamp\n读-写并发：(读-写、写-读)若T事务读x，则将T的时间戳TS与WT(x)比较:若TS大(T后进行)，则允许T操作，并且更改RT(x)为max{RT(x),TS}；否则，有冲突，撤回T，重启T。若T事务写x，则将T的时间戳TS与RT(x)比较：若TS大(T后进行)，则允许T操作，并且更改WT(x)为max{WT(x),TS}；否则，有冲突，撤回T重做。\n写-写并发 \n若T事务写x，则将T的时间戳TS与WT(x)比较：若TS大，则允许T写，并且更改WT(x)为T的时间戳；否则有冲突，T撤回重做。\n前述规则可以解决事务T过晚的读和过晚的写\n但是这两种“事实上 不可实现的”冲 突可以避免了，实用性很有限\n因此引入另一种调度规则\n对DB中的每个数据元素x，系统保留其上的最大时间戳\nRT(x): 即R-timestamp(x) \n  读过该数据事务中最大的时间戳，即最后读x的事务的时间戳。\nWT(x): 即W-timestamp(x) \n  写过该数据事务中最大的时间戳，即最后写x的事务的时间戳。\nC(x): x的提交位。 \n​    该位为真，当且仅当最近写x的事务已经提交。\nC(x)的目的是避免出现事务读另一事务U所写数据然后U终止或者被撤销这样的情况。\n对来自事务T的读写请求，调度器可以：\n\n同意请求\n\n撤销/终止T，并重启具有新时间戳的T(终止+重启，被称回滚)\n\n推迟T，并在以后决定是终止T还是同意请求(如果请求是读，且此读可能是 脏的)\n\n\n调度规则\n\n假设调度器收到请求rT(X)\n\n(1)如果TS(T)&gt;=WT(x), 此读是事实上可实现的\n 如C(x)为真，    同意请求。如果TS(T)&gt;RT(x), 置RT(x):=TS(T); 否则不改变RT(x).\n 如C(x)为假，推迟Ｔ直到C(x)为真或写x的事务终止。\n(2)如果TS(T)&lt;WT(x), 此读是事实上不可实现的\n回滚T(终止并重启T)；(过晚的读)\n\n假设调度器收到请求wT(X)\n\n(1)如果TS(T)&gt;=RT(x), 且TS(T)&gt;=WT(x), 此写是事实上是可实现的\n为x写入新值；置WT(x):=TS(T)；置C(x):=false.\n(2)如果TS(T)&gt;=RT(x),但是TS(T)&lt;WT(x)，此写是事实上可实现的。但x 已经有一个更晚的值\n如果C(x)为真，那么前一个x的写已提交；则忽略T的写；继续进行。(托马斯写规则)如果C(x)为假，则我们需推迟T，直到C(x)为真或写x的事务终止。\n(3)如果TS(T)&lt;RT(x), 此写是事实上不可实现的T必须回滚。(过晚的写)\n\n假设调度器收到提交T的请求。\n\n它必须找到T所写的所有数据库元素x, 并置C(x):=true。\n如果有任何等待x被提交的事务，这些事务就被允许继续进行。\n\n假设调度器收到终止T的请求\n\n像前述步骤一样确定回滚T。\n那么任何等待T所写元素x的事务必须重新尝试 读或写，看这一动作现在T的写被终止后是否合法。\n基于时间戳的并发控制的思想\n 事务在启动时刻被赋予唯一的时间戳，以示其启动顺序。 为每一数据库元素保存读时间戳和写时间戳，以记录读或写该数据元素的最 后的事务。 通过在事务读写数据时判断是否存在冲突(读写冲突、写读冲突、写写冲突) 来强制事务以可串行化的方式执行。\n基于有效性确认的并发控制方法基于有效性确认的并发控制的思想\n 事务在启动时刻被赋予唯一的时间戳，以示其启动顺序。 为每一活跃事务保存其读写数据的集合，RS(T)：事务T读数据的集合； WS(T)：事务T写数据的集合。 通过对多个事务的读写集合，判断是否有冲突(存在事实上不可实现的行为)，即有效性确认，来完成事务的提交与回滚，强制事务以可串行化的方式执行\n基于有效性确认的调度器\n 事务在启动时刻被赋予唯一的时间戳，以示其启动顺序。 每一事务读写数据的集合\n\nRS(T)：事务T读数据的集合；\n\nWS(T)：事务T写数据的集合。\n\n\n事务分三个阶段进行 \n\n读阶段。事务从数据库中读取读集合中的所有元素。事务还在其局部地址空间计算它将要写的所有值；\n有效性确认阶段。调度器通过比较该事务与其它事务的读写集合  来确认该事务的有效性。\n写阶段。事务往数据库中写入其写集合中元素的值。   每个成功确认的事务是在其有效性确认的瞬间执行的。   并发事务串行的顺序即事务有效性确认的顺序。\n\n调度器维护三个集合\n\nSTART集合。已经开始但尚未完成有效性确认的事务集合。对此集合中的事务，调度器维护START(T)，即事务T开始的时间。\nVAL集合。已经确认有效性但尚未完成第3阶段写的事务。对此集合中的事务，调度器维护START(T)和VAL(T)，即T确认的时间。\nFIN集合。已经完成第3阶段的事务。对这样的事务T,START(T), VAL(T)和FIN(T)，即T完成的时间。\n\n有效性确认规则\n-(1)对于所有已经过有效性确认, 且在T开始前没有完成的U（U已经过有效性确认）, 即对于满足 FIN(U)&gt;START(T)（U在T开始前没有完成。）的U,检测:\nRS(T) ∩WS(U)是否为空。 \n若为空，则确认。否则，不予确认。\n其含义是：如果一个较早的事务U现在正在写入T应该 读过的某些对象，则T的有效性不能确认\n(2)对于所有已经过有效性确认，且在T有效性确认前没有完成的U（U有效性已经成功确认）, 即对于 满足FIN(U)&gt;VAL(T)的U（U在T进入其有效性确认阶段以前没有完成）, 检测：WS(T) ∩WS(U)是否为空。 \n若为空，则确认。否则，不予确认。\n其含义是：如果T在有效性确认后可能比一个较早的事 务先写某个对象，则T的有效性不能确认\n","categories":["数据库"],"tags":["数据库"]},{"title":"数据库事务处理技术-故障恢复","url":"/2021/09/01/%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93/Database-transaction-processing-technology-failure-recovery/","content":"第23讲 数据库事务处理技术-故障恢复数据库的故障类型及其影响典型的数据库故障\n\n事务故障某一个程序(事务)自身运行错误所引起的故障影响该程序(事务)本身\n\n系统故障\n由于掉电、非正常关机等所引起的故障影响正在运行的事务以及数据库缓冲区, 数据库缓冲区将涉及正在 运行和已经运行的事务\n\n介质故障\n由于介质损坏等所引起的 故障影响是全面的，既影响内存中的数据, 又影响介质 中存储的数据\n\n\n数据库故障恢复的宏观思路 三种类型故障：事务故障、系统故障和介质故障 三种恢复手段:    事务的撤消与重做, 运行日志和备份 两个重要时刻：检查点和转储点\n每个事务都会读写某些元素READ(X,t):将元素X读到事务的局部变量t中；\nWRITE(X,t):将事务局部变量t写回元素X；\nINPUT(X):将元素X从磁盘读入到内存缓冲区中；\nOUTPUT(X):将元素X写回到磁盘中。\n每个事务都以提交或者撤销结束COMMIT：事务提交\nABORT：事务撤销\nDBMS在故障发生时需要保障事务\n持久性\n\n  已提交的事务——缓冲区内容保证写回磁盘\n  未提交的事务——缓冲区内容不能影响磁盘\n\n\n原子性\n事务的所有操作，要么全都执行，要么全不执行。\n\n\n注意：缓冲区内容和磁盘内容并不是时刻保持一致的。\n不同缓冲区策略Force:内存中的数据最晚在commit的时候写入磁盘。\nNo steal:不允许在事务commit之前把内存中的数据写入磁盘。\nNo force:内存中的数据可以一直保留，在commit之后过一段时间再写入磁盘。此时在系统崩溃的时候可能还没写入到磁盘，需要Redo,此方式较为灵活。\nSteal:允许事务commit之前把内存中的数据写入磁盘，此时若系统在commit之前崩溃时，已经有数据写入到磁盘了，要恢复到崩溃前的状态，需要Undo,此方式同样较为灵活。\n当前最常用：Steal + No force\n什么是日志？一个包含日志记录的、只能追加的顺序文件, 不同事务的日志记录交错存储，按发生时间存储。\n发生系统故障时，使用日志进行恢复:\n故障时已提交的事务，重做(Redo)\n故障时未提交的事务，撤销(Undo)\nUndo型日志及其故障恢复对于任一事务T，按下列顺序向磁盘输出T的日志信息： 首先，&lt;T, X, v&gt;被写到日志中 其次，OUTPUT(X) 最后，或被写到日志中 注意：Undo型日志仅保留旧值。&lt;T, X, v&gt;，v为X原来的值(X的旧值) Undo型日志：“将事务改变的所有数据写到磁盘前不能提交该事务”\n利用undo型日志进行恢复首先，确定每一个事务是否已完成?\n&lt;START T&gt;….&lt;COMMIT T&gt;….\t= yes&lt;START T&gt;….&lt;ABORT T&gt;…….\t= no(已结束，但未完成)&lt;START T&gt;………………………\t= no然后，从日志的尾部开始按日志记录的反序，处理每一日志 记录，撤销未完成事务的所有修改&lt;COMMIT T&gt;:\t标记T已完成&lt;ABORT T&gt;: 标记T已结束但未完成&lt;T,X,v&gt;: 如果T未完成，则将X=v写回磁盘；否则跳过；&lt;START T&gt;: 跳过\n\n\n检查点及其使用\n\n静止检查点：\n周期性地对日志设置检查点停止接受新的事务, 等到所有当前活跃事务提交或终止，并在日志中 写入了COMMIT或ABORT记录后将日志刷新到磁盘，写入日志记录，并再次刷新日志\n\n非静止检查点在设置检查点时不必关闭系统，允许新事务进入写入一条&lt;START CKPT(T1,…,Tk)&gt;其中T1,…,Tk 是所有活跃的未结束的事务继续正常的操作，直到T1,…,Tk都完成时，写入\n\n\n故障需恢复到所 遇到的第一个检查点\nRedo型日志及其故障恢复Redo型日志Undo型日志的问题“将事务改变的所有数据写到磁盘前不能 提交该事务”—如何解决?对于任一事务T，按下列顺序向磁盘输出T的日志信息：\n首先，&lt;T, X, v&gt;被写到日志中其次，&lt;COMMIT T&gt;被写到日志中最后，OUTPUT(X)注意：redo型日志保留新值。&lt;T, X, v&gt;，v为X更新后的值(X的新值)注意：与undo型的差别，在后两步，先写提交记录后输出，还是先输出，再写提交记录。\n利用redo日志进行恢复确定每一个事务是否已完成?\n&lt;START T&gt;….&lt;COMMIT T&gt;…. =yes&lt;START T&gt;….&lt;ABORT T&gt;…….=no(已结束，但未完成)&lt;START T&gt;………………………\t= no\n从日志的起始位置开始按日志记录的正序处理每一日志记录，重做已提交事务的所有修改：\n&lt;COMMIT T&gt;:\t标记T已完成&lt;ABORT T&gt;:标记T已结束但未完成&lt;T,X,v&gt;: 如果T已完成，则将X=v写回磁盘；否则跳过；&lt;START T&gt;: 跳过\n\n\n\n检查点\n\n非静止检查点在进行检查点设置时不必关闭系统，允许新事务进入写入一条&lt;START CKPT(T1,…,Tk)&gt;其中T1,…,Tk 是所有活跃的未结束的事务将所有已提交的事务写回磁盘，继续正常的操作，直到T1,…,Tk都完成时，写入\n\nUndo/Redo结合型日志及其故障恢复Redo型日志与Undo型日志的比较\nUndo型日志:\n\nOUTPUT必须先做。\n\n如果可见, T确定地已将所有其数据写回磁盘，因此不必重做 –– 但可能引起性能下降(因可能频繁地写磁盘)\n\n\nRedo型日志：\n\nOUTPUT必须后做。\n\n如果不可见, T确定地没有将其任何数据写回到磁盘， 因此无需撤销 –– 但灵活性差(数据必须在Commit后才可见)\n\n\n如更喜欢灵活性 – 需要采用Undo/Redo型日志\nUndo/Redo型日志对于任一事务T，按下列顺序向磁盘输出T的日志信息：\n- 第(1)步，&lt;T, X, u, v&gt;被写到日志中- 第(2)or(3)步，&lt;COMMIT T&gt;被写到日志中- 第(3)or(2)步，OUTPUT(X)- 注意：undo/redo型日志既保留新值v，也保留旧值u。\n注意：与undo型和redo型的差别，在后两步。\nRedo型是先写提交记录 后输出；\nundo型是先输出，再写提交记录；\nundo/redo型则无所谓谁先谁 后，只要保证&lt;T,X,u,v&gt;被先于OUTPUT写完即可。\n利用undo/Redo型日志进行恢复\n首先，确定每一个事务是否已完成?\n&lt;START T&gt;….&lt;COMMIT T&gt;….\t= yes&lt;START T&gt;….&lt;ABORT T&gt;……. = no(已结束，但未完成)&lt;START T&gt;………………………\t= no\n自前向后地，按日志记录的正序，重做所有已提交的事务；\n自后向前，按日志记录的反序，撤销所有未完成事务的所有修改。\n&lt;COMMIT T&gt;:\t标记T已完成&lt;ABORT T&gt;:标记T已结束但未完成&lt;T,X,u,v&gt;: 如果T未完成，则将X=u写回磁盘；否则将x=v写回磁盘；&lt;START T&gt;: 跳过\n\n\n总而言之：自后向前地撤销所有未提交的事务；自前向后地重做所有已提交的事务；先做&lt;撤销&gt;，再做&lt;重做&gt;\n","categories":["数据库"],"tags":["数据库"]},{"title":"多维稀疏矩阵行储存压缩研究","url":"/2022/01/15/%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93/Multidimensional-Sparse-Array/","content":"PATRICIA 字典树压缩储存扩展压缩行储存CRS/列储存CCS方法概述在CRS方法的基础上，将维度从二维的行和列扩展到k-维空间(k&gt;2),进而提出了扩展CRS的方法xCRS/xCCS，考虑到CRS和CCS高度的相似性，因此我们只讨论CRS方法。\n为了在多维空间使用CRS方法，我们需要选取一种映射，将k维数组转换到CRS方法中的行和列的形式，具体的操作是将原本的k-维空间映射到一个行(为第j个维度构成集合的势)的二维形式；在这种映射的作用下，原多维空间的每一个行元素能够转化为一个独一无二的键值（key），这个键值则又是通过行偏移量（row offsets）和维度的索引值共同决定的；对于行偏移量，它使用个索引值，比如来表示；而对于行中的每一个元素使用，进一步地可以使用 的形式计算；因此通过这种维度映射，对于每一个行元素都能计算出一个独一无二的键值。\n实现存储形式根据上面的内容，我们可以得出XCRS对多维数据中的非零元素的储存方式的储存方式：对于数据Value本身和它们在原有的多维矩阵中对应的维度的索引被储存在两个一维数组：和中；除此之外，还需要再使用一个一维数组来储存中每个行的起始位置，如果xCRS中的行没有有效的元素，那么这个一行的起始位置就被标记为缺省值“- 1”。需要注意的是xCRS中的每一个行在中都有一个条目，其位置对应着这个行的行偏移值（row offset）。这里给出xCRS存储的一种案例：\n\n对于表中的第一个非零元素，其位置对应着多维数组中的（0，0，0）位置的数据 20.5 ,因此其cind为0。\n对于第二个非零元素，其位置对应着多维数组中的（0，0，1），因为其在K轴上维度上的索引为1，其cind为1；对于17.0，23.6，14.9 类似，其cind分别为 2，3，3。\n对于rptr行的每一个偏移值，其计算方式如下：如果我们固定i=0，j=0，任取K时，我们可以得到一个行[（0，0，0）,（0，0，1）,（0，0，2）,（0，0，3）]，则其第一个元素（20.5）在val中的起始位置的偏移量offset是0,因此该位置的rptr为0；同理，固定i=0，j=1，任取K时，提出出的行[（0，1，0）,（0，1，1）,（0，1，2）,（0，1，3）]，中没有任何的非零元素，因对应位置的rptr为-1，对offset为2的位置（i=0，j=2，任取K）其原理类似，因为offset为0对应的行有两个非零元素，而此行至少有一个非零元素，因此其开始值即为rptr亦为 2，对于剩下的值计算类似。\n\n如何从压缩后的状态还原对于xCRS类似，还是按着上面一节举的例子，如果要在CRS压缩后的结构中查询原矩阵的（，，）位置的数据，需要先计算改位置对应的行索引，即为：3X+Y，然后在中查询对应的行开始位置，即 $rptr[3X+Y]如果该处的值为-1的话，说明该行全部都是空的，返回空值即可；如果不为说明该行有非零数值，再根据cind中存储的数据，查询该坐标中轴对应的位置，即同时满足cind[k]=Z的值，之后就可以根据rptr[3X+Y]获取该行开始的位置，则rptr[3X+Y]到下一个rptr[3*X+Y]中非空的位置的差，即为该行非空元素的个数，然后就可以再根据cind[k]=Z的条件，选出满足该条件的对应的offset对应的val值，即为所求位置（X，Y，Z）$的value；如果没有满足条件的值，说明该位置的元素为空。\n举一个例子，还是再刚才的xCRS表中,加入我们要获取坐标为（，，）处的值,首先需要根据X和Y值算出对应的行的开始坐标，即为 再根据的条件 算出满足 解得 ，即为所求。\n公式化映射：对于K维组,有：从K维空间到三个一维空间的映射满足：多维空间对应的取值等于其中PS：表示维度上的的集合的势。\n研究一下xCRS压缩率当多维数组的稀疏性很高时，xCRS下的压缩比会变差。这是因为存储每一行起始位置的xCRS数组rptr本身可能变得较为稀疏。\n","categories":["数据库"],"tags":["数据库"]},{"title":"EaCRS:一种基于可扩展阵列的多维数据压缩方案","url":"/2022/07/12/%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93/EaCRS/","content":"扩展行的概念为了对常见的多维数据的扩展操作进行支持，本文提出了一种 n 维可扩展数组 ，该数组可以在任何维度仅使用三种辅助表为代价对某个维度中进行维度上的拓展；对于维度 ,这三个辅助数组分别为：历史表  ,地址表  ,和系数表  ,其结构如下图所示：\n如上图所示，历史表  和地址表 都是一维数组，其中历史表用来记录行发生扩展的历史，一个维的扩展行 由拥有个维度的子数组构成 。\n例如对于一个n维数组A，其维度信息分别为：，如果需要在维度上进行拓展,需要动态分配一片连续的地址空间给由n-1维构成的子数组S来保存新增维度的信息，子数组S的各个维度大小分别为，然后将这个新的子数组S添加到A中的维度i。\n然后，历史数值计数器h加一，并将这个值h储存到历史表中，S中的第一个地址被保存到地址表中，注意，新增加的这个数组S通常是一个固定长度的数组，而真实的数据存储在S的子数组中。\n例如，一个元组在一个n维固定大小的数组中的位置可以由下面的公式定位：\n+d_3d_4…d_ni_2+….+d_ni_{n-1}+i_n$\n为了便于这个计算，我们将数组保存下来，及作为系数向量，将其保存在前文提到的系数表中。\n举一个实例，假设A是一个四维的可扩展数组，各个维度的信息分别为,如果在维度上进行扩展的话，就需要分配一个三维固定长度的数组S，各维度大小分别为，S中的元组可以按照行或者列的顺序进行安排，其地址计算函数为：。\n因此我们可以记多维系数向量，对于A的每个维度上的每一次扩展，都需要计算相对应的子数组的系数向量并将其保存对应维度的系数表。大体上说，如果A是n维可扩展表的话（n&gt;2），对于每一个维度，都需要建立一个拥有n-2维度的系数表。\n通过以上的三种系数表，便可以通过以下的形式计算每一个数组元素的地址。\n如上图中的元素，比较。因为有：,可以说明元素在对应的最近的历史值为8，同时我们可以根据该值得出对应的子数组的起始地址为36（保存在中），通过系数向量我们可知，元素相对于S中第一个地址的偏移量为,因此可以得出该元素对应的地址为。\n从上面的元素访问的过程我们可以得知，为了从多个历史表中获得历史变量的最大值，需要对n条记录进行比较；获取了最大值之后，需要对拥有n-1个维度的固定长度子数组通过之前提到的特定地址函数来对其偏移量进行计算。但是，乘法操作和加法操作的实际执行次数要远少于n维固定长度的数据的规模。\n基于扩展行的压缩行储存算法给定一个拥有三个维度的压缩行，EaCRS将每一个子数组进行独立压缩，这种储存格式使用三个一维数组：VL（浮点），RO，CO（整数）对于每一个可扩展数组的子数组（对于n维的可扩展数组，子数组拥有n-1个维度 ）,可以将子数组中的全部非零值进行压缩。\n数组RO存储了每行中的非零元素。拥有最短长度的维度通常被选作为行维度。如果一行的长度为k的话，RO就包含k+1个元素，RO[0]=1.RO[1]则包含子数组和RO[0]的第0行的非零元素。总的来说，RO[i]即为第i-1行中的非零元素的个数累加上之前RO[i-1]的值。\n数组CO则保存每一个行元素的列索引值。\nVL储存每行元素的非零值。\n对于每一个子数组，他们的RO,CO和VL的初始值都为0。\n在EaCRS格式中，对于一个n维的可扩展数组，在其三个辅助表中，只有历史表在每个维度上都需要保存，其是用来计算子数组的扩展维度与其他维度的长度和子数组的大小。\n下图展示了上图中所示模式的一个EaCRS扩展数组的例子：\n为了方便起见我们给定每一个子数组一个名字SA_i_j，其中i表示其所属的被扩展的维度，而j表示该维度的长度。举个例子SA_1_0,SA_1_1,…SA_1_是维度1的子数组，而SA_2_1,SA_2_2,…SA_2_则是维度2的子数。\n考虑到图片1中的子数组SA_1_3，这个子数组沿着维度1进行扩展，如下面图片3中(a)：36,37,38…,47表示了给定三维可扩展数组的子数组元素的逻辑存储位置。为了扩展这里的稀疏度，我们给每一个子数组元素分配一些零和非零值，（例如逻辑位置中的36被分配给0，37被分配给13，38被分配给了0）。考虑到SA_1_3沿着维度1进行扩展，剩下的两个维度则被考虑为行维度和列维度。对于SA_1_3，维度3的长度要比维度2短，所以在其对应的EaCRS格式中，维度3为行维度，维度2是列维度。\n\n在子数组SA_1_3中有三行数据，其中第0行的数据包含一个非零值12（如上图b所示），这是因为RO[1]=2（0-1行有两个元素）,RO[2]=6（0-3行有六个元素）,RO[3]=7，VL行保存了子数组中所有的非零行元素（12，13，14，15，16），而CO行存储了这些非零元素在该列中对应的列数组索引。\nEaCRS格式的前向映射和反向映射前向映射：从逻辑数据库位置计算出物理数据库位置。反向映射：从物理数据库位置计算出逻辑数据库位置\n其中逻辑数据库和物理数据库可以理解为数据经过压缩的前与后的两个状态。\n前向映射这里通过一个案例来说明前向映射，以元素&lt;3,3,1&gt;为例，考虑到，因为且，可以看出扩展的维度的是1号维度，该元素被包含在子数组SA_1_3之中，而在诸多维度之中，用于成员最少的维度通常被考虑为SA_1_3的行维度，又因为且，可知子数组SA_1_3的大小为,维度3作为行维度，该维度拥有的成员数量为3。又因为子数组是二维的，在这个前提下，维度2是SA_1_3唯一的列维度。上上图（a）中，第一行所有的非零元素的格式为RO[2] –RO[1] = 6 – 2 = 4，该行所对应的非零元素的列索引保存在CO[RO[1]-1]，CO[RO[1]]，CO[RO[1]+1]和CO[RO[1]+2]中，即为CO[1], CO[2], CO[3]和 CO[4]，因为该行有四个非零元素，该行中非零元素所对应的数值即为VL[1], VL[2], VL[3] 和 VL[4].\n后向映射","categories":["数据库"],"tags":["数据库"]},{"title":"influxdb源码阅读 -- 项目结构","url":"/2023/05/08/%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93/influxDB-project-struct/","content":"项目结构├─authorizer   验证信息├─bolt                       与bbolt交互的库├─chronograf            提供了一个可视化的监控界面├── cmd│   ├── chronograf-migrator │   ├── influx influx      客户端CLI│   ├── influx_inspect  influx探针│   ├── influxd             influx服务CLI│   └── telemetryd     用户信息征集├── context   与上下文有关的类├── docker 与docker有关的类│   ├── flux   │   └── influxd├── docs    用于存放文档，目前主要存在升级相关事项文档├── endpoints TODO 暂时不知道做什么的。是对原有的endpoints服务进行了一次重构，且抽离出来的├── etc 提供了一些常用脚本├── flux influx的客户端代码├── gather 收集器├── http 对外提供了http接口的目录│   ├── influxdb│   ├── metric│   └── mock├── inmem 服务内部的内存数据管理│   └── kvdata├── internal 内部服务│   ├── fs 文件相关│   ├── gogoproto│   ├── testutil│   └── yaml2json├── jsonweb jwt相关服务├── kit 工具集 │   ├── check│   ├── cli│   ├── errors│   ├── grpc│   ├── metric│   ├── prom│   ├── signals│   ├── tracing│   └── transport├── kv TODO 看上去像是K/V存储，用于缓存内部的一些信息。├── logger 日志相关├── mock mock数据，用于测试├── models 定义了一些数据模型│   └── testdata├── nats NATS队列中间件相关├── notification TODO 暂时看不出是做什么的│   ├── check│   ├── endpoint│   ├── flux│   └── rule├── pkg  一些内部常用的包│   ├── binaryutil│   ├── bloom│   ├── bytesutil│   ├── data│   ├── encoding│   ├── escape│   ├── estimator│   ├── fs│   ├── httpc│   ├── jsonnet│   ├── jsonparser│   ├── lifecycle│   ├── limiter│   ├── metrics│   ├── mmap│   ├── pointer│   ├── pool│   ├── rhh│   ├── slices│   ├── snowflake│   ├── testing│   └── testttp├── pkger TODO 暂时看不出是做什么的│   └── testdata├── predicate TODO 暂时看不出是做什么的├── prometheus WTF ?? TODO 暂时看不出是做什么的├── query  TODO 又是一个船新的HTTP服务，用于 Flux 查询的，但是不知道和http之间的关联│   ├── benchmarks│   ├── builtin│   ├── control│   ├── influxql│   ├── mock│   ├── promql│   ├── querytest│   └── stdlib├── rand 随机生成器，包含ID/Token├── resource 定义了资源的实体，资源实体包含了organization/task/bucket/user│   └── noop├── scripts 包含了一些协议相关的shell文件，这个文件为什么不会合并在etc里?├── snowflake 雪花算法ID生成器├── source 与版本兼容相关的类，包含了UI/v1/v2├── storage TODO 字面意思是存储，但是实际作用还不清楚│   ├── compat│   ├── reads│   ├── readservice│   └── wal├── task 任务相关│   ├── backend │   ├── mock│   ├── options│   └── servicetest├── telegraf TODO 不知道做啥的│   └── plugins├── telemetry 用于从普罗米修斯接收数据的数据收集器├── testing 测试相关├── toml toml解析类。(所以这个为什么不放在pkg目录里)├── tools TODO 工具类，但是具体也不知道做什么的│   └── tmpl├── tsdb TODO 暂时不知道是做什么的│   ├── cursors│   ├── internal│   ├── testdata│   ├── tsi1│   ├── tsm1│   └── value├── ui 后台管理界面│   ├── __mocks__│   ├── assets│   ├── build│   ├── cypress│   ├── mocks│   ├── scripts│   └── src├── uuid 用于生成UUID。所以，这个为什么不放在pkg里├── vault 与valut相关的文件├── write 写入└── zap 与zap日志相关的文件\n参考https://github.com/yinggaozhen/GoLearn/issues/43\n","categories":["数据库"],"tags":["数据库"]},{"title":"稀疏矩阵压缩研究","url":"/2022/01/04/%E5%8D%95%E6%9C%BA%E6%95%B0%E6%8D%AE%E5%BA%93/sparse-matrix-compress/","content":"1. 矩阵（稀疏矩阵）压缩存储（3种方式）数据结构中，提供针对某些特殊矩阵的压缩存储结构。存储矩阵的一般方法是采用二维数组，其优点是可以随机地访问每一个元素，因而能够容易实现矩阵的各种运算。\n对于稀疏矩阵，它通常具有很大的维度，有时甚大到整个矩阵（零元素）占用了绝大部分内存\n采用二维数组的存储方法既浪费大量的存储单元来存放零元素，又要在运算中浪费大量的时间来进行零元素的无效运算。因此必须考虑对稀疏矩阵进行压缩存储（只存储非零元素）。\n这里所说的特殊矩阵，主要分为以下3类：\n\n含有大量相同数据元素的矩阵，比如对称矩阵； 因此可以使用一维数组存储对称矩阵。由于矩阵中沿对角线两侧的数据相等，因此数组中只需存储对角线一侧\n含有大量 0 元素的矩阵，比如稀疏矩阵、上（下）三角矩阵； 上（下）三角矩阵采用对称矩阵的方式存储上（下）三角的数据（元素 0 不用存储）\n稀疏矩阵 如果矩阵中分布有大量的元素 0，即非 0 元素非常少，这类矩阵称为稀疏矩阵。压缩存储稀疏矩阵的一个简单而朴素的方法是：只存储矩阵中的非 0 元素，与前面的存储方法不同，稀疏矩阵非 0 元素的存储需同时存储该元素所在矩阵中的行标和列标。\n\n2. 稀疏矩阵压缩的主要方法2.1 坐标法 COO这种存储格式比较简单易懂，每一个元素需要用一个三元组来表示，分别是（行号，列号，数值），对应上图右边的一列。这种方式简单，但是记录单信息多（行列），每个三元组自己可以定位，因此空间不是最优。\n\n  采用三元组(row, col, data)(或称为ijv format)的形式来存储矩阵中非零元素的信息\n  三个数组 row 、col 和 data 分别保存非零元素的行下标、列下标与值（一般长度相同）\n  故 coo[row[k]][col[k]] = data[k] ，即矩阵的第 row[k] 行、第 col[k] 列的值为 data[k]\n\n适用场景\n  主要用来创建矩阵，因为coo_matrix无法对矩阵的元素进行增删改等操作\n  一旦创建之后，除了将之转换成其它格式的矩阵，几乎无法对其做任何操作和矩阵运算\n\n优缺点①优点\n  转换成其它存储格式很快捷简便（tobsr()、tocsr()、to_csc()、to_dia()、to_dok()、to_lil()）\n  能与CSR / CSC格式的快速转换\n  允许重复的索引（例如在1行1列处存了值2.0，又在1行1列处存了值3.0，则转换成其它矩阵时就是2.0+3.0=5.0）\n\n②缺点\n  不支持切片和算术运算操作\n  如果稀疏矩阵仅包含非0元素的对角线，则对角存储格式(DIA)可以减少非0元素定位的信息量\n  这种存储格式对有限元素或者有限差分离散化的矩阵尤其有效\n\n2.2 行压缩格式 Compressed Sparse Row (CSR)这是经常用的一种，我们会经常在一些标准的线性代数库或者数值运算库中看到此方式存储；CSR是比较标准的一种，也需要三类数据来表达：数值，列号，以及行偏移。CSR不是三元组，而是整体的编码方式。数值和列号与COO一致，表示一个元素以及其列号，行偏移表示某一行的第一个元素在values里面的起始偏移位置。\n如上图中，第一行的第一个元素1在values中是第0个, 所以是0偏移，第二行元素第一个元素2是2偏移，第三行第一个元素5是4偏移，第4行第一个元素6是7偏移。在行偏移的最后补上矩阵总的元素个数，本例中一共是9个非零元素。\n主要特征如下：\n\n  csr_matrix是按行对矩阵进行压缩的\n\n  通过 indices, indptr，data 来确定矩阵。\n\n  data 表示矩阵中的非零数据\n\n  对于第 i 行而言，该行中非零元素的列索引为 indices[indptr[i]:indptr[i+1]]\n\n  可以将 indptr 理解成利用其自身索引 i 来指向第 i 行元素的列索引\n\n  根据[indptr[i]:indptr[i+1]]，我就得到了该行中的非零元素个数，如\n\n  若 index[i] = 3 且 index[i+1] = 3 ，则第 i 行的没有非零元素\n\n  若 index[j] = 6 且 index[j+1] = 7 ，则第 j 行的非零元素的列索引为 indices[6:7]\n\n  得到了行索引、列索引，相应的数据存放在： data[indptr[i]:indptr[i+1]]\n\n\n\n\n  对于矩阵第 0 行，我们需要先得到其非零元素列索引\n\n  由 indptr[0] = 0 和 indptr[1] = 2 可知，第 0 行有两个非零元素。\n\n  它们的列索引为 indices[0:2] = [0, 2] ，且存放的数据为 data[0] = 8 ， data[1] = 2\n\n  因此矩阵第 0 行的非零元素 csr[0][0] = 8 和 csr[0][2] = 2\n\n  对于矩阵第 4 行，同样我们需要先计算其非零元素列索引\n\n  由 indptr[4] = 3 和 indptr[5] = 6 可知，第 4 行有3个非零元素。\n\n  它们的列索引为 indices[3:6] = [2, 3，4] ，且存放的数据为 data[3] = 7 ，data[4] = 1 ，data[5] = 2\n\n  因此矩阵第 4 行的非零元素 csr[4][2] = 7 ， csr[4][3] = 1 和 csr[4][4] = 2\n优缺点\n\n①优点\n  高效的稀疏矩阵算术运算\n  高效的行切片\n  快速地矩阵矢量积运算\n\n②缺点\n  较慢地列切片操作（可以考虑CSC）\n  转换到稀疏结构代价较高（可以考虑LIL，DOK）\n\n2.3列压缩格式 Compressed Sparse Column (CSC)CSC是和CSR相对应的一种方式，即按列压缩的意思。\n[[1 7 0 0] [0 2 8 0] [5 0 3 9] [0 6 0 4]]\n以上图中矩阵为例：\nColumn Offsets：[0 2 5 7 9]Row Index：[0 2 0 1 3 1 2 2 3]Values： [1 5 7 2 6 8 3 9 4]\nValues中的元素要按列写, 跟COO和CSR不同, 指定了Values的元素顺序之后就可以写Row Index, 然后根据每一列第一个元素在Values中的位置确定偏移量Column Offsets. 如第一列第一个元素1是0偏移, 第二列第一个元素7是2偏移, 第三列第一个元素8是5偏移, 第四列第一个元素9是7偏移, 共9个元素.\n主要特征如下：\n\n  csc_matrix是按列对矩阵进行压缩的\n\n  通过 indices, indptr，data 来确定矩阵，可以对比CSR\n\n  data 表示矩阵中的非零数据\n\n  对于第 i 列而言，该行中非零元素的行索引为indices[indptr[i]:indptr[i+1]]\n\n  可以将 indptr 理解成利用其自身索引 i 来指向第 i 列元素的列索引\n\n  根据[indptr[i]:indptr[i+1]]，我就得到了该行中的非零元素个数，如\n\n  若 index[i] = 1 且 index[i+1] = 1 ，则第 i 列的没有非零元素\n\n  若 index[j] = 4 且 index[j+1] = 6 ，则第 j列的非零元素的行索引为 indices[4:6]\n\n  得到了列索引、行索引，相应的数据存放在： data[indptr[i]:indptr[i+1]]\n\n\n对于矩阵第 0 列，我们需要先得到其非零元素行索引\n\n  由 indptr[0] = 0 和 indptr[1] = 1 可知，第 0列行有1个非零元素。\n  它们的行索引为 indices[0:1] = [0] ，且存放的数据为 data[0] = 8\n  因此矩阵第 0 行的非零元素 csc[0][0] = 8\n\n对于矩阵第 3 列，同样我们需要先计算其非零元素行索引\n\n  由 indptr[3] = 4 和 indptr[4] = 6 可知，第 4 行有2个非零元素。\n  它们的行索引为 indices[4:6] = [4, 6] ，且存放的数据为 data[4] = 1 ，data[5] = 9\n  因此矩阵第 i 行的非零元素 csr[4][3] = 1 ， csr[6][3] = 9\n\n2.4 Block Sparse Row Matrix (分块压缩稀疏行格式)(BSR)\n  基于行的块压缩，与csr类似，都是通过data，indices，indptr来确定矩阵\n\n与csr相比，只是data中的元数据由0维的数变为了一个矩阵（块），其余完全相同\n\n  块大小 blocksize\n\n  块大小 (R, C) 必须均匀划分矩阵 (M, N) 的形状。\n\n  R和C必须满足关系：M % R = 0 和 N % C = 0\n\n  适用场景及优点参考csr\n\n\n\n\n参考（抄袭）稀疏矩阵及其压缩格式\n\nSparse稀疏矩阵主要存储格式总结\n\n","categories":["数据库"],"tags":["数据库"]},{"title":"presto-基本概念","url":"/2024/08/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/presto-%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/","content":"Presto计算模块基本概念https://www.iteblog.com/archives/9955.html\nhttps://aliyuque.antfin.com/olap_platform/dtglq3/nfd5u2\nhttps://aaaaaaron.github.io/2022/07/11/Presto-Scheduler/:::\n\n执行流程名词解析\n首先介绍adb -xihe里每个查询的各个概念\nQuery： 当Presto接受一个SQL语句并执行时，会解析该SQL语句，将其转变成一个查询执行。\n计算过程\nStage（逻辑）\n查询执行阶段，当运行Query时，Presto根据是否需要跨worker做数据传输来将一个Query拆分成具有层级关系的多个Stage。\n\n每个Stage都有id，StageId越小，这个Stage的执行顺序越靠后。\nSpark计算引擎也有Stage，不过Spark是批处理的模式，前面的Stage执行完所有数据再执行后面的Stage，前一个stage执行完再启动后一个stage。\nPresto中数据流水线（pipeline）的处理机制，一批数据走完所有的stage流程，所以在初始化的时候，所有worker上的task都是启起来的。\n\nTask（物理）：\n分布式任务的执行单元，Stage只是定义了执行计划怎么划分, 接下来被调度到各个机器上去执行\n\nTask是节点级的并发：Stage并不会在Presto集群中实际执行，只是用来对查询计划进行管理和建模，因此Task是stage在某一个worker或者executor上的实例化\n一个Stage对应的多个Task内部执行逻辑完全相同，对应的Task数量就是Stage的并法度，具体是根据Stage的类型（Source、Fixed、Single）以及Worker的个数来决定的。\n从数据的视角出发，每个Task处理一个或者多个Split\n从计算的视角出发，一个Task又被分解为一个或多个Driver。\n\nPipeline（逻辑）：\n在Task内部，每个operator的最佳并发度可能不同。所以将Task切分为若干PipeLine，每个Pipeline内部的Operator的并发度相同。\n\n每个task会把算子执行树分成多个pipeline，每个pipeline执行stage任务的一部分操作\n\nTask 执行 stage(PlanFragment) 的逻辑, 就是执行一组 operator, 执行 operator 的最佳并行度可能是不同的, 比如说做Tablescan的并发可以很大, 但做Final Aggregation(如Sort)的并发度只能是一;\n\n所以一个 stage 会被切为若干 pipeline, 每个 Pipeline 由一组 Operator 组成, 这些 Operator 被设置同样的并行度. Pipeline 之间会通过 LocalExchangeOperator 来传递数据.\n\ndriver 的数量就是 pipeline 的并行度\n\n\nDriver（物理）：\nDriver是Pipeline的实例，其作用于一个Split的一系列Operator，Pipeline就是DriverFactory，用来create Driver\n\nDriver里不再有并行度, 每个Driver都是单线程的，一个PipeLine以实例化成多个相同的driver，driver之间是利用多线程并发运行\n每一个driver是一串operator算子操作集合，每个 Driver 拥有一个输入和输出.\n\nOperator\n代表对一个split的一种操作。例如过滤，加权等。以Page为最小处理单位进行输入输出。\n\n算子，是对数据的最小计算处理单位,每次读取/处理/输出一个page\n\n数据过程\nSplit：\n分片, 和 MapReduce 的 split 概念相似, 其下面包含 page\nPresto Connector会将待处理的所有数据划分为若干分片让Presto读取，一个分片就是一个大的数据集中的一部分，和shard的关系？\nPage：\nPage是Presto中处理的最小数据单元。一个Page对象包含多个Block对象。每个 Block 对象是一个字节数组, 存储一个字段（列）的若干行. 多个 Block 的横切的一行表示真实的一行数据. 一个 Page 最大 1MB, 最多 16 * 1024 行数据\nBlock：\n是xihe底层存储时候的读写基本单元，多个Block共同组成一个Page，详见 《ADB-Block-格式梳理》\n简单整体流程\n\n第一步：【Controller】接收SQL Query请求\n将sql转换为一个statement\n\n\n第二步：【Controller】词法与语法分析（生成AST）\n第三步：【Controller】创建和启动QueryExecution\n第四步：【Controller】语义分析\n第五步：【Controller】执行计划生成和优化\n生产逻辑计划Logic Plan\n\n\n第六步：【Controller】为逻辑执行计划分段\nPlan根据是否有数据的Shuffle 来生成 Fragment\n\n\n第七步：【Controller】创建SqlStageExecution\n把Fragment 按照是否需要跨worker传输数据划分成Stage\n\n\n第八步：【Controller】Stage调度-生成HttpRemoteTask并分发到Worker\nStage在逻辑上划分为一系列Task实例，并交给Work执行\nTask是Stage的实例，Task是Stage的并发度\n一个Task被处理多个数据分片：Spilt\n一个Task被切分为多个Pipeline（考虑到不同的Oprator并发度不同）\n\n\n第九步：【Worker】在Worker上执行任务，生成Query结果\n一个Driver是作用于一个Spilt的一串Operator的集合，负责执行Pipeline\n一个Pipeline对应多个Driver，每个Driver串行执行Operator\n\n\n第十步：【Controller】结果返回\n\n关键信息\nStage间在Task维度Shuffle，通过RemoteExchange表示\n\nStage内有多个Task，task个数由hash_partition_count决定\n\nTask内在Pipeline间Shuffle，通过LocalExchange表示\n\nPipeline内有多个Driver，driver个数由task_concurrency决定\n\nPage是xihe的数据，从存储的Block读出来转换过去，然后Query跟存储关联的是TableScan\n\n一个Page包含多个Block对象，如下图所示\n\n\n\n\n一个Driver可以被认为是串行执行一条pipeline，并且按照operator的顺序去处理page\n如下图所示：\n\n\n\n一个Stage 拆解成fragement后的执行流程\n\n\n\n从Worker的视角考虑各个粒度创建Task当Stage Plan下发到worker 后\nworker会通过SqlTaskExecutionFactory#createTask方法创建Thread个Task并发\n在SqlTaskManager中，管理着一个taskid与task任务对应的映射表\nConcurrentHashMap&lt;QueryId, Set&lt;TaskId&gt;&gt;\n其中taskid由sql的查询id与stageid唯一组成。\nTask的创建方式是依靠CacheBuilder.newBuilder().build的load动态加载，非常适合presto从自下而上，或者自上而下等调度方式。这样task的创建，完全由controller控制，非常方便，这里不多做诠释了。\nSpilt下发创建Driver一个Task对应多个Pipeline（通过DriverFactor），每个Pipeline有多个Driver作为其并发度，Driver就是一个最小的调度和执行的实体，其中有多个Operator算子\nDriver的并发调度方式如下所示：\n\n因此并发可以分成两个维度\n\nstage/task 级别并发:\ndriver级别并发\n\n详见图：\n\n","categories":["分布式系统"],"tags":["分布式系统"]},{"title":"大数据已死?","url":"/2023/06/28/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/big-data-is-dead/","content":"大数据时代已经结束了，大数据的存储和分析，作为一个技术问题已经解决了。    —— Jordan Tigani\n大数据起源于谷歌于2003年起发布一系列论文（大数据三驾马车）\n\nGFS 的论文《The Google File System 》发表于 2003 年，它主要是解决了数据的存储问题。作为一个上千节点的分布式文件系统，Google 可以把所有需要的数据都能很容易地存储下来。\nMapReduce的论文《MapReduce: Simplified Data Processing on Large Clusters》，利用简单的 Map 和 Reduce 两个函数，对于海量数据计算做了一次抽象，这就让“处理”数据的人，不再需要深入掌握分布式系统的开发了。\n《Bigtable: A Distributed Storage System for Structured Data》提出了 Google 设计的分布式数据存储系统 BigTable，来解决解决数据的高性能随机读写问题，是用来处理海量数据的一种非关系型数据库。BigTable 是一个稀疏的、分布式的、持久化存储的多维度排序的映射表。（HBase是Google Bigtable的开源实现，适合于非结构化数据存储的数据库，其基于列的而不是基于行的存储模式）\n\n大数据也或多或少影响到了后续云计算的发展方向，Hadoop后来他做云，云上放 MapReduce，并以Hadoop接口的方式对外提供服务，阿里云一开始做云计算，参考的就是Hadoop集群做批处理的方式，10年代之后伴随着AWS给出基于虚拟化做出可调度的计算/存储单元的云计算解决方案并获得巨大成功，才把云计算拉回当今世界线的轨道上。\n大数据已死的几个原因\n绝大多数企业到不了大数据级别，企业的数据量往往不到 1TB，很多甚至不到 100GB。\n存储和计算正在分离，大数据作为单一问题就不存在了，变成了海量存储和大型计算两个问题\n没有新业务的情况下，数据是线性增长的，即每天的新增数据与以前的数据结构相同。\n看重的往往只是最近的数据，90%的查询涉及的数据少于 100 MB。\n真正拥有大数据的公司，几乎从不查询全部数据。\n硬件的飞速发展，使得单台计算机的计算能力大增，意味着大数据的最大难点—-分布式计算—-即使被用到，困难程度也大大降低。\n\n综上所述，结论就是：数据量已经不需要特别关注了，再也不必担心处理不了海量数据了。 大数据作为一个技术问题，已经解决了。\n现在的一些方向Native Engine近年来，随着 IO 技术的提升，尤其是 SSD 和万兆网卡的普及，大家基于 Apache Spark 的数据负载场景遇到越来越多的 CPU 计算瓶颈，而不是传统认知中的 IO 瓶颈。而众所周知，基于 JVM 进行 CPU 指令的优化比较困难，因为 JVM 提供的 CPU 指令级的优化（例如 SIMD）要远远少于其他 Native 语言（例如 C++）。\n同时，大家也发现目前开源社区已经有比较成熟的 Native Engine（例如 ClickHouse、Velox），具备了优秀的向量化执行（Vectorized Execution）能力，并被证明能够带来显著的性能优势，然而它们往往游离于 Spark 生态之外，这对已经严重依赖 Spark 计算框架、无法接受大量运维和迁移成本的用户而言不够友好。Gluten 社区希望能够让 Spark 用户无需迁移，就能享受这些成熟的 Native Engine 带来的性能优势。\n参考\n《大数据经典论文解读》 三驾马车学习\n\nGoogle 引爆大数据时代的三篇论文-《GFS》、《BigTable》、《MapReduce》\n\n\n","categories":["分布式系统"],"tags":["分布式系统"]},{"title":"分布式Join方式的简单原理","url":"/2024/08/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%B3%BB%E7%BB%9F/%E5%88%86%E5%B8%83%E5%BC%8FJoin%E6%96%B9%E5%BC%8F%E7%9A%84%E7%AE%80%E5%8D%95%E5%8E%9F%E7%90%86/","content":"分布式Join方式的简单原理优化器会进行代价估计（有时候不一定准确），具体选择使用哪种join方式\n参考文档：\n\nDoris的join     \n\nPresto 两种 JOIN 算法实现\n\n\n单机join的几种方式\nHash Join：在右表上根据等值 Join 列建立哈希表，左表流式的利用哈希表进行 Join 计算，它的限制是只能适用于等值 Join。\nNest Loop Join：通过两个 for 循环，很直观，也很慢 。然后它适用的场景就是不等值的 Join，例如：大于小于或者是需要求笛卡尔积的场景。它是一个通用的 Join 算子，但是性能表现差。\n\n作为分布式的 MPP 数据库，在 Join 的过程中是需要进行数据的 Shuffle。数据需要进行拆分调度，才能保证最终的 Join 结果是正确的。举个简单的例子，假设关系 S 和 R 进行 Join，N 表示参与 Join 计算的节点的数量；T 则表示关系的 Tuple 数目。\n目前Presto主要使用的是hash join\nPresto中join的几种方式\nHash Join\nPresto 的hash join 将join操作中涉及的这两个表称为构建表（Build Table）和探测表（Probe Table），其区别如下\n\nbuild端：两表（或者子查询）做Hash Join时，其中一张表（子查询）的数据会构建成Hash表， 通常，在读取probe表之前必须完整读取构build表。\nprobe端：Hash Join的另一边，主要是读取数据然后和build端的Hash表进行匹配，一旦build表被读取并存储在内存中，probe表就会被逐行读取。 从探测表读取的每一行都将根据 join 条件 与build表进行连接。\n\nPresto 有一些基于成本的优化器，它们可以重新排序连接以将最小的表（即构建表）保留在右侧，以便它可以放入内存中，因此在执行计划正确的情况下，小表是build端，大表是probe端。\n其java 伪代码如下所示：\nMap&lt;Integer, List&lt;S&gt;&gt; index = new Hashtable&lt;&gt;();for (S s : build) &#123;  int hash = Objects.hash(s.joinKey);  index.putIfAbsent(hash, new LinkedList&lt;&gt;());  index.get(hash).add(order);&#125;// Hash Join algorithmfor (R r : probes) &#123;  int hash = Objects.hash(r.joinKey);  List&lt;r&gt; matches = index.get(hash);  if (matches != null) &#123;      for (S s : matches) &#123;          if (Objects.equals(s.joinKey, r.joinKey)) &#123;              System.out.println(s + &quot; -&gt; &quot; + r);          &#125;      &#125;  &#125;&#125;\n\nHash Join 算法的最坏情况时间复杂度是 O(n²)，但平均情况下预计为 O(n)。\n Nested Loop Join\n幽默连接算法，时间复杂度为 O(n²)，因为它必须将探测表中的每一行与构建表中的每一行连接起来，因此，不建议在没有连接条件的情况下连接两个大表。\n分布式join的shuffle方式\njoin 大概可以分为五种可能的形式：\n\n两个表join的key不是分布的key，这样的话需要加两个exchange算子来做数据的reshuffle （性能差）\n左表的数据按照joinkey分布，这样对右边的数据做重分布就可以了\n右表的数据量比较少，直接把右表的数据做一次BroadCast（BroadCast Join）\n在存储计算不分离的情境下，比如右表（例如维度表）本来就在本地，这种情况下，不需要做网络开销，直接从本地拉取\n最理想的情况下，左右两个表的joinkey都是分布的key，这样的话直接做local join \n\n\nBroadcast Join\n左表数据不移动，右表数据发送到左表数据的扫描****节点，适合一张较小的表和一张大表进行join\n它要求把右表全量的数据都发送到左表上，即每一个参与 Join 的节点，它都拥有右表全量的数据，也就是 T(R)。\n它适用的场景是比较通用的，同时能够支持 Hash Join 和 Nest loop Join，它的网络开销 N * T(R)。\n\nShuffle Join\n一旦小表数据量较大，此时就不再适合进行广播分发。这种情况下左右表数据根据分区，计算的结果发送到不同的分区节点上，将两张表分别按照join key进行重新组织分区，这样就可以将join分而治之，划分为很多小join\n当进行 Hash Join 时候，可以通过 Join 列计算对应的 Hash 值，并进行 Hash 分桶。\n它的网络开销则是：T（S） + T（R），但它只能支持 Hash Join，因为它是根据 Join 的条件也去做计算分桶的。\n\nBucket Shuffle Join\nDoris 的表数据本身是通过 Hash 计算分桶的，所以就可以利用表本身的分桶列的性质来进行 Join 数据的 Shuffle。假如两张表需要做 Join，并且 Join 列是左表的分桶列，那么左表的数据其实可以不用去移动右表通过左表的数据分桶发送数据就可以完成 Join 的计算。\n它的网络开销则是：T（R）相当于只 Shuffle 右表的数据就可以了。\n几种 Shuffle 方式对比\n\n\nShuffle 方式\n网络开销\n物理算子\n适用场景\n\n\n\nBroadCast\nN * T(R)\nHash Join / Nest Loop Join\n通用\n\n\nShuffle\nT(S) + T(R)\nHash Join\n通用\n\n\nBucket Shuffle\nT(R)\nHash Join\nJoin 条件中存在左表的分布式列，且左表执行时为单分区\n\n\nN：参与 Join 计算的 Instance 个数\nT(关系) : 关系的 Tuple 数目\n","categories":["分布式系统"],"tags":["分布式系统"]},{"title":"压缩WSL2占用的磁盘空间","url":"/2025/01/19/cleanup-wsl-storage/","content":"前言WSL占用的宿主机空间和实体机Linux不同的是，其已经占用的空间不会随着WSL内部文件的删除而释放，这样就会导致其占用额外的磁盘空间，这里对操作的指令进行备份，方便后续查询\n停止运行WSL实例解除对WSL所使用的VHDX文件的占用，IDE比如vscode也要停掉，不然有IO会导致拒绝访问问题\nwsl --shutdown\n\n寻找WSL 磁盘地址默认实在这个路径：%USERPROFILE%\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu*\\LocalState\\ext4.vhdx\n比如我的路径就是：%USERPROFILE%\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState\n在Windows中启动diskpart，并执行清理命令启动diskpart\ndiskpart\n然后输入下面的指令先选中磁盘文件，然后对其进行合并（压缩）：\n注意需要转为真实路径，%USERPROFILE% 可能会遇到一些问题\n# 替换为你的路径 select vdisk file=&quot;C:\\Users\\fzquantum\\AppData\\Local\\Packages\\CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\\LocalState\\ext4.vhdx&quot;compact vdisk\n\n\n下图是清理前后的区别：\n\n","tags":["折腾"]}]